{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import gensim\n",
    "import simple_net\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_df.sentence.values\n",
    "train_labels = train_df.label.values\n",
    "\n",
    "test_sentences = test_df.sentence.values\n",
    "test_labels = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('../model/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bring_nn_input(sentences):\n",
    "    vec_list = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = sentence.strip().split()\n",
    "\n",
    "        count = 0\n",
    "        sum_vec = np.zeros(300)\n",
    "\n",
    "        for word in words:\n",
    "            if word in word2vec_model:\n",
    "                sum_vec += word2vec_model[word]\n",
    "                count += 1\n",
    "        \n",
    "        if count != 0:\n",
    "            vec = (sum_vec / count)\n",
    "    \n",
    "        vec_list.append(vec)\n",
    "\n",
    "    return np.array(vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = bring_nn_input(train_sentences)\n",
    "test_vec = bring_nn_input(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 300\n",
    "hidden=100\n",
    "output = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_model = simple_net.Simple_Net(input, hidden, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(train_vec, train_labels, shuffle=True, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "optimizer = torch.optim.Adam(sn_model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/usairline{}'.format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sn_train(epochs):\n",
    "    x_train = Variable(torch.from_numpy(features_train)).float()\n",
    "    y_train = Variable(torch.from_numpy(labels_train)).long()\n",
    "\n",
    "    x_test = Variable(torch.from_numpy(features_test)).float()\n",
    "    y_test = Variable(torch.from_numpy(labels_test)).long()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sn_model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred_train = sn_model(x_train)\n",
    "        loss_train = criterion(y_pred_train, y_train)\n",
    "        \n",
    "        # print (\"epoch #\",epoch)\n",
    "        print (\"train loss: \", loss_train.item())\n",
    "        pred_train = torch.max(y_pred_train, 1)[1].eq(y_train).sum()\n",
    "        print (\"train acc:(%) \", 100*pred_train/len(x_train))\n",
    "\n",
    "        tb_x = epoch\n",
    "        # writer.add_scalar('Loss/train', loss_train.item(), tb_x)\n",
    "\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_test = sn_model(x_test)\n",
    "            loss_test = criterion(y_pred_test, y_test)\n",
    "            \n",
    "            # print (\"epoch #\",epoch)\n",
    "            print (\"test loss: \", loss_test.item())\n",
    "            pred_test = torch.max(y_pred_test, 1)[1].eq(y_test).sum()\n",
    "            print (\"test acc (%): \", 100*pred_test/len(x_test))\n",
    "        \n",
    "        writer.add_scalars('SimpleNet Training vs. Testing Loss',\n",
    "                    { 'Train' : loss_train.item(), 'Test' : loss_test.item() },\n",
    "                    tb_x + 1)\n",
    "        \n",
    "        writer.add_scalars('SimpleNet Training vs. Testing Accuracy',\n",
    "                    { 'Train' : 100*pred_train/len(x_train), 'Test' : 100*pred_test/len(x_test) },\n",
    "                    tb_x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sn_test(epochs):\n",
    "    sn_model.eval()\n",
    "    x_test = Variable(torch.from_numpy(features_test)).float()\n",
    "    y_test = Variable(torch.from_numpy(labels_test)).long()\n",
    "    for epoch in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            y_pred = sn_model(x_test)\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            print (\"epoch #\",epoch)\n",
    "            print (\"loss: \", loss.item())\n",
    "            pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "            print (\"acc (%): \", 100*pred/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sn_real_test(epochs):\n",
    "    sn_model.eval()\n",
    "    x_test = Variable(torch.from_numpy(test_vec)).float()\n",
    "    y_test = Variable(torch.from_numpy(test_labels)).long()\n",
    "    for epoch in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            y_pred = sn_model(x_test)\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            print (\"epoch #\",epoch)\n",
    "            print (\"loss: \", loss.item())\n",
    "            pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "            print (\"acc (%): \", 100*pred/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  train loss:  0.6982799768447876\n",
      "1  train loss:  0.6631367802619934\n",
      "2  train loss:  0.6772649884223938\n",
      "3  train loss:  0.6467200517654419\n",
      "4  train loss:  0.652622640132904\n",
      "5  train loss:  0.6458669304847717\n",
      "6  train loss:  0.6286985874176025\n",
      "7  train loss:  0.603245735168457\n",
      "8  train loss:  0.5661724209785461\n",
      "9  train loss:  0.5220828652381897\n",
      "10  train loss:  0.4905472695827484\n",
      "11  train loss:  0.49301955103874207\n",
      "12  train loss:  0.5840985178947449\n",
      "13  train loss:  0.4555674195289612\n",
      "14  train loss:  0.47621071338653564\n",
      "15  train loss:  0.416436105966568\n",
      "16  train loss:  0.4487517178058624\n",
      "17  train loss:  0.45910707116127014\n",
      "18  train loss:  0.42673230171203613\n",
      "19  train loss:  0.4062543213367462\n",
      "20  train loss:  0.40585413575172424\n",
      "21  train loss:  0.38097551465034485\n",
      "22  train loss:  0.370319664478302\n",
      "23  train loss:  0.37835225462913513\n",
      "24  train loss:  0.3511509597301483\n",
      "25  train loss:  0.35929521918296814\n",
      "26  train loss:  0.33906492590904236\n",
      "27  train loss:  0.33496153354644775\n",
      "28  train loss:  0.32997897267341614\n",
      "29  train loss:  0.31452444195747375\n",
      "30  train loss:  0.3180433213710785\n",
      "31  train loss:  0.30233219265937805\n",
      "32  train loss:  0.3004554510116577\n",
      "33  train loss:  0.29152432084083557\n",
      "34  train loss:  0.2816527187824249\n",
      "35  train loss:  0.2781563997268677\n",
      "36  train loss:  0.2667911648750305\n",
      "37  train loss:  0.26372575759887695\n",
      "38  train loss:  0.25310438871383667\n",
      "39  train loss:  0.24592699110507965\n",
      "40  train loss:  0.2406816929578781\n",
      "41  train loss:  0.2270510494709015\n",
      "42  train loss:  0.22252371907234192\n",
      "43  train loss:  0.21095192432403564\n",
      "44  train loss:  0.20091280341148376\n",
      "45  train loss:  0.19418108463287354\n",
      "46  train loss:  0.1845099776983261\n",
      "47  train loss:  0.17292138934135437\n",
      "48  train loss:  0.16154339909553528\n",
      "49  train loss:  0.15083831548690796\n",
      "50  train loss:  0.1423797458410263\n",
      "51  train loss:  0.14505617320537567\n",
      "52  train loss:  0.1940358430147171\n",
      "53  train loss:  0.17383326590061188\n",
      "54  train loss:  0.1439083218574524\n",
      "55  train loss:  0.13064831495285034\n",
      "56  train loss:  0.13090167939662933\n",
      "57  train loss:  0.1002817377448082\n",
      "58  train loss:  0.10665088891983032\n",
      "59  train loss:  0.09204377979040146\n",
      "60  train loss:  0.09270864725112915\n",
      "61  train loss:  0.07519316673278809\n",
      "62  train loss:  0.07524055242538452\n",
      "63  train loss:  0.06699574738740921\n",
      "64  train loss:  0.06883104145526886\n",
      "65  train loss:  0.06021546572446823\n",
      "66  train loss:  0.05821489170193672\n",
      "67  train loss:  0.0531405434012413\n",
      "68  train loss:  0.05002785474061966\n",
      "69  train loss:  0.04464110732078552\n",
      "70  train loss:  0.041470445692539215\n",
      "71  train loss:  0.037314273416996\n",
      "72  train loss:  0.03320993110537529\n",
      "73  train loss:  0.03030191920697689\n",
      "74  train loss:  0.028280911967158318\n",
      "75  train loss:  0.02533959411084652\n",
      "76  train loss:  0.024166211485862732\n",
      "77  train loss:  0.021015752106904984\n",
      "78  train loss:  0.01931523159146309\n",
      "79  train loss:  0.017359497025609016\n",
      "80  train loss:  0.01601666584610939\n",
      "81  train loss:  0.013476098887622356\n",
      "82  train loss:  0.01135745458304882\n",
      "83  train loss:  0.009987450204789639\n",
      "84  train loss:  0.00781817827373743\n",
      "85  train loss:  0.006123867351561785\n",
      "86  train loss:  0.005005689337849617\n",
      "87  train loss:  0.003453450044617057\n",
      "88  train loss:  0.002390759065747261\n",
      "89  train loss:  0.0019054383737966418\n",
      "90  train loss:  0.001692516845650971\n",
      "91  train loss:  0.0010161538375541568\n",
      "92  train loss:  0.0008368126582354307\n",
      "93  train loss:  0.0007679108530282974\n",
      "94  train loss:  0.0005905305733904243\n",
      "95  train loss:  0.0005116037209518254\n",
      "96  train loss:  0.00046522149932570755\n",
      "97  train loss:  0.0003734147176146507\n",
      "98  train loss:  0.0003040513547603041\n",
      "99  train loss:  0.0002636723220348358\n",
      "test acc (%):  tensor(78.0488)\n",
      "0  train loss:  1.8266668319702148\n",
      "1  train loss:  1.600218415260315\n",
      "2  train loss:  0.8451935052871704\n",
      "3  train loss:  0.4425690472126007\n",
      "4  train loss:  0.3994908034801483\n",
      "5  train loss:  0.41785624623298645\n",
      "6  train loss:  0.4607701599597931\n",
      "7  train loss:  0.48989418148994446\n",
      "8  train loss:  0.5038406252861023\n",
      "9  train loss:  0.5116679668426514\n",
      "10  train loss:  0.5133527517318726\n",
      "11  train loss:  0.5074586868286133\n",
      "12  train loss:  0.49434295296669006\n",
      "13  train loss:  0.47796735167503357\n",
      "14  train loss:  0.4576473832130432\n",
      "15  train loss:  0.43449026346206665\n",
      "16  train loss:  0.40932154655456543\n",
      "17  train loss:  0.38386961817741394\n",
      "18  train loss:  0.3620779514312744\n",
      "19  train loss:  0.35047683119773865\n",
      "20  train loss:  0.34433794021606445\n",
      "21  train loss:  0.3346715271472931\n",
      "22  train loss:  0.32579687237739563\n",
      "23  train loss:  0.3171479105949402\n",
      "24  train loss:  0.32268205285072327\n",
      "25  train loss:  0.34340307116508484\n",
      "26  train loss:  0.28215473890304565\n",
      "27  train loss:  0.3382849395275116\n",
      "28  train loss:  0.2888715863227844\n",
      "29  train loss:  0.3066766858100891\n",
      "30  train loss:  0.2650676667690277\n",
      "31  train loss:  0.29237255454063416\n",
      "32  train loss:  0.2515185475349426\n",
      "33  train loss:  0.26752713322639465\n",
      "34  train loss:  0.24323342740535736\n",
      "35  train loss:  0.2500879168510437\n",
      "36  train loss:  0.22377163171768188\n",
      "37  train loss:  0.22577117383480072\n",
      "38  train loss:  0.2128387838602066\n",
      "39  train loss:  0.21489392220973969\n",
      "40  train loss:  0.19562265276908875\n",
      "41  train loss:  0.19505701959133148\n",
      "42  train loss:  0.17682650685310364\n",
      "43  train loss:  0.18303312361240387\n",
      "44  train loss:  0.17084282636642456\n",
      "45  train loss:  0.15799176692962646\n",
      "46  train loss:  0.16352203488349915\n",
      "47  train loss:  0.14533060789108276\n",
      "48  train loss:  0.13604897260665894\n",
      "49  train loss:  0.14055125415325165\n",
      "50  train loss:  0.12689834833145142\n",
      "51  train loss:  0.11064578592777252\n",
      "52  train loss:  0.12082958966493607\n",
      "53  train loss:  0.11808852851390839\n",
      "54  train loss:  0.08984959870576859\n",
      "55  train loss:  0.1115836650133133\n",
      "56  train loss:  0.1235533058643341\n",
      "57  train loss:  0.07630883157253265\n",
      "58  train loss:  0.12042228877544403\n",
      "59  train loss:  0.13804177939891815\n",
      "60  train loss:  0.07465380430221558\n",
      "61  train loss:  0.12049846351146698\n",
      "62  train loss:  0.07377047091722488\n",
      "63  train loss:  0.12003181129693985\n",
      "64  train loss:  0.06617026776075363\n",
      "65  train loss:  0.13654117286205292\n",
      "66  train loss:  0.12878240644931793\n",
      "67  train loss:  0.11018485575914383\n",
      "68  train loss:  0.06333455443382263\n",
      "69  train loss:  0.178550124168396\n",
      "70  train loss:  0.08595207333564758\n",
      "71  train loss:  0.27341535687446594\n",
      "72  train loss:  0.06795014441013336\n",
      "73  train loss:  0.42660608887672424\n",
      "74  train loss:  0.10891477763652802\n",
      "75  train loss:  0.3728863298892975\n",
      "76  train loss:  0.2541073262691498\n",
      "77  train loss:  0.22250770032405853\n",
      "78  train loss:  0.2673581838607788\n",
      "79  train loss:  0.12796758115291595\n",
      "80  train loss:  0.14349597692489624\n",
      "81  train loss:  0.15341684222221375\n",
      "82  train loss:  0.1421450525522232\n",
      "83  train loss:  0.15446847677230835\n",
      "84  train loss:  0.1509210765361786\n",
      "85  train loss:  0.12961949408054352\n",
      "86  train loss:  0.12829352915287018\n",
      "87  train loss:  0.11993187665939331\n",
      "88  train loss:  0.09868954122066498\n",
      "89  train loss:  0.08657172322273254\n",
      "90  train loss:  0.08488176017999649\n",
      "91  train loss:  0.07416950911283493\n",
      "92  train loss:  0.06406085938215256\n",
      "93  train loss:  0.06501005589962006\n",
      "94  train loss:  0.06423463672399521\n",
      "95  train loss:  0.05939313396811485\n",
      "96  train loss:  0.055267903953790665\n",
      "97  train loss:  0.04838544502854347\n",
      "98  train loss:  0.04301504045724869\n",
      "99  train loss:  0.04127395153045654\n",
      "test acc (%):  tensor(78.7339)\n",
      "0  train loss:  0.8043036460876465\n",
      "1  train loss:  0.7093623876571655\n",
      "2  train loss:  0.594262421131134\n",
      "3  train loss:  0.4985629916191101\n",
      "4  train loss:  0.4223642945289612\n",
      "5  train loss:  0.37038132548332214\n",
      "6  train loss:  0.34186458587646484\n",
      "7  train loss:  0.3298155665397644\n",
      "8  train loss:  0.3270975947380066\n",
      "9  train loss:  0.32898324728012085\n",
      "10  train loss:  0.3310198485851288\n",
      "11  train loss:  0.3310393691062927\n",
      "12  train loss:  0.3284313380718231\n",
      "13  train loss:  0.322965532541275\n",
      "14  train loss:  0.3149646520614624\n",
      "15  train loss:  0.3052612841129303\n",
      "16  train loss:  0.29489046335220337\n",
      "17  train loss:  0.28453102707862854\n",
      "18  train loss:  0.27350637316703796\n",
      "19  train loss:  0.2622533440589905\n",
      "20  train loss:  0.25110965967178345\n",
      "21  train loss:  0.2401382327079773\n",
      "22  train loss:  0.22979457676410675\n",
      "23  train loss:  0.22045639157295227\n",
      "24  train loss:  0.21095587313175201\n",
      "25  train loss:  0.20201769471168518\n",
      "26  train loss:  0.19409741461277008\n",
      "27  train loss:  0.18589943647384644\n",
      "28  train loss:  0.1780553013086319\n",
      "29  train loss:  0.1705493927001953\n",
      "30  train loss:  0.16246512532234192\n",
      "31  train loss:  0.15551699697971344\n",
      "32  train loss:  0.14802128076553345\n",
      "33  train loss:  0.1404843032360077\n",
      "34  train loss:  0.13352316617965698\n",
      "35  train loss:  0.12785108387470245\n",
      "36  train loss:  0.12251927703619003\n",
      "37  train loss:  0.11697179079055786\n",
      "38  train loss:  0.11111386120319366\n",
      "39  train loss:  0.1058214083313942\n",
      "40  train loss:  0.10136241465806961\n",
      "41  train loss:  0.09760097414255142\n",
      "42  train loss:  0.09447383135557175\n",
      "43  train loss:  0.0914192795753479\n",
      "44  train loss:  0.08852089941501617\n",
      "45  train loss:  0.08627308905124664\n",
      "46  train loss:  0.08418063819408417\n",
      "47  train loss:  0.08191642165184021\n",
      "48  train loss:  0.07920923084020615\n",
      "49  train loss:  0.07645983248949051\n",
      "50  train loss:  0.07404886931180954\n",
      "51  train loss:  0.07192414999008179\n",
      "52  train loss:  0.07076340913772583\n",
      "53  train loss:  0.06983954459428787\n",
      "54  train loss:  0.06886215507984161\n",
      "55  train loss:  0.06804250925779343\n",
      "56  train loss:  0.06723856180906296\n",
      "57  train loss:  0.0663917064666748\n",
      "58  train loss:  0.06538130342960358\n",
      "59  train loss:  0.0643291026353836\n",
      "60  train loss:  0.06328237801790237\n",
      "61  train loss:  0.06195090711116791\n",
      "62  train loss:  0.06039317324757576\n",
      "63  train loss:  0.05898072198033333\n",
      "64  train loss:  0.05785011127591133\n",
      "65  train loss:  0.05648932605981827\n",
      "66  train loss:  0.05516766756772995\n",
      "67  train loss:  0.05406613275408745\n",
      "68  train loss:  0.053238265216350555\n",
      "69  train loss:  0.05250969156622887\n",
      "70  train loss:  0.05167035013437271\n",
      "71  train loss:  0.05088246241211891\n",
      "72  train loss:  0.049873221665620804\n",
      "73  train loss:  0.04877697303891182\n",
      "74  train loss:  0.04764571040868759\n",
      "75  train loss:  0.04619600996375084\n",
      "76  train loss:  0.045055367052555084\n",
      "77  train loss:  0.043640732765197754\n",
      "78  train loss:  0.04238859564065933\n",
      "79  train loss:  0.04147973284125328\n",
      "80  train loss:  0.04078109562397003\n",
      "81  train loss:  0.039980847388505936\n",
      "82  train loss:  0.039182353764772415\n",
      "83  train loss:  0.03799944370985031\n",
      "84  train loss:  0.03671002388000488\n",
      "85  train loss:  0.035526759922504425\n",
      "86  train loss:  0.0341930128633976\n",
      "87  train loss:  0.0335351899266243\n",
      "88  train loss:  0.03252893686294556\n",
      "89  train loss:  0.03169671818614006\n",
      "90  train loss:  0.031369440257549286\n",
      "91  train loss:  0.03017214685678482\n",
      "92  train loss:  0.029585570096969604\n",
      "93  train loss:  0.02903141640126705\n",
      "94  train loss:  0.028537996113300323\n",
      "95  train loss:  0.02813497930765152\n",
      "96  train loss:  0.027630936354398727\n",
      "97  train loss:  0.027169188484549522\n",
      "98  train loss:  0.026905780658125877\n",
      "99  train loss:  0.026522105559706688\n",
      "test acc (%):  tensor(77.4185)\n",
      "0  train loss:  4.115567207336426\n",
      "1  train loss:  5.3399529457092285\n",
      "2  train loss:  1.4664746522903442\n",
      "3  train loss:  1.5301234722137451\n",
      "4  train loss:  0.76705402135849\n",
      "5  train loss:  0.6306979656219482\n",
      "6  train loss:  0.5645972490310669\n",
      "7  train loss:  0.5561221241950989\n",
      "8  train loss:  0.5571886897087097\n",
      "9  train loss:  0.5494181513786316\n",
      "10  train loss:  0.5358031392097473\n",
      "11  train loss:  0.5287436842918396\n",
      "12  train loss:  0.5158792734146118\n",
      "13  train loss:  0.5054622888565063\n",
      "14  train loss:  0.49947720766067505\n",
      "15  train loss:  0.4855033755302429\n",
      "16  train loss:  0.4805016815662384\n",
      "17  train loss:  0.4704189896583557\n",
      "18  train loss:  0.46029898524284363\n",
      "19  train loss:  0.45572853088378906\n",
      "20  train loss:  0.44000932574272156\n",
      "21  train loss:  0.43394413590431213\n",
      "22  train loss:  0.42918887734413147\n",
      "23  train loss:  0.4194200038909912\n",
      "24  train loss:  0.40711119771003723\n",
      "25  train loss:  0.4018811285495758\n",
      "26  train loss:  0.40337327122688293\n",
      "27  train loss:  0.39448657631874084\n",
      "28  train loss:  0.38479846715927124\n",
      "29  train loss:  0.37005114555358887\n",
      "30  train loss:  0.3622108995914459\n",
      "31  train loss:  0.3596552908420563\n",
      "32  train loss:  0.356000155210495\n",
      "33  train loss:  0.35259610414505005\n",
      "34  train loss:  0.3399448096752167\n",
      "35  train loss:  0.3317890167236328\n",
      "36  train loss:  0.32954877614974976\n",
      "37  train loss:  0.32905372977256775\n",
      "38  train loss:  0.3277525007724762\n",
      "39  train loss:  0.31515514850616455\n",
      "40  train loss:  0.30657365918159485\n",
      "41  train loss:  0.3063768148422241\n",
      "42  train loss:  0.30480054020881653\n",
      "43  train loss:  0.2980952858924866\n",
      "44  train loss:  0.289437860250473\n",
      "45  train loss:  0.2857060730457306\n",
      "46  train loss:  0.2844564914703369\n",
      "47  train loss:  0.27859944105148315\n",
      "48  train loss:  0.2719821333885193\n",
      "49  train loss:  0.2663247287273407\n",
      "50  train loss:  0.261492520570755\n",
      "51  train loss:  0.2573898732662201\n",
      "52  train loss:  0.2538539469242096\n",
      "53  train loss:  0.2513121962547302\n",
      "54  train loss:  0.25148138403892517\n",
      "55  train loss:  0.26750239729881287\n",
      "56  train loss:  0.26154056191444397\n",
      "57  train loss:  0.2518802583217621\n",
      "58  train loss:  0.231695294380188\n",
      "59  train loss:  0.2527010440826416\n",
      "60  train loss:  0.2631646990776062\n",
      "61  train loss:  0.2252849042415619\n",
      "62  train loss:  0.2761171758174896\n",
      "63  train loss:  0.24770395457744598\n",
      "64  train loss:  0.24283432960510254\n",
      "65  train loss:  0.23810699582099915\n",
      "66  train loss:  0.2147875726222992\n",
      "67  train loss:  0.226218119263649\n",
      "68  train loss:  0.21299339830875397\n",
      "69  train loss:  0.2208038717508316\n",
      "70  train loss:  0.19753989577293396\n",
      "71  train loss:  0.20486140251159668\n",
      "72  train loss:  0.19280797243118286\n",
      "73  train loss:  0.20170968770980835\n",
      "74  train loss:  0.18855006992816925\n",
      "75  train loss:  0.19074535369873047\n",
      "76  train loss:  0.18446487188339233\n",
      "77  train loss:  0.18156133592128754\n",
      "78  train loss:  0.18341025710105896\n",
      "79  train loss:  0.17453940212726593\n",
      "80  train loss:  0.1809660792350769\n",
      "81  train loss:  0.1723661571741104\n",
      "82  train loss:  0.170406311750412\n",
      "83  train loss:  0.17461857199668884\n",
      "84  train loss:  0.166303813457489\n",
      "85  train loss:  0.16092243790626526\n",
      "86  train loss:  0.16911476850509644\n",
      "87  train loss:  0.17047345638275146\n",
      "88  train loss:  0.15445354580879211\n",
      "89  train loss:  0.17247723042964935\n",
      "90  train loss:  0.18389825522899628\n",
      "91  train loss:  0.1540466845035553\n",
      "92  train loss:  0.19455158710479736\n",
      "93  train loss:  0.1753905713558197\n",
      "94  train loss:  0.16882985830307007\n",
      "95  train loss:  0.19368788599967957\n",
      "96  train loss:  0.15562734007835388\n",
      "97  train loss:  0.1700543314218521\n",
      "98  train loss:  0.16988368332386017\n",
      "99  train loss:  0.16790512204170227\n",
      "test acc (%):  tensor(78.8161)\n",
      "0  train loss:  1.0051769018173218\n",
      "1  train loss:  0.9008076786994934\n",
      "2  train loss:  0.8204612731933594\n",
      "3  train loss:  0.625541090965271\n",
      "4  train loss:  0.5481305122375488\n",
      "5  train loss:  0.5935285091400146\n",
      "6  train loss:  0.481187105178833\n",
      "7  train loss:  0.5005239844322205\n",
      "8  train loss:  0.5083888173103333\n",
      "9  train loss:  0.4791518747806549\n",
      "10  train loss:  0.4583917260169983\n",
      "11  train loss:  0.47051486372947693\n",
      "12  train loss:  0.47342047095298767\n",
      "13  train loss:  0.4403618276119232\n",
      "14  train loss:  0.41990751028060913\n",
      "15  train loss:  0.42471617460250854\n",
      "16  train loss:  0.41679298877716064\n",
      "17  train loss:  0.3986155390739441\n",
      "18  train loss:  0.41842201352119446\n",
      "19  train loss:  0.3955727517604828\n",
      "20  train loss:  0.3869929313659668\n",
      "21  train loss:  0.38164985179901123\n",
      "22  train loss:  0.37497296929359436\n",
      "23  train loss:  0.3682732880115509\n",
      "24  train loss:  0.3639211356639862\n",
      "25  train loss:  0.356147825717926\n",
      "26  train loss:  0.3523505628108978\n",
      "27  train loss:  0.3494724631309509\n",
      "28  train loss:  0.3466346561908722\n",
      "29  train loss:  0.3424830734729767\n",
      "30  train loss:  0.3355637490749359\n",
      "31  train loss:  0.33172258734703064\n",
      "32  train loss:  0.32728275656700134\n",
      "33  train loss:  0.32257094979286194\n",
      "34  train loss:  0.31768977642059326\n",
      "35  train loss:  0.31385618448257446\n",
      "36  train loss:  0.3108358383178711\n",
      "37  train loss:  0.30503055453300476\n",
      "38  train loss:  0.2986615300178528\n",
      "39  train loss:  0.2937847673892975\n",
      "40  train loss:  0.29031431674957275\n",
      "41  train loss:  0.28601863980293274\n",
      "42  train loss:  0.28157636523246765\n",
      "43  train loss:  0.27703073620796204\n",
      "44  train loss:  0.2727782726287842\n",
      "45  train loss:  0.26856106519699097\n",
      "46  train loss:  0.2649995684623718\n",
      "47  train loss:  0.2602599859237671\n",
      "48  train loss:  0.2551063597202301\n",
      "49  train loss:  0.24944816529750824\n",
      "50  train loss:  0.24508190155029297\n",
      "51  train loss:  0.24169401824474335\n",
      "52  train loss:  0.24072107672691345\n",
      "53  train loss:  0.2455030381679535\n",
      "54  train loss:  0.24633556604385376\n",
      "55  train loss:  0.23095294833183289\n",
      "56  train loss:  0.2276364117860794\n",
      "57  train loss:  0.22998455166816711\n",
      "58  train loss:  0.21896299719810486\n",
      "59  train loss:  0.21740223467350006\n",
      "60  train loss:  0.21948903799057007\n",
      "61  train loss:  0.21025070548057556\n",
      "62  train loss:  0.2053089141845703\n",
      "63  train loss:  0.20664024353027344\n",
      "64  train loss:  0.20427244901657104\n",
      "65  train loss:  0.19715005159378052\n",
      "66  train loss:  0.1921415627002716\n",
      "67  train loss:  0.1904624104499817\n",
      "68  train loss:  0.19147031009197235\n",
      "69  train loss:  0.19659920036792755\n",
      "70  train loss:  0.19810478389263153\n",
      "71  train loss:  0.18468986451625824\n",
      "72  train loss:  0.17331629991531372\n",
      "73  train loss:  0.177764892578125\n",
      "74  train loss:  0.1850654035806656\n",
      "75  train loss:  0.17978842556476593\n",
      "76  train loss:  0.16297999024391174\n",
      "77  train loss:  0.16448400914669037\n",
      "78  train loss:  0.17352093756198883\n",
      "79  train loss:  0.16162697970867157\n",
      "80  train loss:  0.15028762817382812\n",
      "81  train loss:  0.15112099051475525\n",
      "82  train loss:  0.1545737236738205\n",
      "83  train loss:  0.1531209498643875\n",
      "84  train loss:  0.14185647666454315\n",
      "85  train loss:  0.13599033653736115\n",
      "86  train loss:  0.13656140863895416\n",
      "87  train loss:  0.13925310969352722\n",
      "88  train loss:  0.14560391008853912\n",
      "89  train loss:  0.14690546691417694\n",
      "90  train loss:  0.1480465680360794\n",
      "91  train loss:  0.13013488054275513\n",
      "92  train loss:  0.11884275078773499\n",
      "93  train loss:  0.12104011327028275\n",
      "94  train loss:  0.12401416152715683\n",
      "95  train loss:  0.1255754977464676\n",
      "96  train loss:  0.11514388024806976\n",
      "97  train loss:  0.10831189155578613\n",
      "98  train loss:  0.10724752396345139\n",
      "99  train loss:  0.10873740911483765\n",
      "test acc (%):  tensor(77.9392)\n",
      "0  train loss:  1.0263023376464844\n",
      "1  train loss:  0.8674647808074951\n",
      "2  train loss:  0.6449616551399231\n",
      "3  train loss:  0.5852621793746948\n",
      "4  train loss:  0.49827268719673157\n",
      "5  train loss:  0.4666514992713928\n",
      "6  train loss:  0.46621203422546387\n",
      "7  train loss:  0.46989038586616516\n",
      "8  train loss:  0.46944037079811096\n",
      "9  train loss:  0.4707023799419403\n",
      "10  train loss:  0.47394970059394836\n",
      "11  train loss:  0.47591015696525574\n",
      "12  train loss:  0.47115933895111084\n",
      "13  train loss:  0.45937415957450867\n",
      "14  train loss:  0.4444723427295685\n",
      "15  train loss:  0.42927923798561096\n",
      "16  train loss:  0.41467714309692383\n",
      "17  train loss:  0.4018881022930145\n",
      "18  train loss:  0.391320139169693\n",
      "19  train loss:  0.38358446955680847\n",
      "20  train loss:  0.37973254919052124\n",
      "21  train loss:  0.37746554613113403\n",
      "22  train loss:  0.37484535574913025\n",
      "23  train loss:  0.3709551692008972\n",
      "24  train loss:  0.3657224476337433\n",
      "25  train loss:  0.3603866994380951\n",
      "26  train loss:  0.3561049997806549\n",
      "27  train loss:  0.35283559560775757\n",
      "28  train loss:  0.34982699155807495\n",
      "29  train loss:  0.3480489253997803\n",
      "30  train loss:  0.3462635278701782\n",
      "31  train loss:  0.34010812640190125\n",
      "32  train loss:  0.33704257011413574\n",
      "33  train loss:  0.3350134491920471\n",
      "34  train loss:  0.3294019103050232\n",
      "35  train loss:  0.3281223773956299\n",
      "36  train loss:  0.32368728518486023\n",
      "37  train loss:  0.32235628366470337\n",
      "38  train loss:  0.31815478205680847\n",
      "39  train loss:  0.3163241446018219\n",
      "40  train loss:  0.3131032884120941\n",
      "41  train loss:  0.3111450672149658\n",
      "42  train loss:  0.30820322036743164\n",
      "43  train loss:  0.3046763241291046\n",
      "44  train loss:  0.3031771779060364\n",
      "45  train loss:  0.2991008758544922\n",
      "46  train loss:  0.2969712018966675\n",
      "47  train loss:  0.2944117784500122\n",
      "48  train loss:  0.2907734215259552\n",
      "49  train loss:  0.2881253659725189\n",
      "50  train loss:  0.28677618503570557\n",
      "51  train loss:  0.2872496545314789\n",
      "52  train loss:  0.2830570936203003\n",
      "53  train loss:  0.2781982719898224\n",
      "54  train loss:  0.27655911445617676\n",
      "55  train loss:  0.2751599848270416\n",
      "56  train loss:  0.271585077047348\n",
      "57  train loss:  0.26842284202575684\n",
      "58  train loss:  0.26735782623291016\n",
      "59  train loss:  0.2648305296897888\n",
      "60  train loss:  0.26142624020576477\n",
      "61  train loss:  0.2599523663520813\n",
      "62  train loss:  0.25817424058914185\n",
      "63  train loss:  0.25484949350357056\n",
      "64  train loss:  0.25334158539772034\n",
      "65  train loss:  0.25174856185913086\n",
      "66  train loss:  0.24840278923511505\n",
      "67  train loss:  0.24668824672698975\n",
      "68  train loss:  0.24524278938770294\n",
      "69  train loss:  0.24220602214336395\n",
      "70  train loss:  0.23975476622581482\n",
      "71  train loss:  0.23841160535812378\n",
      "72  train loss:  0.23614457249641418\n",
      "73  train loss:  0.23331230878829956\n",
      "74  train loss:  0.2316124141216278\n",
      "75  train loss:  0.22999651730060577\n",
      "76  train loss:  0.22746989130973816\n",
      "77  train loss:  0.22476623952388763\n",
      "78  train loss:  0.2227376252412796\n",
      "79  train loss:  0.22107180953025818\n",
      "80  train loss:  0.21913491189479828\n",
      "81  train loss:  0.21690112352371216\n",
      "82  train loss:  0.2144487202167511\n",
      "83  train loss:  0.21242812275886536\n",
      "84  train loss:  0.21078599989414215\n",
      "85  train loss:  0.2092459499835968\n",
      "86  train loss:  0.20749539136886597\n",
      "87  train loss:  0.20541061460971832\n",
      "88  train loss:  0.20340347290039062\n",
      "89  train loss:  0.20150573551654816\n",
      "90  train loss:  0.19987212121486664\n",
      "91  train loss:  0.19844964146614075\n",
      "92  train loss:  0.197122722864151\n",
      "93  train loss:  0.19578123092651367\n",
      "94  train loss:  0.19405309855937958\n",
      "95  train loss:  0.1924811601638794\n",
      "96  train loss:  0.1906912624835968\n",
      "97  train loss:  0.18947134912014008\n",
      "98  train loss:  0.18805722892284393\n",
      "99  train loss:  0.18751634657382965\n",
      "test acc (%):  tensor(78.3776)\n",
      "0  train loss:  0.559872031211853\n",
      "1  train loss:  0.5151343941688538\n",
      "2  train loss:  0.4807407855987549\n",
      "3  train loss:  0.4303107261657715\n",
      "4  train loss:  0.41505858302116394\n",
      "5  train loss:  0.4160023331642151\n",
      "6  train loss:  0.4150066375732422\n",
      "7  train loss:  0.40426352620124817\n",
      "8  train loss:  0.3944835364818573\n",
      "9  train loss:  0.38116201758384705\n",
      "10  train loss:  0.3738757073879242\n",
      "11  train loss:  0.36662203073501587\n",
      "12  train loss:  0.36103564500808716\n",
      "13  train loss:  0.35821956396102905\n",
      "14  train loss:  0.35560861229896545\n",
      "15  train loss:  0.3510066270828247\n",
      "16  train loss:  0.3453648090362549\n",
      "17  train loss:  0.3407050371170044\n",
      "18  train loss:  0.337980717420578\n",
      "19  train loss:  0.3352682590484619\n",
      "20  train loss:  0.3324071168899536\n",
      "21  train loss:  0.32900330424308777\n",
      "22  train loss:  0.32533466815948486\n",
      "23  train loss:  0.3219442069530487\n",
      "24  train loss:  0.3183209002017975\n",
      "25  train loss:  0.31467342376708984\n",
      "26  train loss:  0.31099140644073486\n",
      "27  train loss:  0.3074095845222473\n",
      "28  train loss:  0.3042716681957245\n",
      "29  train loss:  0.3017772138118744\n",
      "30  train loss:  0.29894956946372986\n",
      "31  train loss:  0.29574066400527954\n",
      "32  train loss:  0.2924707531929016\n",
      "33  train loss:  0.28948479890823364\n",
      "34  train loss:  0.28659147024154663\n",
      "35  train loss:  0.2839463949203491\n",
      "36  train loss:  0.28124645352363586\n",
      "37  train loss:  0.2786860466003418\n",
      "38  train loss:  0.2763843536376953\n",
      "39  train loss:  0.2740301489830017\n",
      "40  train loss:  0.27165159583091736\n",
      "41  train loss:  0.26935407519340515\n",
      "42  train loss:  0.26695358753204346\n",
      "43  train loss:  0.2643996775150299\n",
      "44  train loss:  0.2620851993560791\n",
      "45  train loss:  0.25978171825408936\n",
      "46  train loss:  0.25764596462249756\n",
      "47  train loss:  0.25530198216438293\n",
      "48  train loss:  0.2531657814979553\n",
      "49  train loss:  0.2511614263057709\n",
      "50  train loss:  0.24887266755104065\n",
      "51  train loss:  0.24663107097148895\n",
      "52  train loss:  0.24454092979431152\n",
      "53  train loss:  0.24250873923301697\n",
      "54  train loss:  0.24047107994556427\n",
      "55  train loss:  0.23854050040245056\n",
      "56  train loss:  0.23696966469287872\n",
      "57  train loss:  0.23479010164737701\n",
      "58  train loss:  0.23305819928646088\n",
      "59  train loss:  0.23113904893398285\n",
      "60  train loss:  0.22923924028873444\n",
      "61  train loss:  0.22735992074012756\n",
      "62  train loss:  0.22538352012634277\n",
      "63  train loss:  0.2231692671775818\n",
      "64  train loss:  0.2211492657661438\n",
      "65  train loss:  0.21939776837825775\n",
      "66  train loss:  0.21761612594127655\n",
      "67  train loss:  0.2159223109483719\n",
      "68  train loss:  0.21443034708499908\n",
      "69  train loss:  0.21247577667236328\n",
      "70  train loss:  0.21075916290283203\n",
      "71  train loss:  0.20894990861415863\n",
      "72  train loss:  0.20725910365581512\n",
      "73  train loss:  0.2057592123746872\n",
      "74  train loss:  0.20424427092075348\n",
      "75  train loss:  0.20281939208507538\n",
      "76  train loss:  0.20140241086483002\n",
      "77  train loss:  0.2000119686126709\n",
      "78  train loss:  0.19861812889575958\n",
      "79  train loss:  0.19710472226142883\n",
      "80  train loss:  0.1956206113100052\n",
      "81  train loss:  0.19419777393341064\n",
      "82  train loss:  0.19295178353786469\n",
      "83  train loss:  0.19180931150913239\n",
      "84  train loss:  0.19060499966144562\n",
      "85  train loss:  0.19052256643772125\n",
      "86  train loss:  0.18946148455142975\n",
      "87  train loss:  0.18725596368312836\n",
      "88  train loss:  0.18707877397537231\n",
      "89  train loss:  0.1848963052034378\n",
      "90  train loss:  0.1846773326396942\n",
      "91  train loss:  0.18366749584674835\n",
      "92  train loss:  0.1820140928030014\n",
      "93  train loss:  0.18189269304275513\n",
      "94  train loss:  0.18030786514282227\n",
      "95  train loss:  0.17892757058143616\n",
      "96  train loss:  0.17871983349323273\n",
      "97  train loss:  0.17714852094650269\n",
      "98  train loss:  0.17528310418128967\n",
      "99  train loss:  0.17435096204280853\n",
      "test acc (%):  tensor(79.1176)\n",
      "0  train loss:  0.7263287305831909\n",
      "1  train loss:  0.5564910769462585\n",
      "2  train loss:  0.4798518717288971\n",
      "3  train loss:  0.44655418395996094\n",
      "4  train loss:  0.410854309797287\n",
      "5  train loss:  0.38041380047798157\n",
      "6  train loss:  0.4012509882450104\n",
      "7  train loss:  0.4011824131011963\n",
      "8  train loss:  0.395046204328537\n",
      "9  train loss:  0.39002835750579834\n",
      "10  train loss:  0.3791210949420929\n",
      "11  train loss:  0.36963364481925964\n",
      "12  train loss:  0.3648828864097595\n",
      "13  train loss:  0.35638129711151123\n",
      "14  train loss:  0.3485199511051178\n",
      "15  train loss:  0.3439299464225769\n",
      "16  train loss:  0.3385583758354187\n",
      "17  train loss:  0.3315652310848236\n",
      "18  train loss:  0.326386958360672\n",
      "19  train loss:  0.32221704721450806\n",
      "20  train loss:  0.3196476101875305\n",
      "21  train loss:  0.31567832827568054\n",
      "22  train loss:  0.31088003516197205\n",
      "23  train loss:  0.3056396543979645\n",
      "24  train loss:  0.3002829849720001\n",
      "25  train loss:  0.2954312264919281\n",
      "26  train loss:  0.29092371463775635\n",
      "27  train loss:  0.2855212390422821\n",
      "28  train loss:  0.2827337682247162\n",
      "29  train loss:  0.27928876876831055\n",
      "30  train loss:  0.27760744094848633\n",
      "31  train loss:  0.2743060886859894\n",
      "32  train loss:  0.2722010016441345\n",
      "33  train loss:  0.2676040232181549\n",
      "34  train loss:  0.264622300863266\n",
      "35  train loss:  0.26114755868911743\n",
      "36  train loss:  0.2586573362350464\n",
      "37  train loss:  0.25523802638053894\n",
      "38  train loss:  0.2515156865119934\n",
      "39  train loss:  0.24890395998954773\n",
      "40  train loss:  0.2455664426088333\n",
      "41  train loss:  0.24332475662231445\n",
      "42  train loss:  0.2413499504327774\n",
      "43  train loss:  0.23942069709300995\n",
      "44  train loss:  0.23758678138256073\n",
      "45  train loss:  0.23558855056762695\n",
      "46  train loss:  0.23394399881362915\n",
      "47  train loss:  0.2319672703742981\n",
      "48  train loss:  0.23054827749729156\n",
      "49  train loss:  0.22877205908298492\n",
      "50  train loss:  0.2263832837343216\n",
      "51  train loss:  0.22324195504188538\n",
      "52  train loss:  0.2206922322511673\n",
      "53  train loss:  0.2186284214258194\n",
      "54  train loss:  0.21674583852291107\n",
      "55  train loss:  0.2147713452577591\n",
      "56  train loss:  0.21308262646198273\n",
      "57  train loss:  0.21053917706012726\n",
      "58  train loss:  0.20856353640556335\n",
      "59  train loss:  0.20626424252986908\n",
      "60  train loss:  0.20450393855571747\n",
      "61  train loss:  0.20245753228664398\n",
      "62  train loss:  0.20082835853099823\n",
      "63  train loss:  0.19879533350467682\n",
      "64  train loss:  0.19555462896823883\n",
      "65  train loss:  0.1933591365814209\n",
      "66  train loss:  0.19159160554409027\n",
      "67  train loss:  0.18994152545928955\n",
      "68  train loss:  0.18809941411018372\n",
      "69  train loss:  0.1855383813381195\n",
      "70  train loss:  0.18364283442497253\n",
      "71  train loss:  0.18216082453727722\n",
      "72  train loss:  0.1809658408164978\n",
      "73  train loss:  0.1795036494731903\n",
      "74  train loss:  0.1780727207660675\n",
      "75  train loss:  0.17670872807502747\n",
      "76  train loss:  0.17535874247550964\n",
      "77  train loss:  0.17389243841171265\n",
      "78  train loss:  0.17207889258861542\n",
      "79  train loss:  0.1699828952550888\n",
      "80  train loss:  0.1682189255952835\n",
      "81  train loss:  0.16704398393630981\n",
      "82  train loss:  0.16520754992961884\n",
      "83  train loss:  0.16344831883907318\n",
      "84  train loss:  0.1623562127351761\n",
      "85  train loss:  0.1609795242547989\n",
      "86  train loss:  0.15986603498458862\n",
      "87  train loss:  0.15847109258174896\n",
      "88  train loss:  0.15701059997081757\n",
      "89  train loss:  0.1556853950023651\n",
      "90  train loss:  0.1547834426164627\n",
      "91  train loss:  0.15382015705108643\n",
      "92  train loss:  0.15261436998844147\n",
      "93  train loss:  0.15128464996814728\n",
      "94  train loss:  0.14956127107143402\n",
      "95  train loss:  0.1484038084745407\n",
      "96  train loss:  0.14702561497688293\n",
      "97  train loss:  0.14559176564216614\n",
      "98  train loss:  0.14445118606090546\n",
      "99  train loss:  0.14314110577106476\n",
      "test acc (%):  tensor(78.4599)\n",
      "0  train loss:  0.6078757643699646\n",
      "1  train loss:  0.5518279671669006\n",
      "2  train loss:  0.49248799681663513\n",
      "3  train loss:  0.4604792892932892\n",
      "4  train loss:  0.443827360868454\n",
      "5  train loss:  0.4075581729412079\n",
      "6  train loss:  0.4151811897754669\n",
      "7  train loss:  0.4127281606197357\n",
      "8  train loss:  0.40741586685180664\n",
      "9  train loss:  0.41024380922317505\n",
      "10  train loss:  0.4084267318248749\n",
      "11  train loss:  0.39901071786880493\n",
      "12  train loss:  0.3914758265018463\n",
      "13  train loss:  0.38332250714302063\n",
      "14  train loss:  0.37671422958374023\n",
      "15  train loss:  0.37303605675697327\n",
      "16  train loss:  0.36763742566108704\n",
      "17  train loss:  0.3630390167236328\n",
      "18  train loss:  0.3597663640975952\n",
      "19  train loss:  0.3535856306552887\n",
      "20  train loss:  0.3475915491580963\n",
      "21  train loss:  0.34338295459747314\n",
      "22  train loss:  0.33961546421051025\n",
      "23  train loss:  0.33747366070747375\n",
      "24  train loss:  0.3354180157184601\n",
      "25  train loss:  0.33257248997688293\n",
      "26  train loss:  0.32961276173591614\n",
      "27  train loss:  0.3265208303928375\n",
      "28  train loss:  0.3229391574859619\n",
      "29  train loss:  0.3197195827960968\n",
      "30  train loss:  0.31715402007102966\n",
      "31  train loss:  0.31441423296928406\n",
      "32  train loss:  0.31137558817863464\n",
      "33  train loss:  0.30889254808425903\n",
      "34  train loss:  0.3061859905719757\n",
      "35  train loss:  0.30282437801361084\n",
      "36  train loss:  0.3004057705402374\n",
      "37  train loss:  0.2974909842014313\n",
      "38  train loss:  0.2946053743362427\n",
      "39  train loss:  0.29284244775772095\n",
      "40  train loss:  0.28874245285987854\n",
      "41  train loss:  0.28677570819854736\n",
      "42  train loss:  0.28289180994033813\n",
      "43  train loss:  0.2806233763694763\n",
      "44  train loss:  0.27665653824806213\n",
      "45  train loss:  0.27447226643562317\n",
      "46  train loss:  0.2713243067264557\n",
      "47  train loss:  0.26818856596946716\n",
      "48  train loss:  0.26561421155929565\n",
      "49  train loss:  0.2633900046348572\n",
      "50  train loss:  0.26103413105010986\n",
      "51  train loss:  0.2584269046783447\n",
      "52  train loss:  0.25632402300834656\n",
      "53  train loss:  0.2537876069545746\n",
      "54  train loss:  0.2517867088317871\n",
      "55  train loss:  0.24939501285552979\n",
      "56  train loss:  0.24674983322620392\n",
      "57  train loss:  0.244500532746315\n",
      "58  train loss:  0.2418481558561325\n",
      "59  train loss:  0.23912040889263153\n",
      "60  train loss:  0.23636049032211304\n",
      "61  train loss:  0.23346871137619019\n",
      "62  train loss:  0.23067675530910492\n",
      "63  train loss:  0.22773121297359467\n",
      "64  train loss:  0.2251252979040146\n",
      "65  train loss:  0.22237467765808105\n",
      "66  train loss:  0.21915611624717712\n",
      "67  train loss:  0.21669739484786987\n",
      "68  train loss:  0.21354703605175018\n",
      "69  train loss:  0.21102365851402283\n",
      "70  train loss:  0.2081267237663269\n",
      "71  train loss:  0.20508170127868652\n",
      "72  train loss:  0.2017374038696289\n",
      "73  train loss:  0.19791913032531738\n",
      "74  train loss:  0.1942102611064911\n",
      "75  train loss:  0.19043678045272827\n",
      "76  train loss:  0.18783199787139893\n",
      "77  train loss:  0.18873901665210724\n",
      "78  train loss:  0.18586651980876923\n",
      "79  train loss:  0.1822490096092224\n",
      "80  train loss:  0.17661724984645844\n",
      "81  train loss:  0.17243364453315735\n",
      "82  train loss:  0.17172940075397491\n",
      "83  train loss:  0.1707504540681839\n",
      "84  train loss:  0.16926074028015137\n",
      "85  train loss:  0.16377755999565125\n",
      "86  train loss:  0.16038207709789276\n",
      "87  train loss:  0.15900446474552155\n",
      "88  train loss:  0.15746785700321198\n",
      "89  train loss:  0.15505488216876984\n",
      "90  train loss:  0.15240658819675446\n",
      "91  train loss:  0.15111510455608368\n",
      "92  train loss:  0.15377530455589294\n",
      "93  train loss:  0.15176577866077423\n",
      "94  train loss:  0.1530011147260666\n",
      "95  train loss:  0.1477709710597992\n",
      "96  train loss:  0.1423114389181137\n",
      "97  train loss:  0.13855576515197754\n",
      "98  train loss:  0.13679330050945282\n",
      "99  train loss:  0.13998864591121674\n",
      "test acc (%):  tensor(78.2680)\n",
      "0  train loss:  0.5135127305984497\n",
      "1  train loss:  0.4753456711769104\n",
      "2  train loss:  0.43823492527008057\n",
      "3  train loss:  0.3986344635486603\n",
      "4  train loss:  0.37884825468063354\n",
      "5  train loss:  0.3622224032878876\n",
      "6  train loss:  0.3568073511123657\n",
      "7  train loss:  0.35046976804733276\n",
      "8  train loss:  0.34662869572639465\n",
      "9  train loss:  0.3435972034931183\n",
      "10  train loss:  0.3366175591945648\n",
      "11  train loss:  0.32921770215034485\n",
      "12  train loss:  0.32456937432289124\n",
      "13  train loss:  0.3168698847293854\n",
      "14  train loss:  0.3080841600894928\n",
      "15  train loss:  0.29947787523269653\n",
      "16  train loss:  0.2913612425327301\n",
      "17  train loss:  0.2847307324409485\n",
      "18  train loss:  0.27954041957855225\n",
      "19  train loss:  0.2741274833679199\n",
      "20  train loss:  0.26942530274391174\n",
      "21  train loss:  0.2666737735271454\n",
      "22  train loss:  0.26163536310195923\n",
      "23  train loss:  0.25601983070373535\n",
      "24  train loss:  0.25217199325561523\n",
      "25  train loss:  0.24887579679489136\n",
      "26  train loss:  0.2449502944946289\n",
      "27  train loss:  0.2404746115207672\n",
      "28  train loss:  0.23651228845119476\n",
      "29  train loss:  0.23288202285766602\n",
      "30  train loss:  0.22921501100063324\n",
      "31  train loss:  0.22543302178382874\n",
      "32  train loss:  0.22143009305000305\n",
      "33  train loss:  0.21775516867637634\n",
      "34  train loss:  0.21390405297279358\n",
      "35  train loss:  0.21011561155319214\n",
      "36  train loss:  0.20691440999507904\n",
      "37  train loss:  0.20403876900672913\n",
      "38  train loss:  0.2010369598865509\n",
      "39  train loss:  0.1974959820508957\n",
      "40  train loss:  0.1940860152244568\n",
      "41  train loss:  0.19055591523647308\n",
      "42  train loss:  0.18683907389640808\n",
      "43  train loss:  0.18283678591251373\n",
      "44  train loss:  0.1794855147600174\n",
      "45  train loss:  0.1767444759607315\n",
      "46  train loss:  0.174385666847229\n",
      "47  train loss:  0.17236623167991638\n",
      "48  train loss:  0.16990306973457336\n",
      "49  train loss:  0.1681404709815979\n",
      "50  train loss:  0.16598069667816162\n",
      "51  train loss:  0.1641152948141098\n",
      "52  train loss:  0.16172125935554504\n",
      "53  train loss:  0.15983152389526367\n",
      "54  train loss:  0.15717780590057373\n",
      "55  train loss:  0.15467572212219238\n",
      "56  train loss:  0.1525709182024002\n",
      "57  train loss:  0.15099813044071198\n",
      "58  train loss:  0.14894190430641174\n",
      "59  train loss:  0.14754435420036316\n",
      "60  train loss:  0.1459653079509735\n",
      "61  train loss:  0.14427274465560913\n",
      "62  train loss:  0.14315858483314514\n",
      "63  train loss:  0.14137603342533112\n",
      "64  train loss:  0.13953697681427002\n",
      "65  train loss:  0.13772575557231903\n",
      "66  train loss:  0.1361113041639328\n",
      "67  train loss:  0.13472996652126312\n",
      "68  train loss:  0.13234394788742065\n",
      "69  train loss:  0.13061055541038513\n",
      "70  train loss:  0.1293584555387497\n",
      "71  train loss:  0.12768346071243286\n",
      "72  train loss:  0.12660843133926392\n",
      "73  train loss:  0.12501658499240875\n",
      "74  train loss:  0.12405653297901154\n",
      "75  train loss:  0.12224780768156052\n",
      "76  train loss:  0.12121502310037613\n",
      "77  train loss:  0.11987198889255524\n",
      "78  train loss:  0.11884621530771255\n",
      "79  train loss:  0.1168992891907692\n",
      "80  train loss:  0.1149325892329216\n",
      "81  train loss:  0.11236928403377533\n",
      "82  train loss:  0.10962847620248795\n",
      "83  train loss:  0.10816500335931778\n",
      "84  train loss:  0.10691601783037186\n",
      "85  train loss:  0.10542383044958115\n",
      "86  train loss:  0.10415595769882202\n",
      "87  train loss:  0.10465431213378906\n",
      "88  train loss:  0.10468708723783493\n",
      "89  train loss:  0.10250914096832275\n",
      "90  train loss:  0.10105159878730774\n",
      "91  train loss:  0.09941273182630539\n",
      "92  train loss:  0.09751980006694794\n",
      "93  train loss:  0.09887206554412842\n",
      "94  train loss:  0.09764453768730164\n",
      "95  train loss:  0.09736591577529907\n",
      "96  train loss:  0.09700465947389603\n",
      "97  train loss:  0.0957280695438385\n",
      "98  train loss:  0.09291846305131912\n",
      "99  train loss:  0.09486252814531326\n",
      "test acc (%):  tensor(78.5147)\n",
      "0  train loss:  0.721405565738678\n",
      "1  train loss:  0.6488195657730103\n",
      "2  train loss:  0.5459277033805847\n",
      "3  train loss:  0.4976903796195984\n",
      "4  train loss:  0.5009168982505798\n",
      "5  train loss:  0.44042930006980896\n",
      "6  train loss:  0.4039765000343323\n",
      "7  train loss:  0.3937147557735443\n",
      "8  train loss:  0.39332321286201477\n",
      "9  train loss:  0.40082845091819763\n",
      "10  train loss:  0.39822912216186523\n",
      "11  train loss:  0.3889238238334656\n",
      "12  train loss:  0.382785439491272\n",
      "13  train loss:  0.37595540285110474\n",
      "14  train loss:  0.36590319871902466\n",
      "15  train loss:  0.35977497696876526\n",
      "16  train loss:  0.3520852327346802\n",
      "17  train loss:  0.3400701880455017\n",
      "18  train loss:  0.329296737909317\n",
      "19  train loss:  0.3202839195728302\n",
      "20  train loss:  0.3121189475059509\n",
      "21  train loss:  0.30608826875686646\n",
      "22  train loss:  0.30288776755332947\n",
      "23  train loss:  0.30000367760658264\n",
      "24  train loss:  0.2969999313354492\n",
      "25  train loss:  0.29466336965560913\n",
      "26  train loss:  0.29014864563941956\n",
      "27  train loss:  0.2857316732406616\n",
      "28  train loss:  0.28182438015937805\n",
      "29  train loss:  0.27754342555999756\n",
      "30  train loss:  0.27535831928253174\n",
      "31  train loss:  0.2716907262802124\n",
      "32  train loss:  0.26923513412475586\n",
      "33  train loss:  0.26559874415397644\n",
      "34  train loss:  0.26278218626976013\n",
      "35  train loss:  0.2590249478816986\n",
      "36  train loss:  0.255866676568985\n",
      "37  train loss:  0.2527017593383789\n",
      "38  train loss:  0.25016191601753235\n",
      "39  train loss:  0.24684882164001465\n",
      "40  train loss:  0.24414381384849548\n",
      "41  train loss:  0.24083825945854187\n",
      "42  train loss:  0.23836404085159302\n",
      "43  train loss:  0.23550322651863098\n",
      "44  train loss:  0.2331429272890091\n",
      "45  train loss:  0.2303439974784851\n",
      "46  train loss:  0.2282065451145172\n",
      "47  train loss:  0.2257276475429535\n",
      "48  train loss:  0.22396597266197205\n",
      "49  train loss:  0.22139421105384827\n",
      "50  train loss:  0.2201509028673172\n",
      "51  train loss:  0.21698810160160065\n",
      "52  train loss:  0.2158348560333252\n",
      "53  train loss:  0.21251222491264343\n",
      "54  train loss:  0.210897296667099\n",
      "55  train loss:  0.20834830403327942\n",
      "56  train loss:  0.20703306794166565\n",
      "57  train loss:  0.20542249083518982\n",
      "58  train loss:  0.20351526141166687\n",
      "59  train loss:  0.20197123289108276\n",
      "60  train loss:  0.2002825140953064\n",
      "61  train loss:  0.19848798215389252\n",
      "62  train loss:  0.1967969685792923\n",
      "63  train loss:  0.1954098641872406\n",
      "64  train loss:  0.19385358691215515\n",
      "65  train loss:  0.19225305318832397\n",
      "66  train loss:  0.19075274467468262\n",
      "67  train loss:  0.18923111259937286\n",
      "68  train loss:  0.18750794231891632\n",
      "69  train loss:  0.18607936799526215\n",
      "70  train loss:  0.18477347493171692\n",
      "71  train loss:  0.18276247382164001\n",
      "72  train loss:  0.18139542639255524\n",
      "73  train loss:  0.18002569675445557\n",
      "74  train loss:  0.1787935346364975\n",
      "75  train loss:  0.17752985656261444\n",
      "76  train loss:  0.17664556205272675\n",
      "77  train loss:  0.17590749263763428\n",
      "78  train loss:  0.1745302975177765\n",
      "79  train loss:  0.17368055880069733\n",
      "80  train loss:  0.17230883240699768\n",
      "81  train loss:  0.17137411236763\n",
      "82  train loss:  0.1704605519771576\n",
      "83  train loss:  0.1693314164876938\n",
      "84  train loss:  0.16835923492908478\n",
      "85  train loss:  0.16745169460773468\n",
      "86  train loss:  0.1664566546678543\n",
      "87  train loss:  0.16548889875411987\n",
      "88  train loss:  0.1648847609758377\n",
      "89  train loss:  0.16407905519008636\n",
      "90  train loss:  0.16286419332027435\n",
      "91  train loss:  0.16235457360744476\n",
      "92  train loss:  0.1610984057188034\n",
      "93  train loss:  0.1601407527923584\n",
      "94  train loss:  0.15901575982570648\n",
      "95  train loss:  0.1576874852180481\n",
      "96  train loss:  0.15692748129367828\n",
      "97  train loss:  0.15584717690944672\n",
      "98  train loss:  0.15493141114711761\n",
      "99  train loss:  0.15372636914253235\n",
      "test acc (%):  tensor(79.2272)\n",
      "0  train loss:  0.5828816294670105\n",
      "1  train loss:  0.45977723598480225\n",
      "2  train loss:  0.40756919980049133\n",
      "3  train loss:  0.37519699335098267\n",
      "4  train loss:  0.357256144285202\n",
      "5  train loss:  0.34471797943115234\n",
      "6  train loss:  0.33189836144447327\n",
      "7  train loss:  0.32366490364074707\n",
      "8  train loss:  0.322162389755249\n",
      "9  train loss:  0.3206176459789276\n",
      "10  train loss:  0.31921079754829407\n",
      "11  train loss:  0.31319427490234375\n",
      "12  train loss:  0.3027973175048828\n",
      "13  train loss:  0.29774436354637146\n",
      "14  train loss:  0.2905673682689667\n",
      "15  train loss:  0.28318238258361816\n",
      "16  train loss:  0.2820507287979126\n",
      "17  train loss:  0.2789899408817291\n",
      "18  train loss:  0.27136409282684326\n",
      "19  train loss:  0.2667003571987152\n",
      "20  train loss:  0.2593834400177002\n",
      "21  train loss:  0.2543891370296478\n",
      "22  train loss:  0.25032439827919006\n",
      "23  train loss:  0.24520325660705566\n",
      "24  train loss:  0.24181346595287323\n",
      "25  train loss:  0.2377825230360031\n",
      "26  train loss:  0.23376137018203735\n",
      "27  train loss:  0.23100830614566803\n",
      "28  train loss:  0.22706784307956696\n",
      "29  train loss:  0.22272194921970367\n",
      "30  train loss:  0.2185547947883606\n",
      "31  train loss:  0.2139430046081543\n",
      "32  train loss:  0.21136261522769928\n",
      "33  train loss:  0.20869913697242737\n",
      "34  train loss:  0.20559251308441162\n",
      "35  train loss:  0.20219822227954865\n",
      "36  train loss:  0.19885750114917755\n",
      "37  train loss:  0.19576974213123322\n",
      "38  train loss:  0.19229507446289062\n",
      "39  train loss:  0.18887217342853546\n",
      "40  train loss:  0.1858256757259369\n",
      "41  train loss:  0.18344971537590027\n",
      "42  train loss:  0.1810505986213684\n",
      "43  train loss:  0.17900608479976654\n",
      "44  train loss:  0.1766442209482193\n",
      "45  train loss:  0.1741226762533188\n",
      "46  train loss:  0.17168496549129486\n",
      "47  train loss:  0.1690179854631424\n",
      "48  train loss:  0.16666559875011444\n",
      "49  train loss:  0.1641935557126999\n",
      "50  train loss:  0.1621047556400299\n",
      "51  train loss:  0.1595347672700882\n",
      "52  train loss:  0.15716224908828735\n",
      "53  train loss:  0.1548231691122055\n",
      "54  train loss:  0.15285101532936096\n",
      "55  train loss:  0.15054954588413239\n",
      "56  train loss:  0.14848941564559937\n",
      "57  train loss:  0.146206796169281\n",
      "58  train loss:  0.14414305984973907\n",
      "59  train loss:  0.14160287380218506\n",
      "60  train loss:  0.13987067341804504\n",
      "61  train loss:  0.13793028891086578\n",
      "62  train loss:  0.13596965372562408\n",
      "63  train loss:  0.13404998183250427\n",
      "64  train loss:  0.13245640695095062\n",
      "65  train loss:  0.1305694878101349\n",
      "66  train loss:  0.129039466381073\n",
      "67  train loss:  0.1273125559091568\n",
      "68  train loss:  0.12567733228206635\n",
      "69  train loss:  0.12393391877412796\n",
      "70  train loss:  0.12211331725120544\n",
      "71  train loss:  0.12016887962818146\n",
      "72  train loss:  0.11830240488052368\n",
      "73  train loss:  0.11633319407701492\n",
      "74  train loss:  0.11433389037847519\n",
      "75  train loss:  0.11228945851325989\n",
      "76  train loss:  0.11012284457683563\n",
      "77  train loss:  0.10821366310119629\n",
      "78  train loss:  0.10639408975839615\n",
      "79  train loss:  0.10483961552381516\n",
      "80  train loss:  0.10339002311229706\n",
      "81  train loss:  0.10215503722429276\n",
      "82  train loss:  0.10063036531209946\n",
      "83  train loss:  0.09927919507026672\n",
      "84  train loss:  0.09786370396614075\n",
      "85  train loss:  0.09637951850891113\n",
      "86  train loss:  0.09524033218622208\n",
      "87  train loss:  0.09378886222839355\n",
      "88  train loss:  0.09250464290380478\n",
      "89  train loss:  0.09128738194704056\n",
      "90  train loss:  0.09028736501932144\n",
      "91  train loss:  0.0893305167555809\n",
      "92  train loss:  0.0883820429444313\n",
      "93  train loss:  0.08750680088996887\n",
      "94  train loss:  0.08663436770439148\n",
      "95  train loss:  0.0857492983341217\n",
      "96  train loss:  0.08493692427873611\n",
      "97  train loss:  0.08410653471946716\n",
      "98  train loss:  0.08330544829368591\n",
      "99  train loss:  0.08258352428674698\n",
      "test acc (%):  tensor(79.6657)\n",
      "0  train loss:  0.6732699275016785\n",
      "1  train loss:  0.5982891917228699\n",
      "2  train loss:  0.5207225680351257\n",
      "3  train loss:  0.4586718678474426\n",
      "4  train loss:  0.4526253640651703\n",
      "5  train loss:  0.41135790944099426\n",
      "6  train loss:  0.3865653872489929\n",
      "7  train loss:  0.3724071979522705\n",
      "8  train loss:  0.3734830915927887\n",
      "9  train loss:  0.3584028482437134\n",
      "10  train loss:  0.3441730737686157\n",
      "11  train loss:  0.33229073882102966\n",
      "12  train loss:  0.322345495223999\n",
      "13  train loss:  0.3241816461086273\n",
      "14  train loss:  0.3210107386112213\n",
      "15  train loss:  0.3113042116165161\n",
      "16  train loss:  0.3014336824417114\n",
      "17  train loss:  0.29255199432373047\n",
      "18  train loss:  0.285756915807724\n",
      "19  train loss:  0.2836765646934509\n",
      "20  train loss:  0.278487890958786\n",
      "21  train loss:  0.27395254373550415\n",
      "22  train loss:  0.266474187374115\n",
      "23  train loss:  0.2588321268558502\n",
      "24  train loss:  0.25489774346351624\n",
      "25  train loss:  0.24999389052391052\n",
      "26  train loss:  0.24678736925125122\n",
      "27  train loss:  0.24311606585979462\n",
      "28  train loss:  0.2391207218170166\n",
      "29  train loss:  0.23446691036224365\n",
      "30  train loss:  0.23079954087734222\n",
      "31  train loss:  0.22816862165927887\n",
      "32  train loss:  0.22445730865001678\n",
      "33  train loss:  0.2218860536813736\n",
      "34  train loss:  0.21829861402511597\n",
      "35  train loss:  0.21472704410552979\n",
      "36  train loss:  0.21110032498836517\n",
      "37  train loss:  0.20772533118724823\n",
      "38  train loss:  0.20383289456367493\n",
      "39  train loss:  0.20027558505535126\n",
      "40  train loss:  0.19663918018341064\n",
      "41  train loss:  0.19288530945777893\n",
      "42  train loss:  0.18949933350086212\n",
      "43  train loss:  0.18592651188373566\n",
      "44  train loss:  0.18370205163955688\n",
      "45  train loss:  0.18073955178260803\n",
      "46  train loss:  0.17809641361236572\n",
      "47  train loss:  0.17530472576618195\n",
      "48  train loss:  0.17327335476875305\n",
      "49  train loss:  0.17068326473236084\n",
      "50  train loss:  0.16822127997875214\n",
      "51  train loss:  0.16549915075302124\n",
      "52  train loss:  0.16361801326274872\n",
      "53  train loss:  0.16169080138206482\n",
      "54  train loss:  0.15976616740226746\n",
      "55  train loss:  0.15781046450138092\n",
      "56  train loss:  0.15598183870315552\n",
      "57  train loss:  0.154034823179245\n",
      "58  train loss:  0.15180987119674683\n",
      "59  train loss:  0.14974288642406464\n",
      "60  train loss:  0.146815225481987\n",
      "61  train loss:  0.14503350853919983\n",
      "62  train loss:  0.1427524983882904\n",
      "63  train loss:  0.14091449975967407\n",
      "64  train loss:  0.13902312517166138\n",
      "65  train loss:  0.13704271614551544\n",
      "66  train loss:  0.13546150922775269\n",
      "67  train loss:  0.13357077538967133\n",
      "68  train loss:  0.13184769451618195\n",
      "69  train loss:  0.12997356057167053\n",
      "70  train loss:  0.1284254789352417\n",
      "71  train loss:  0.1268785148859024\n",
      "72  train loss:  0.12555669248104095\n",
      "73  train loss:  0.1242155134677887\n",
      "74  train loss:  0.12294219434261322\n",
      "75  train loss:  0.12174125015735626\n",
      "76  train loss:  0.1205134466290474\n",
      "77  train loss:  0.11929257959127426\n",
      "78  train loss:  0.11814423650503159\n",
      "79  train loss:  0.117055743932724\n",
      "80  train loss:  0.11606155335903168\n",
      "81  train loss:  0.11492780596017838\n",
      "82  train loss:  0.11392349749803543\n",
      "83  train loss:  0.11299683153629303\n",
      "84  train loss:  0.1119479387998581\n",
      "85  train loss:  0.11068811267614365\n",
      "86  train loss:  0.10937100648880005\n",
      "87  train loss:  0.10749342292547226\n",
      "88  train loss:  0.10649548470973969\n",
      "89  train loss:  0.10546411573886871\n",
      "90  train loss:  0.1047377735376358\n",
      "91  train loss:  0.1035323515534401\n",
      "92  train loss:  0.10267151892185211\n",
      "93  train loss:  0.1015610471367836\n",
      "94  train loss:  0.10079223662614822\n",
      "95  train loss:  0.09964226186275482\n",
      "96  train loss:  0.09861727803945541\n",
      "97  train loss:  0.09788896888494492\n",
      "98  train loss:  0.0971619263291359\n",
      "99  train loss:  0.09617050737142563\n",
      "test acc (%):  tensor(79.1450)\n",
      "0  train loss:  0.8404057621955872\n",
      "1  train loss:  0.668398916721344\n",
      "2  train loss:  0.5721574425697327\n",
      "3  train loss:  0.5339272022247314\n",
      "4  train loss:  0.4830150008201599\n",
      "5  train loss:  0.43545401096343994\n",
      "6  train loss:  0.40233880281448364\n",
      "7  train loss:  0.39139702916145325\n",
      "8  train loss:  0.3954046666622162\n",
      "9  train loss:  0.40769556164741516\n",
      "10  train loss:  0.400954931974411\n",
      "11  train loss:  0.3829297423362732\n",
      "12  train loss:  0.36520615220069885\n",
      "13  train loss:  0.35272860527038574\n",
      "14  train loss:  0.3466288447380066\n",
      "15  train loss:  0.3350217640399933\n",
      "16  train loss:  0.3252473473548889\n",
      "17  train loss:  0.3186081349849701\n",
      "18  train loss:  0.3111967444419861\n",
      "19  train loss:  0.3040626347064972\n",
      "20  train loss:  0.3000967800617218\n",
      "21  train loss:  0.2985104024410248\n",
      "22  train loss:  0.2958182394504547\n",
      "23  train loss:  0.2915842533111572\n",
      "24  train loss:  0.2863694429397583\n",
      "25  train loss:  0.2817624807357788\n",
      "26  train loss:  0.27681154012680054\n",
      "27  train loss:  0.27325159311294556\n",
      "28  train loss:  0.2712600827217102\n",
      "29  train loss:  0.267965167760849\n",
      "30  train loss:  0.26390495896339417\n",
      "31  train loss:  0.26056912541389465\n",
      "32  train loss:  0.25799867510795593\n",
      "33  train loss:  0.2554098069667816\n",
      "34  train loss:  0.2516493797302246\n",
      "35  train loss:  0.24817855656147003\n",
      "36  train loss:  0.24464741349220276\n",
      "37  train loss:  0.24159753322601318\n",
      "38  train loss:  0.23926113545894623\n",
      "39  train loss:  0.23678381741046906\n",
      "40  train loss:  0.23444993793964386\n",
      "41  train loss:  0.23189596831798553\n",
      "42  train loss:  0.22933997213840485\n",
      "43  train loss:  0.22687111794948578\n",
      "44  train loss:  0.22438715398311615\n",
      "45  train loss:  0.2218838781118393\n",
      "46  train loss:  0.2182491570711136\n",
      "47  train loss:  0.21587365865707397\n",
      "48  train loss:  0.21342024207115173\n",
      "49  train loss:  0.21081018447875977\n",
      "50  train loss:  0.20888324081897736\n",
      "51  train loss:  0.20698700845241547\n",
      "52  train loss:  0.20511022210121155\n",
      "53  train loss:  0.2028990387916565\n",
      "54  train loss:  0.20069201290607452\n",
      "55  train loss:  0.19853603839874268\n",
      "56  train loss:  0.19660085439682007\n",
      "57  train loss:  0.19426999986171722\n",
      "58  train loss:  0.19261550903320312\n",
      "59  train loss:  0.19033175706863403\n",
      "60  train loss:  0.18830178678035736\n",
      "61  train loss:  0.18603989481925964\n",
      "62  train loss:  0.18391546607017517\n",
      "63  train loss:  0.18131934106349945\n",
      "64  train loss:  0.1794390231370926\n",
      "65  train loss:  0.17645440995693207\n",
      "66  train loss:  0.17399519681930542\n",
      "67  train loss:  0.17153982818126678\n",
      "68  train loss:  0.1692080944776535\n",
      "69  train loss:  0.16684910655021667\n",
      "70  train loss:  0.16471877694129944\n",
      "71  train loss:  0.16247452795505524\n",
      "72  train loss:  0.1602247953414917\n",
      "73  train loss:  0.15828394889831543\n",
      "74  train loss:  0.156794011592865\n",
      "75  train loss:  0.15521645545959473\n",
      "76  train loss:  0.15386345982551575\n",
      "77  train loss:  0.15291078388690948\n",
      "78  train loss:  0.1506694108247757\n",
      "79  train loss:  0.15074412524700165\n",
      "80  train loss:  0.15444809198379517\n",
      "81  train loss:  0.15380360186100006\n",
      "82  train loss:  0.15015940368175507\n",
      "83  train loss:  0.14776501059532166\n",
      "84  train loss:  0.15398968756198883\n",
      "85  train loss:  0.1424262374639511\n",
      "86  train loss:  0.1439952850341797\n",
      "87  train loss:  0.14437995851039886\n",
      "88  train loss:  0.14463593065738678\n",
      "89  train loss:  0.142185777425766\n",
      "90  train loss:  0.13999849557876587\n",
      "91  train loss:  0.1374538540840149\n",
      "92  train loss:  0.13450460135936737\n",
      "93  train loss:  0.13226792216300964\n",
      "94  train loss:  0.12942524254322052\n",
      "95  train loss:  0.12761090695858002\n",
      "96  train loss:  0.12749308347702026\n",
      "97  train loss:  0.12403998523950577\n",
      "98  train loss:  0.12415740638971329\n",
      "99  train loss:  0.12313254922628403\n",
      "test acc (%):  tensor(79.2546)\n",
      "0  train loss:  0.634823203086853\n",
      "1  train loss:  0.5542237162590027\n",
      "2  train loss:  0.4713420569896698\n",
      "3  train loss:  0.42743563652038574\n",
      "4  train loss:  0.39300107955932617\n",
      "5  train loss:  0.36448487639427185\n",
      "6  train loss:  0.35565459728240967\n",
      "7  train loss:  0.35080331563949585\n",
      "8  train loss:  0.33722883462905884\n",
      "9  train loss:  0.3259304463863373\n",
      "10  train loss:  0.3229926526546478\n",
      "11  train loss:  0.3115744888782501\n",
      "12  train loss:  0.30344006419181824\n",
      "13  train loss:  0.3005315363407135\n",
      "14  train loss:  0.3006654381752014\n",
      "15  train loss:  0.2963767647743225\n",
      "16  train loss:  0.2928873896598816\n",
      "17  train loss:  0.28290873765945435\n",
      "18  train loss:  0.27814924716949463\n",
      "19  train loss:  0.2726891338825226\n",
      "20  train loss:  0.2637529671192169\n",
      "21  train loss:  0.2608412206172943\n",
      "22  train loss:  0.25588229298591614\n",
      "23  train loss:  0.25158506631851196\n",
      "24  train loss:  0.24934038519859314\n",
      "25  train loss:  0.2440766543149948\n",
      "26  train loss:  0.24052487313747406\n",
      "27  train loss:  0.23657912015914917\n",
      "28  train loss:  0.2317224144935608\n",
      "29  train loss:  0.22868478298187256\n",
      "30  train loss:  0.22423548996448517\n",
      "31  train loss:  0.22070468962192535\n",
      "32  train loss:  0.21776247024536133\n",
      "33  train loss:  0.2139502316713333\n",
      "34  train loss:  0.2112007588148117\n",
      "35  train loss:  0.20773598551750183\n",
      "36  train loss:  0.2042088508605957\n",
      "37  train loss:  0.20153957605361938\n",
      "38  train loss:  0.19900406897068024\n",
      "39  train loss:  0.19659718871116638\n",
      "40  train loss:  0.19441434741020203\n",
      "41  train loss:  0.19230616092681885\n",
      "42  train loss:  0.18960173428058624\n",
      "43  train loss:  0.1871740072965622\n",
      "44  train loss:  0.18503442406654358\n",
      "45  train loss:  0.18260416388511658\n",
      "46  train loss:  0.1804889440536499\n",
      "47  train loss:  0.17825888097286224\n",
      "48  train loss:  0.17540974915027618\n",
      "49  train loss:  0.1729818880558014\n",
      "50  train loss:  0.17073602974414825\n",
      "51  train loss:  0.16900666058063507\n",
      "52  train loss:  0.16735340654850006\n",
      "53  train loss:  0.16563592851161957\n",
      "54  train loss:  0.16389550268650055\n",
      "55  train loss:  0.162086620926857\n",
      "56  train loss:  0.1604195386171341\n",
      "57  train loss:  0.15908664464950562\n",
      "58  train loss:  0.1576014906167984\n",
      "59  train loss:  0.1559184044599533\n",
      "60  train loss:  0.15477842092514038\n",
      "61  train loss:  0.1530485898256302\n",
      "62  train loss:  0.15113785862922668\n",
      "63  train loss:  0.14966155588626862\n",
      "64  train loss:  0.14783760905265808\n",
      "65  train loss:  0.14648140966892242\n",
      "66  train loss:  0.1450861245393753\n",
      "67  train loss:  0.14341524243354797\n",
      "68  train loss:  0.14247475564479828\n",
      "69  train loss:  0.1410377025604248\n",
      "70  train loss:  0.1393960565328598\n",
      "71  train loss:  0.13847440481185913\n",
      "72  train loss:  0.13737265765666962\n",
      "73  train loss:  0.13616694509983063\n",
      "74  train loss:  0.13512791693210602\n",
      "75  train loss:  0.13389062881469727\n",
      "76  train loss:  0.13268887996673584\n",
      "77  train loss:  0.131398007273674\n",
      "78  train loss:  0.13001424074172974\n",
      "79  train loss:  0.12872585654258728\n",
      "80  train loss:  0.1272616684436798\n",
      "81  train loss:  0.12599177658557892\n",
      "82  train loss:  0.12489835172891617\n",
      "83  train loss:  0.12370570749044418\n",
      "84  train loss:  0.1226363256573677\n",
      "85  train loss:  0.12149068713188171\n",
      "86  train loss:  0.1202043890953064\n",
      "87  train loss:  0.11886058002710342\n",
      "88  train loss:  0.11756173521280289\n",
      "89  train loss:  0.11631867289543152\n",
      "90  train loss:  0.11523269861936569\n",
      "91  train loss:  0.11411679536104202\n",
      "92  train loss:  0.11312173306941986\n",
      "93  train loss:  0.11219220608472824\n",
      "94  train loss:  0.1111719161272049\n",
      "95  train loss:  0.11010332405567169\n",
      "96  train loss:  0.10895230621099472\n",
      "97  train loss:  0.10771778970956802\n",
      "98  train loss:  0.10647569596767426\n",
      "99  train loss:  0.10522729158401489\n",
      "test acc (%):  tensor(78.0488)\n",
      "0  train loss:  0.6563680171966553\n",
      "1  train loss:  0.5864840149879456\n",
      "2  train loss:  0.5244128704071045\n",
      "3  train loss:  0.4457560181617737\n",
      "4  train loss:  0.3762423098087311\n",
      "5  train loss:  0.3816516101360321\n",
      "6  train loss:  0.3361363708972931\n",
      "7  train loss:  0.34600815176963806\n",
      "8  train loss:  0.3332373797893524\n",
      "9  train loss:  0.3185604214668274\n",
      "10  train loss:  0.30727988481521606\n",
      "11  train loss:  0.3029325306415558\n",
      "12  train loss:  0.29075250029563904\n",
      "13  train loss:  0.28447192907333374\n",
      "14  train loss:  0.2804420590400696\n",
      "15  train loss:  0.27600088715553284\n",
      "16  train loss:  0.2663268744945526\n",
      "17  train loss:  0.259831041097641\n",
      "18  train loss:  0.25587934255599976\n",
      "19  train loss:  0.2475506067276001\n",
      "20  train loss:  0.2409781664609909\n",
      "21  train loss:  0.23743407428264618\n",
      "22  train loss:  0.23393793404102325\n",
      "23  train loss:  0.22924207150936127\n",
      "24  train loss:  0.22391211986541748\n",
      "25  train loss:  0.21943403780460358\n",
      "26  train loss:  0.21586547791957855\n",
      "27  train loss:  0.21217939257621765\n",
      "28  train loss:  0.2078629434108734\n",
      "29  train loss:  0.2043178230524063\n",
      "30  train loss:  0.20095239579677582\n",
      "31  train loss:  0.19679318368434906\n",
      "32  train loss:  0.19370463490486145\n",
      "33  train loss:  0.19106043875217438\n",
      "34  train loss:  0.18873974680900574\n",
      "35  train loss:  0.1860881894826889\n",
      "36  train loss:  0.18363916873931885\n",
      "37  train loss:  0.1810082048177719\n",
      "38  train loss:  0.17883223295211792\n",
      "39  train loss:  0.1766522228717804\n",
      "40  train loss:  0.17429639399051666\n",
      "41  train loss:  0.17254523932933807\n",
      "42  train loss:  0.1708701252937317\n",
      "43  train loss:  0.16862936317920685\n",
      "44  train loss:  0.16676151752471924\n",
      "45  train loss:  0.16506610810756683\n",
      "46  train loss:  0.16337332129478455\n",
      "47  train loss:  0.1613350808620453\n",
      "48  train loss:  0.15950919687747955\n",
      "49  train loss:  0.15873008966445923\n",
      "50  train loss:  0.1570960134267807\n",
      "51  train loss:  0.15487954020500183\n",
      "52  train loss:  0.15414640307426453\n",
      "53  train loss:  0.15458722412586212\n",
      "54  train loss:  0.151145800948143\n",
      "55  train loss:  0.15035654604434967\n",
      "56  train loss:  0.1497318148612976\n",
      "57  train loss:  0.14697103202342987\n",
      "58  train loss:  0.14670239388942719\n",
      "59  train loss:  0.14559347927570343\n",
      "60  train loss:  0.14276394248008728\n",
      "61  train loss:  0.14411494135856628\n",
      "62  train loss:  0.14289897680282593\n",
      "63  train loss:  0.13851501047611237\n",
      "64  train loss:  0.14207486808300018\n",
      "65  train loss:  0.14057061076164246\n",
      "66  train loss:  0.13516250252723694\n",
      "67  train loss:  0.13817696273326874\n",
      "68  train loss:  0.133696049451828\n",
      "69  train loss:  0.13203123211860657\n",
      "70  train loss:  0.13238762319087982\n",
      "71  train loss:  0.12829871475696564\n",
      "72  train loss:  0.1282041072845459\n",
      "73  train loss:  0.12435384094715118\n",
      "74  train loss:  0.1241263821721077\n",
      "75  train loss:  0.12280892580747604\n",
      "76  train loss:  0.11977541446685791\n",
      "77  train loss:  0.11798752844333649\n",
      "78  train loss:  0.11663763970136642\n",
      "79  train loss:  0.11485809087753296\n",
      "80  train loss:  0.11356314271688461\n",
      "81  train loss:  0.11267798393964767\n",
      "82  train loss:  0.11175055056810379\n",
      "83  train loss:  0.11039397120475769\n",
      "84  train loss:  0.10959603637456894\n",
      "85  train loss:  0.10847530514001846\n",
      "86  train loss:  0.10758288949728012\n",
      "87  train loss:  0.1072595939040184\n",
      "88  train loss:  0.1059630960226059\n",
      "89  train loss:  0.10486150532960892\n",
      "90  train loss:  0.104352205991745\n",
      "91  train loss:  0.10339711606502533\n",
      "92  train loss:  0.10263684391975403\n",
      "93  train loss:  0.10199883580207825\n",
      "94  train loss:  0.10139200091362\n",
      "95  train loss:  0.10068567097187042\n",
      "96  train loss:  0.10010197758674622\n",
      "97  train loss:  0.09950065612792969\n",
      "98  train loss:  0.09880058467388153\n",
      "99  train loss:  0.09836623817682266\n",
      "test acc (%):  tensor(77.6925)\n",
      "0  train loss:  0.7732229828834534\n",
      "1  train loss:  0.6242143511772156\n",
      "2  train loss:  0.5358424186706543\n",
      "3  train loss:  0.4866794943809509\n",
      "4  train loss:  0.46528908610343933\n",
      "5  train loss:  0.4097195267677307\n",
      "6  train loss:  0.38465288281440735\n",
      "7  train loss:  0.3653796315193176\n",
      "8  train loss:  0.3610213100910187\n",
      "9  train loss:  0.35056638717651367\n",
      "10  train loss:  0.3385083079338074\n",
      "11  train loss:  0.3375585377216339\n",
      "12  train loss:  0.3319914937019348\n",
      "13  train loss:  0.3303479850292206\n",
      "14  train loss:  0.32811421155929565\n",
      "15  train loss:  0.32088154554367065\n",
      "16  train loss:  0.3152737617492676\n",
      "17  train loss:  0.30674880743026733\n",
      "18  train loss:  0.29641979932785034\n",
      "19  train loss:  0.28803500533103943\n",
      "20  train loss:  0.27921900153160095\n",
      "21  train loss:  0.2703084945678711\n",
      "22  train loss:  0.26282817125320435\n",
      "23  train loss:  0.25500887632369995\n",
      "24  train loss:  0.24837930500507355\n",
      "25  train loss:  0.24312610924243927\n",
      "26  train loss:  0.23806051909923553\n",
      "27  train loss:  0.23242256045341492\n",
      "28  train loss:  0.22855055332183838\n",
      "29  train loss:  0.2235114574432373\n",
      "30  train loss:  0.22005802392959595\n",
      "31  train loss:  0.2150966227054596\n",
      "32  train loss:  0.2100980281829834\n",
      "33  train loss:  0.20711922645568848\n",
      "34  train loss:  0.2032795548439026\n",
      "35  train loss:  0.20092269778251648\n",
      "36  train loss:  0.19783534109592438\n",
      "37  train loss:  0.19572554528713226\n",
      "38  train loss:  0.19393907487392426\n",
      "39  train loss:  0.19304046034812927\n",
      "40  train loss:  0.19186770915985107\n",
      "41  train loss:  0.18995963037014008\n",
      "42  train loss:  0.18815818428993225\n",
      "43  train loss:  0.1868942528963089\n",
      "44  train loss:  0.1850869059562683\n",
      "45  train loss:  0.18290705978870392\n",
      "46  train loss:  0.17975902557373047\n",
      "47  train loss:  0.17817972600460052\n",
      "48  train loss:  0.17641395330429077\n",
      "49  train loss:  0.17502383887767792\n",
      "50  train loss:  0.17355673015117645\n",
      "51  train loss:  0.17183861136436462\n",
      "52  train loss:  0.17041529715061188\n",
      "53  train loss:  0.1691262573003769\n",
      "54  train loss:  0.1677032709121704\n",
      "55  train loss:  0.16647733747959137\n",
      "56  train loss:  0.16522783041000366\n",
      "57  train loss:  0.16420690715312958\n",
      "58  train loss:  0.1630992591381073\n",
      "59  train loss:  0.16192083060741425\n",
      "60  train loss:  0.1606699675321579\n",
      "61  train loss:  0.1596531718969345\n",
      "62  train loss:  0.15830662846565247\n",
      "63  train loss:  0.1571735441684723\n",
      "64  train loss:  0.15583524107933044\n",
      "65  train loss:  0.15456679463386536\n",
      "66  train loss:  0.1535017341375351\n",
      "67  train loss:  0.15274785459041595\n",
      "68  train loss:  0.15181376039981842\n",
      "69  train loss:  0.15092654526233673\n",
      "70  train loss:  0.14997375011444092\n",
      "71  train loss:  0.14901942014694214\n",
      "72  train loss:  0.14803773164749146\n",
      "73  train loss:  0.14721691608428955\n",
      "74  train loss:  0.1462835967540741\n",
      "75  train loss:  0.14367419481277466\n",
      "76  train loss:  0.14316293597221375\n",
      "77  train loss:  0.1405363231897354\n",
      "78  train loss:  0.1396479606628418\n",
      "79  train loss:  0.13872304558753967\n",
      "80  train loss:  0.1380377560853958\n",
      "81  train loss:  0.13705097138881683\n",
      "82  train loss:  0.1362467110157013\n",
      "83  train loss:  0.13536986708641052\n",
      "84  train loss:  0.13453097641468048\n",
      "85  train loss:  0.1338368058204651\n",
      "86  train loss:  0.13251091539859772\n",
      "87  train loss:  0.13167239725589752\n",
      "88  train loss:  0.1307971030473709\n",
      "89  train loss:  0.13020549714565277\n",
      "90  train loss:  0.12933966517448425\n",
      "91  train loss:  0.12851449847221375\n",
      "92  train loss:  0.12765172123908997\n",
      "93  train loss:  0.1274273544549942\n",
      "94  train loss:  0.1266753375530243\n",
      "95  train loss:  0.12547782063484192\n",
      "96  train loss:  0.12442029267549515\n",
      "97  train loss:  0.12595157325267792\n",
      "98  train loss:  0.12485546618700027\n",
      "99  train loss:  0.12235470116138458\n",
      "test acc (%):  tensor(78.7339)\n",
      "0  train loss:  0.6924353837966919\n",
      "1  train loss:  0.5966162085533142\n",
      "2  train loss:  0.49712204933166504\n",
      "3  train loss:  0.45625001192092896\n",
      "4  train loss:  0.41106823086738586\n",
      "5  train loss:  0.3855929672718048\n",
      "6  train loss:  0.36966919898986816\n",
      "7  train loss:  0.3569938540458679\n",
      "8  train loss:  0.3536892831325531\n",
      "9  train loss:  0.3576003313064575\n",
      "10  train loss:  0.3682863712310791\n",
      "11  train loss:  0.35746732354164124\n",
      "12  train loss:  0.33538541197776794\n",
      "13  train loss:  0.32423320412635803\n",
      "14  train loss:  0.338788777589798\n",
      "15  train loss:  0.3175041079521179\n",
      "16  train loss:  0.3040313720703125\n",
      "17  train loss:  0.3056769073009491\n",
      "18  train loss:  0.3014114499092102\n",
      "19  train loss:  0.2880646288394928\n",
      "20  train loss:  0.27478501200675964\n",
      "21  train loss:  0.2788611650466919\n",
      "22  train loss:  0.2656613886356354\n",
      "23  train loss:  0.26207560300827026\n",
      "24  train loss:  0.26017531752586365\n",
      "25  train loss:  0.25483274459838867\n",
      "26  train loss:  0.24738427996635437\n",
      "27  train loss:  0.2461131364107132\n",
      "28  train loss:  0.24314774572849274\n",
      "29  train loss:  0.23970112204551697\n",
      "30  train loss:  0.23872388899326324\n",
      "31  train loss:  0.23715563118457794\n",
      "32  train loss:  0.23350651562213898\n",
      "33  train loss:  0.23078934848308563\n",
      "34  train loss:  0.22934940457344055\n",
      "35  train loss:  0.22588419914245605\n",
      "36  train loss:  0.22295860946178436\n",
      "37  train loss:  0.2211429476737976\n",
      "38  train loss:  0.2191803753376007\n",
      "39  train loss:  0.2163076400756836\n",
      "40  train loss:  0.21416908502578735\n",
      "41  train loss:  0.21241140365600586\n",
      "42  train loss:  0.20977701246738434\n",
      "43  train loss:  0.20791584253311157\n",
      "44  train loss:  0.2062130570411682\n",
      "45  train loss:  0.20391827821731567\n",
      "46  train loss:  0.2025691419839859\n",
      "47  train loss:  0.20168235898017883\n",
      "48  train loss:  0.19991973042488098\n",
      "49  train loss:  0.19841672480106354\n",
      "50  train loss:  0.19707900285720825\n",
      "51  train loss:  0.1959371417760849\n",
      "52  train loss:  0.19465279579162598\n",
      "53  train loss:  0.1931159794330597\n",
      "54  train loss:  0.1919638067483902\n",
      "55  train loss:  0.19080577790737152\n",
      "56  train loss:  0.18952013552188873\n",
      "57  train loss:  0.18852713704109192\n",
      "58  train loss:  0.1870414912700653\n",
      "59  train loss:  0.18502913415431976\n",
      "60  train loss:  0.183399498462677\n",
      "61  train loss:  0.18146228790283203\n",
      "62  train loss:  0.18010953068733215\n",
      "63  train loss:  0.1783597469329834\n",
      "64  train loss:  0.1778102070093155\n",
      "65  train loss:  0.17648637294769287\n",
      "66  train loss:  0.1754435896873474\n",
      "67  train loss:  0.17410172522068024\n",
      "68  train loss:  0.17314375936985016\n",
      "69  train loss:  0.17255385220050812\n",
      "70  train loss:  0.17134951055049896\n",
      "71  train loss:  0.17023736238479614\n",
      "72  train loss:  0.16932259500026703\n",
      "73  train loss:  0.16835421323776245\n",
      "74  train loss:  0.167180135846138\n",
      "75  train loss:  0.16617810726165771\n",
      "76  train loss:  0.16511885821819305\n",
      "77  train loss:  0.16403715312480927\n",
      "78  train loss:  0.16282525658607483\n",
      "79  train loss:  0.16125844419002533\n",
      "80  train loss:  0.16029877960681915\n",
      "81  train loss:  0.15939989686012268\n",
      "82  train loss:  0.15836147964000702\n",
      "83  train loss:  0.1572686731815338\n",
      "84  train loss:  0.15612803399562836\n",
      "85  train loss:  0.1551096886396408\n",
      "86  train loss:  0.1541835069656372\n",
      "87  train loss:  0.1531064510345459\n",
      "88  train loss:  0.1521589159965515\n",
      "89  train loss:  0.15116092562675476\n",
      "90  train loss:  0.1502208709716797\n",
      "91  train loss:  0.14940889179706573\n",
      "92  train loss:  0.14863653481006622\n",
      "93  train loss:  0.14804260432720184\n",
      "94  train loss:  0.14728543162345886\n",
      "95  train loss:  0.14663511514663696\n",
      "96  train loss:  0.1460128128528595\n",
      "97  train loss:  0.14531707763671875\n",
      "98  train loss:  0.1445925384759903\n",
      "99  train loss:  0.14395426213741302\n",
      "test acc (%):  tensor(77.8844)\n",
      "0  train loss:  0.636589765548706\n",
      "1  train loss:  0.5761418342590332\n",
      "2  train loss:  0.5106236934661865\n",
      "3  train loss:  0.4450704753398895\n",
      "4  train loss:  0.39985814690589905\n",
      "5  train loss:  0.3597070872783661\n",
      "6  train loss:  0.3501705527305603\n",
      "7  train loss:  0.35042035579681396\n",
      "8  train loss:  0.34255191683769226\n",
      "9  train loss:  0.3392748236656189\n",
      "10  train loss:  0.33822396397590637\n",
      "11  train loss:  0.33338475227355957\n",
      "12  train loss:  0.32112058997154236\n",
      "13  train loss:  0.3061220943927765\n",
      "14  train loss:  0.3092181086540222\n",
      "15  train loss:  0.29892003536224365\n",
      "16  train loss:  0.29280567169189453\n",
      "17  train loss:  0.28700998425483704\n",
      "18  train loss:  0.28197214007377625\n",
      "19  train loss:  0.2709488570690155\n",
      "20  train loss:  0.2675364911556244\n",
      "21  train loss:  0.25798970460891724\n",
      "22  train loss:  0.2590227723121643\n",
      "23  train loss:  0.2479124665260315\n",
      "24  train loss:  0.24396614730358124\n",
      "25  train loss:  0.24686871469020844\n",
      "26  train loss:  0.23334041237831116\n",
      "27  train loss:  0.23677347600460052\n",
      "28  train loss:  0.23104619979858398\n",
      "29  train loss:  0.22726000845432281\n",
      "30  train loss:  0.22648674249649048\n",
      "31  train loss:  0.2199561446905136\n",
      "32  train loss:  0.22032055258750916\n",
      "33  train loss:  0.21461257338523865\n",
      "34  train loss:  0.21228164434432983\n",
      "35  train loss:  0.21263717114925385\n",
      "36  train loss:  0.20875607430934906\n",
      "37  train loss:  0.20668968558311462\n",
      "38  train loss:  0.2057373821735382\n",
      "39  train loss:  0.20197445154190063\n",
      "40  train loss:  0.2000538855791092\n",
      "41  train loss:  0.19820694625377655\n",
      "42  train loss:  0.19652535021305084\n",
      "43  train loss:  0.1943529099225998\n",
      "44  train loss:  0.19277942180633545\n",
      "45  train loss:  0.19084171950817108\n",
      "46  train loss:  0.18903468549251556\n",
      "47  train loss:  0.18758800625801086\n",
      "48  train loss:  0.18617448210716248\n",
      "49  train loss:  0.18507908284664154\n",
      "50  train loss:  0.18378673493862152\n",
      "51  train loss:  0.18263228237628937\n",
      "52  train loss:  0.18135958909988403\n",
      "53  train loss:  0.18012474477291107\n",
      "54  train loss:  0.1779841035604477\n",
      "55  train loss:  0.17715945839881897\n",
      "56  train loss:  0.17607669532299042\n",
      "57  train loss:  0.17528077960014343\n",
      "58  train loss:  0.1744292825460434\n",
      "59  train loss:  0.1732618361711502\n",
      "60  train loss:  0.17220868170261383\n",
      "61  train loss:  0.17135852575302124\n",
      "62  train loss:  0.1706392616033554\n",
      "63  train loss:  0.1698371171951294\n",
      "64  train loss:  0.1691700518131256\n",
      "65  train loss:  0.1685352325439453\n",
      "66  train loss:  0.16802023351192474\n",
      "67  train loss:  0.1672632098197937\n",
      "68  train loss:  0.1666424721479416\n",
      "69  train loss:  0.16605091094970703\n",
      "70  train loss:  0.16546332836151123\n",
      "71  train loss:  0.16488346457481384\n",
      "72  train loss:  0.1642952412366867\n",
      "73  train loss:  0.16357985138893127\n",
      "74  train loss:  0.16299115121364594\n",
      "75  train loss:  0.1624009758234024\n",
      "76  train loss:  0.16180790960788727\n",
      "77  train loss:  0.16130535304546356\n",
      "78  train loss:  0.16061708331108093\n",
      "79  train loss:  0.15970511734485626\n",
      "80  train loss:  0.15918010473251343\n",
      "81  train loss:  0.15784211456775665\n",
      "82  train loss:  0.15688708424568176\n",
      "83  train loss:  0.1558743417263031\n",
      "84  train loss:  0.15512681007385254\n",
      "85  train loss:  0.1542981117963791\n",
      "86  train loss:  0.15302950143814087\n",
      "87  train loss:  0.15220500528812408\n",
      "88  train loss:  0.15144731104373932\n",
      "89  train loss:  0.1506889909505844\n",
      "90  train loss:  0.1499062329530716\n",
      "91  train loss:  0.1493014544248581\n",
      "92  train loss:  0.148663729429245\n",
      "93  train loss:  0.14824147522449493\n",
      "94  train loss:  0.14733469486236572\n",
      "95  train loss:  0.14678281545639038\n",
      "96  train loss:  0.14604848623275757\n",
      "97  train loss:  0.14555467665195465\n",
      "98  train loss:  0.144847571849823\n",
      "99  train loss:  0.14400093257427216\n",
      "test acc (%):  tensor(77.5829)\n",
      "0  train loss:  0.6221825480461121\n",
      "1  train loss:  0.5157927870750427\n",
      "2  train loss:  0.4546303451061249\n",
      "3  train loss:  0.4096904993057251\n",
      "4  train loss:  0.38916051387786865\n",
      "5  train loss:  0.3681615889072418\n",
      "6  train loss:  0.35902050137519836\n",
      "7  train loss:  0.3569298982620239\n",
      "8  train loss:  0.35386523604393005\n",
      "9  train loss:  0.35485371947288513\n",
      "10  train loss:  0.3606765866279602\n",
      "11  train loss:  0.33670130372047424\n",
      "12  train loss:  0.32981809973716736\n",
      "13  train loss:  0.32116299867630005\n",
      "14  train loss:  0.31375718116760254\n",
      "15  train loss:  0.3099696636199951\n",
      "16  train loss:  0.30424177646636963\n",
      "17  train loss:  0.2997449040412903\n",
      "18  train loss:  0.29467469453811646\n",
      "19  train loss:  0.29058316349983215\n",
      "20  train loss:  0.2858527600765228\n",
      "21  train loss:  0.28033486008644104\n",
      "22  train loss:  0.2757381796836853\n",
      "23  train loss:  0.27157074213027954\n",
      "24  train loss:  0.2659827470779419\n",
      "25  train loss:  0.2621801793575287\n",
      "26  train loss:  0.2584175169467926\n",
      "27  train loss:  0.25425469875335693\n",
      "28  train loss:  0.25078508257865906\n",
      "29  train loss:  0.24721968173980713\n",
      "30  train loss:  0.24540476500988007\n",
      "31  train loss:  0.2422778457403183\n",
      "32  train loss:  0.2399352788925171\n",
      "33  train loss:  0.2375887930393219\n",
      "34  train loss:  0.23492147028446198\n",
      "35  train loss:  0.2307831346988678\n",
      "36  train loss:  0.227775439620018\n",
      "37  train loss:  0.22482459247112274\n",
      "38  train loss:  0.22213214635849\n",
      "39  train loss:  0.22029265761375427\n",
      "40  train loss:  0.21868906915187836\n",
      "41  train loss:  0.21687708795070648\n",
      "42  train loss:  0.21421444416046143\n",
      "43  train loss:  0.21147792041301727\n",
      "44  train loss:  0.20946717262268066\n",
      "45  train loss:  0.20604939758777618\n",
      "46  train loss:  0.20394735038280487\n",
      "47  train loss:  0.20138812065124512\n",
      "48  train loss:  0.19901159405708313\n",
      "49  train loss:  0.19693125784397125\n",
      "50  train loss:  0.19525091350078583\n",
      "51  train loss:  0.19358797371387482\n",
      "52  train loss:  0.19240766763687134\n",
      "53  train loss:  0.18977738916873932\n",
      "54  train loss:  0.188023179769516\n",
      "55  train loss:  0.1860867589712143\n",
      "56  train loss:  0.18355825543403625\n",
      "57  train loss:  0.18139156699180603\n",
      "58  train loss:  0.1794920116662979\n",
      "59  train loss:  0.17809827625751495\n",
      "60  train loss:  0.1763094663619995\n",
      "61  train loss:  0.1742336004972458\n",
      "62  train loss:  0.17235256731510162\n",
      "63  train loss:  0.17036430537700653\n",
      "64  train loss:  0.16861125826835632\n",
      "65  train loss:  0.16655921936035156\n",
      "66  train loss:  0.1653469353914261\n",
      "67  train loss:  0.1642918735742569\n",
      "68  train loss:  0.16292592883110046\n",
      "69  train loss:  0.1614181250333786\n",
      "70  train loss:  0.16026851534843445\n",
      "71  train loss:  0.15911398828029633\n",
      "72  train loss:  0.15763388574123383\n",
      "73  train loss:  0.15600983798503876\n",
      "74  train loss:  0.15476305782794952\n",
      "75  train loss:  0.15394288301467896\n",
      "76  train loss:  0.15301814675331116\n",
      "77  train loss:  0.15182922780513763\n",
      "78  train loss:  0.15066152811050415\n",
      "79  train loss:  0.14985288679599762\n",
      "80  train loss:  0.1492682844400406\n",
      "81  train loss:  0.14863771200180054\n",
      "82  train loss:  0.14783403277397156\n",
      "83  train loss:  0.14703896641731262\n",
      "84  train loss:  0.14556992053985596\n",
      "85  train loss:  0.1453276425600052\n",
      "86  train loss:  0.14436981081962585\n",
      "87  train loss:  0.14369796216487885\n",
      "88  train loss:  0.1431599259376526\n",
      "89  train loss:  0.14251603186130524\n",
      "90  train loss:  0.14214611053466797\n",
      "91  train loss:  0.1415145844221115\n",
      "92  train loss:  0.1410587728023529\n",
      "93  train loss:  0.14049747586250305\n",
      "94  train loss:  0.1404133439064026\n",
      "95  train loss:  0.13993030786514282\n",
      "96  train loss:  0.13982103765010834\n",
      "97  train loss:  0.1392775923013687\n",
      "98  train loss:  0.1385699361562729\n",
      "99  train loss:  0.1378229558467865\n",
      "test acc (%):  tensor(78.4050)\n",
      "0  train loss:  0.5212581753730774\n",
      "1  train loss:  0.4588746726512909\n",
      "2  train loss:  0.4173915386199951\n",
      "3  train loss:  0.390696257352829\n",
      "4  train loss:  0.4029618203639984\n",
      "5  train loss:  0.3410986661911011\n",
      "6  train loss:  0.3310922682285309\n",
      "7  train loss:  0.31917300820350647\n",
      "8  train loss:  0.3102952837944031\n",
      "9  train loss:  0.3140192925930023\n",
      "10  train loss:  0.2913646399974823\n",
      "11  train loss:  0.30902817845344543\n",
      "12  train loss:  0.2873498499393463\n",
      "13  train loss:  0.29254022240638733\n",
      "14  train loss:  0.29264071583747864\n",
      "15  train loss:  0.2773936092853546\n",
      "16  train loss:  0.27132847905158997\n",
      "17  train loss:  0.26661014556884766\n",
      "18  train loss:  0.2558715045452118\n",
      "19  train loss:  0.2553451955318451\n",
      "20  train loss:  0.24800994992256165\n",
      "21  train loss:  0.23620203137397766\n",
      "22  train loss:  0.23288613557815552\n",
      "23  train loss:  0.2277545928955078\n",
      "24  train loss:  0.22220918536186218\n",
      "25  train loss:  0.22099025547504425\n",
      "26  train loss:  0.21820570528507233\n",
      "27  train loss:  0.21510455012321472\n",
      "28  train loss:  0.21314503252506256\n",
      "29  train loss:  0.2092871367931366\n",
      "30  train loss:  0.20682385563850403\n",
      "31  train loss:  0.20506152510643005\n",
      "32  train loss:  0.2028868943452835\n",
      "33  train loss:  0.20042908191680908\n",
      "34  train loss:  0.1982325166463852\n",
      "35  train loss:  0.19440646469593048\n",
      "36  train loss:  0.19227327406406403\n",
      "37  train loss:  0.18956920504570007\n",
      "38  train loss:  0.18607307970523834\n",
      "39  train loss:  0.18405430018901825\n",
      "40  train loss:  0.18276315927505493\n",
      "41  train loss:  0.18028657138347626\n",
      "42  train loss:  0.17904387414455414\n",
      "43  train loss:  0.17802362143993378\n",
      "44  train loss:  0.17574118077754974\n",
      "45  train loss:  0.17420606315135956\n",
      "46  train loss:  0.1719886213541031\n",
      "47  train loss:  0.1696954071521759\n",
      "48  train loss:  0.16824021935462952\n",
      "49  train loss:  0.1664835661649704\n",
      "50  train loss:  0.16554521024227142\n",
      "51  train loss:  0.16334085166454315\n",
      "52  train loss:  0.1626027375459671\n",
      "53  train loss:  0.16060824692249298\n",
      "54  train loss:  0.15885329246520996\n",
      "55  train loss:  0.15735051035881042\n",
      "56  train loss:  0.1555931717157364\n",
      "57  train loss:  0.15476487576961517\n",
      "58  train loss:  0.15313945710659027\n",
      "59  train loss:  0.15227560698986053\n",
      "60  train loss:  0.15091609954833984\n",
      "61  train loss:  0.1508321762084961\n",
      "62  train loss:  0.14915920794010162\n",
      "63  train loss:  0.14861227571964264\n",
      "64  train loss:  0.14649134874343872\n",
      "65  train loss:  0.14502476155757904\n",
      "66  train loss:  0.1444288194179535\n",
      "67  train loss:  0.1425371766090393\n",
      "68  train loss:  0.14144861698150635\n",
      "69  train loss:  0.1402100771665573\n",
      "70  train loss:  0.13918344676494598\n",
      "71  train loss:  0.13830126821994781\n",
      "72  train loss:  0.13611619174480438\n",
      "73  train loss:  0.13499237596988678\n",
      "74  train loss:  0.1349608302116394\n",
      "75  train loss:  0.13302788138389587\n",
      "76  train loss:  0.13221441209316254\n",
      "77  train loss:  0.1313730627298355\n",
      "78  train loss:  0.13049691915512085\n",
      "79  train loss:  0.12971055507659912\n",
      "80  train loss:  0.12892365455627441\n",
      "81  train loss:  0.12789084017276764\n",
      "82  train loss:  0.1273738443851471\n",
      "83  train loss:  0.12669892609119415\n",
      "84  train loss:  0.12615402042865753\n",
      "85  train loss:  0.12549805641174316\n",
      "86  train loss:  0.12495853751897812\n",
      "87  train loss:  0.12465448677539825\n",
      "88  train loss:  0.12391826510429382\n",
      "89  train loss:  0.12312795966863632\n",
      "90  train loss:  0.12256794422864914\n",
      "91  train loss:  0.12153767794370651\n",
      "92  train loss:  0.12094578146934509\n",
      "93  train loss:  0.12026187032461166\n",
      "94  train loss:  0.11928968131542206\n",
      "95  train loss:  0.11856234073638916\n",
      "96  train loss:  0.11800336092710495\n",
      "97  train loss:  0.11687316745519638\n",
      "98  train loss:  0.11554518342018127\n",
      "99  train loss:  0.11504711210727692\n",
      "test acc (%):  tensor(77.4459)\n",
      "0  train loss:  0.6847792267799377\n",
      "1  train loss:  0.5906670689582825\n",
      "2  train loss:  0.5116318464279175\n",
      "3  train loss:  0.4615982174873352\n",
      "4  train loss:  0.418201208114624\n",
      "5  train loss:  0.3971269726753235\n",
      "6  train loss:  0.3722032308578491\n",
      "7  train loss:  0.37086042761802673\n",
      "8  train loss:  0.3546101152896881\n",
      "9  train loss:  0.3450978994369507\n",
      "10  train loss:  0.34173357486724854\n",
      "11  train loss:  0.33461853861808777\n",
      "12  train loss:  0.32635125517845154\n",
      "13  train loss:  0.3271145522594452\n",
      "14  train loss:  0.31710389256477356\n",
      "15  train loss:  0.308659166097641\n",
      "16  train loss:  0.30550408363342285\n",
      "17  train loss:  0.2935745418071747\n",
      "18  train loss:  0.29563891887664795\n",
      "19  train loss:  0.2866450250148773\n",
      "20  train loss:  0.2815386652946472\n",
      "21  train loss:  0.2779925465583801\n",
      "22  train loss:  0.27167680859565735\n",
      "23  train loss:  0.2666695713996887\n",
      "24  train loss:  0.26401835680007935\n",
      "25  train loss:  0.2597293555736542\n",
      "26  train loss:  0.2543962597846985\n",
      "27  train loss:  0.24992342293262482\n",
      "28  train loss:  0.24710844457149506\n",
      "29  train loss:  0.24299339950084686\n",
      "30  train loss:  0.2403840273618698\n",
      "31  train loss:  0.2374562919139862\n",
      "32  train loss:  0.23474588990211487\n",
      "33  train loss:  0.23171097040176392\n",
      "34  train loss:  0.22921785712242126\n",
      "35  train loss:  0.22731845080852509\n",
      "36  train loss:  0.2250760942697525\n",
      "37  train loss:  0.22253280878067017\n",
      "38  train loss:  0.21975909173488617\n",
      "39  train loss:  0.2177460789680481\n",
      "40  train loss:  0.21465983986854553\n",
      "41  train loss:  0.21062245965003967\n",
      "42  train loss:  0.20742855966091156\n",
      "43  train loss:  0.20459230244159698\n",
      "44  train loss:  0.20166637003421783\n",
      "45  train loss:  0.19945712387561798\n",
      "46  train loss:  0.19764402508735657\n",
      "47  train loss:  0.19609129428863525\n",
      "48  train loss:  0.19414231181144714\n",
      "49  train loss:  0.19200053811073303\n",
      "50  train loss:  0.18924197554588318\n",
      "51  train loss:  0.18727751076221466\n",
      "52  train loss:  0.18609246611595154\n",
      "53  train loss:  0.18359605967998505\n",
      "54  train loss:  0.18084673583507538\n",
      "55  train loss:  0.17866821587085724\n",
      "56  train loss:  0.17607252299785614\n",
      "57  train loss:  0.17397134006023407\n",
      "58  train loss:  0.172361820936203\n",
      "59  train loss:  0.17043344676494598\n",
      "60  train loss:  0.16796095669269562\n",
      "61  train loss:  0.16573560237884521\n",
      "62  train loss:  0.16408269107341766\n",
      "63  train loss:  0.16152091324329376\n",
      "64  train loss:  0.15952932834625244\n",
      "65  train loss:  0.15633873641490936\n",
      "66  train loss:  0.1552307903766632\n",
      "67  train loss:  0.1531178504228592\n",
      "68  train loss:  0.1511233150959015\n",
      "69  train loss:  0.15036730468273163\n",
      "70  train loss:  0.14841243624687195\n",
      "71  train loss:  0.14754964411258698\n",
      "72  train loss:  0.14701083302497864\n",
      "73  train loss:  0.14571931958198547\n",
      "74  train loss:  0.14452850818634033\n",
      "75  train loss:  0.14371846616268158\n",
      "76  train loss:  0.14287720620632172\n",
      "77  train loss:  0.14217020571231842\n",
      "78  train loss:  0.14120985567569733\n",
      "79  train loss:  0.14025285840034485\n",
      "80  train loss:  0.13929764926433563\n",
      "81  train loss:  0.13831545412540436\n",
      "82  train loss:  0.13733218610286713\n",
      "83  train loss:  0.1362856775522232\n",
      "84  train loss:  0.1353580206632614\n",
      "85  train loss:  0.1341736614704132\n",
      "86  train loss:  0.13364635407924652\n",
      "87  train loss:  0.1326301097869873\n",
      "88  train loss:  0.13170038163661957\n",
      "89  train loss:  0.130764439702034\n",
      "90  train loss:  0.12958087027072906\n",
      "91  train loss:  0.12847813963890076\n",
      "92  train loss:  0.12736934423446655\n",
      "93  train loss:  0.12678803503513336\n",
      "94  train loss:  0.12560580670833588\n",
      "95  train loss:  0.12495318800210953\n",
      "96  train loss:  0.12426538020372391\n",
      "97  train loss:  0.12346342206001282\n",
      "98  train loss:  0.12234000861644745\n",
      "99  train loss:  0.12199055403470993\n",
      "test acc (%):  tensor(77.6377)\n",
      "0  train loss:  0.5814424753189087\n",
      "1  train loss:  0.5056078433990479\n",
      "2  train loss:  0.4316388964653015\n",
      "3  train loss:  0.3979824185371399\n",
      "4  train loss:  0.3618050813674927\n",
      "5  train loss:  0.34807872772216797\n",
      "6  train loss:  0.3356207013130188\n",
      "7  train loss:  0.3198946714401245\n",
      "8  train loss:  0.3137813210487366\n",
      "9  train loss:  0.31082358956336975\n",
      "10  train loss:  0.3046666085720062\n",
      "11  train loss:  0.2965547740459442\n",
      "12  train loss:  0.28684383630752563\n",
      "13  train loss:  0.28488031029701233\n",
      "14  train loss:  0.2811931371688843\n",
      "15  train loss:  0.2773285210132599\n",
      "16  train loss:  0.271318644285202\n",
      "17  train loss:  0.2651981711387634\n",
      "18  train loss:  0.2605552673339844\n",
      "19  train loss:  0.2566463351249695\n",
      "20  train loss:  0.25098732113838196\n",
      "21  train loss:  0.24625642597675323\n",
      "22  train loss:  0.2408515214920044\n",
      "23  train loss:  0.23754650354385376\n",
      "24  train loss:  0.2341635376214981\n",
      "25  train loss:  0.23069053888320923\n",
      "26  train loss:  0.22743889689445496\n",
      "27  train loss:  0.22407567501068115\n",
      "28  train loss:  0.22096188366413116\n",
      "29  train loss:  0.21817299723625183\n",
      "30  train loss:  0.21533718705177307\n",
      "31  train loss:  0.21256114542484283\n",
      "32  train loss:  0.209431990981102\n",
      "33  train loss:  0.2069220244884491\n",
      "34  train loss:  0.2038242667913437\n",
      "35  train loss:  0.2004501074552536\n",
      "36  train loss:  0.19799119234085083\n",
      "37  train loss:  0.1951846480369568\n",
      "38  train loss:  0.19227160513401031\n",
      "39  train loss:  0.18907010555267334\n",
      "40  train loss:  0.18706458806991577\n",
      "41  train loss:  0.18540914356708527\n",
      "42  train loss:  0.1831219494342804\n",
      "43  train loss:  0.1824321150779724\n",
      "44  train loss:  0.18072862923145294\n",
      "45  train loss:  0.178925558924675\n",
      "46  train loss:  0.17821483314037323\n",
      "47  train loss:  0.1763988584280014\n",
      "48  train loss:  0.17521299421787262\n",
      "49  train loss:  0.17388957738876343\n",
      "50  train loss:  0.17164556682109833\n",
      "51  train loss:  0.16952407360076904\n",
      "52  train loss:  0.1681901216506958\n",
      "53  train loss:  0.16688603162765503\n",
      "54  train loss:  0.16525085270404816\n",
      "55  train loss:  0.16315092146396637\n",
      "56  train loss:  0.16191039979457855\n",
      "57  train loss:  0.1598038226366043\n",
      "58  train loss:  0.15925778448581696\n",
      "59  train loss:  0.1580912470817566\n",
      "60  train loss:  0.15702374279499054\n",
      "61  train loss:  0.15616732835769653\n",
      "62  train loss:  0.15477928519248962\n",
      "63  train loss:  0.1541285514831543\n",
      "64  train loss:  0.15241289138793945\n",
      "65  train loss:  0.1513134092092514\n",
      "66  train loss:  0.1502290517091751\n",
      "67  train loss:  0.14921250939369202\n",
      "68  train loss:  0.14842937886714935\n",
      "69  train loss:  0.14727945625782013\n",
      "70  train loss:  0.1467246264219284\n",
      "71  train loss:  0.14552609622478485\n",
      "72  train loss:  0.14473606646060944\n",
      "73  train loss:  0.14382965862751007\n",
      "74  train loss:  0.143163800239563\n",
      "75  train loss:  0.1419774442911148\n",
      "76  train loss:  0.14183852076530457\n",
      "77  train loss:  0.14108890295028687\n",
      "78  train loss:  0.14065711200237274\n",
      "79  train loss:  0.13846395909786224\n",
      "80  train loss:  0.13846321403980255\n",
      "81  train loss:  0.13579989969730377\n",
      "82  train loss:  0.1359087973833084\n",
      "83  train loss:  0.1345881074666977\n",
      "84  train loss:  0.13264769315719604\n",
      "85  train loss:  0.13397987186908722\n",
      "86  train loss:  0.13054640591144562\n",
      "87  train loss:  0.13112835586071014\n",
      "88  train loss:  0.1296239048242569\n",
      "89  train loss:  0.1282193511724472\n",
      "90  train loss:  0.12896008789539337\n",
      "91  train loss:  0.12691698968410492\n",
      "92  train loss:  0.1268898993730545\n",
      "93  train loss:  0.12538032233715057\n",
      "94  train loss:  0.12395913898944855\n",
      "95  train loss:  0.12345775961875916\n",
      "96  train loss:  0.12229643762111664\n",
      "97  train loss:  0.12204458564519882\n",
      "98  train loss:  0.120674267411232\n",
      "99  train loss:  0.11929339170455933\n",
      "test acc (%):  tensor(77.8569)\n",
      "0  train loss:  0.5567030906677246\n",
      "1  train loss:  0.49250245094299316\n",
      "2  train loss:  0.44121018052101135\n",
      "3  train loss:  0.3821936845779419\n",
      "4  train loss:  0.3592175245285034\n",
      "5  train loss:  0.34428757429122925\n",
      "6  train loss:  0.32157042622566223\n",
      "7  train loss:  0.31319209933280945\n",
      "8  train loss:  0.30322569608688354\n",
      "9  train loss:  0.2928413152694702\n",
      "10  train loss:  0.28362593054771423\n",
      "11  train loss:  0.2781967520713806\n",
      "12  train loss:  0.27073749899864197\n",
      "13  train loss:  0.2635166049003601\n",
      "14  train loss:  0.25532904267311096\n",
      "15  train loss:  0.24719981849193573\n",
      "16  train loss:  0.24104583263397217\n",
      "17  train loss:  0.2383556365966797\n",
      "18  train loss:  0.23319697380065918\n",
      "19  train loss:  0.2249682992696762\n",
      "20  train loss:  0.2196478694677353\n",
      "21  train loss:  0.2149447649717331\n",
      "22  train loss:  0.20893114805221558\n",
      "23  train loss:  0.20747298002243042\n",
      "24  train loss:  0.20198345184326172\n",
      "25  train loss:  0.19713807106018066\n",
      "26  train loss:  0.1927689164876938\n",
      "27  train loss:  0.18915273249149323\n",
      "28  train loss:  0.1858406662940979\n",
      "29  train loss:  0.1823868453502655\n",
      "30  train loss:  0.17926740646362305\n",
      "31  train loss:  0.17600470781326294\n",
      "32  train loss:  0.17205554246902466\n",
      "33  train loss:  0.16909268498420715\n",
      "34  train loss:  0.16556678712368011\n",
      "35  train loss:  0.1629931926727295\n",
      "36  train loss:  0.16083456575870514\n",
      "37  train loss:  0.15896262228488922\n",
      "38  train loss:  0.15728195011615753\n",
      "39  train loss:  0.15562114119529724\n",
      "40  train loss:  0.15348848700523376\n",
      "41  train loss:  0.15212512016296387\n",
      "42  train loss:  0.15060000121593475\n",
      "43  train loss:  0.14947952330112457\n",
      "44  train loss:  0.1483370065689087\n",
      "45  train loss:  0.147074893116951\n",
      "46  train loss:  0.1453988403081894\n",
      "47  train loss:  0.14419622719287872\n",
      "48  train loss:  0.14230702817440033\n",
      "49  train loss:  0.14122873544692993\n",
      "50  train loss:  0.14047366380691528\n",
      "51  train loss:  0.1383000910282135\n",
      "52  train loss:  0.13685342669487\n",
      "53  train loss:  0.13534386456012726\n",
      "54  train loss:  0.13434043526649475\n",
      "55  train loss:  0.13289178907871246\n",
      "56  train loss:  0.13231641054153442\n",
      "57  train loss:  0.1314801722764969\n",
      "58  train loss:  0.1297307014465332\n",
      "59  train loss:  0.12795251607894897\n",
      "60  train loss:  0.127365380525589\n",
      "61  train loss:  0.1257045865058899\n",
      "62  train loss:  0.12467776983976364\n",
      "63  train loss:  0.12380924075841904\n",
      "64  train loss:  0.12243599444627762\n",
      "65  train loss:  0.12048647552728653\n",
      "66  train loss:  0.11877736449241638\n",
      "67  train loss:  0.11704754829406738\n",
      "68  train loss:  0.11428487300872803\n",
      "69  train loss:  0.1136152446269989\n",
      "70  train loss:  0.11208850890398026\n",
      "71  train loss:  0.10987791419029236\n",
      "72  train loss:  0.10927502065896988\n",
      "73  train loss:  0.10698434710502625\n",
      "74  train loss:  0.10684402287006378\n",
      "75  train loss:  0.10491692274808884\n",
      "76  train loss:  0.10445648431777954\n",
      "77  train loss:  0.10236088931560516\n",
      "78  train loss:  0.1004469096660614\n",
      "79  train loss:  0.0994582399725914\n",
      "80  train loss:  0.0978865772485733\n",
      "81  train loss:  0.09707088023424149\n",
      "82  train loss:  0.09603412449359894\n",
      "83  train loss:  0.09574352204799652\n",
      "84  train loss:  0.09506524354219437\n",
      "85  train loss:  0.09443698078393936\n",
      "86  train loss:  0.09361402690410614\n",
      "87  train loss:  0.09295723587274551\n",
      "88  train loss:  0.09216947108507156\n",
      "89  train loss:  0.09131725132465363\n",
      "90  train loss:  0.09047649055719376\n",
      "91  train loss:  0.08967350423336029\n",
      "92  train loss:  0.0888211578130722\n",
      "93  train loss:  0.08820238709449768\n",
      "94  train loss:  0.08714534342288971\n",
      "95  train loss:  0.08639267832040787\n",
      "96  train loss:  0.08563149720430374\n",
      "97  train loss:  0.08471129834651947\n",
      "98  train loss:  0.08398585766553879\n",
      "99  train loss:  0.08316247910261154\n",
      "test acc (%):  tensor(78.0762)\n",
      "0  train loss:  0.6303365230560303\n",
      "1  train loss:  0.5846819281578064\n",
      "2  train loss:  0.49612319469451904\n",
      "3  train loss:  0.43165168166160583\n",
      "4  train loss:  0.4232218265533447\n",
      "5  train loss:  0.3842710256576538\n",
      "6  train loss:  0.36128756403923035\n",
      "7  train loss:  0.3598606288433075\n",
      "8  train loss:  0.3488676846027374\n",
      "9  train loss:  0.33299097418785095\n",
      "10  train loss:  0.329745888710022\n",
      "11  train loss:  0.3276139795780182\n",
      "12  train loss:  0.31820058822631836\n",
      "13  train loss:  0.3124062120914459\n",
      "14  train loss:  0.3045606315135956\n",
      "15  train loss:  0.29844701290130615\n",
      "16  train loss:  0.29282891750335693\n",
      "17  train loss:  0.2879166305065155\n",
      "18  train loss:  0.281524121761322\n",
      "19  train loss:  0.2754163146018982\n",
      "20  train loss:  0.2688940763473511\n",
      "21  train loss:  0.2615434527397156\n",
      "22  train loss:  0.2549356520175934\n",
      "23  train loss:  0.2487681359052658\n",
      "24  train loss:  0.24285843968391418\n",
      "25  train loss:  0.23948141932487488\n",
      "26  train loss:  0.2339887171983719\n",
      "27  train loss:  0.22903122007846832\n",
      "28  train loss:  0.2253577560186386\n",
      "29  train loss:  0.2209884077310562\n",
      "30  train loss:  0.21717213094234467\n",
      "31  train loss:  0.21344628930091858\n",
      "32  train loss:  0.20900966227054596\n",
      "33  train loss:  0.20568987727165222\n",
      "34  train loss:  0.2024981528520584\n",
      "35  train loss:  0.20000773668289185\n",
      "36  train loss:  0.19597946107387543\n",
      "37  train loss:  0.19411489367485046\n",
      "38  train loss:  0.1902211755514145\n",
      "39  train loss:  0.18754121661186218\n",
      "40  train loss:  0.1841340810060501\n",
      "41  train loss:  0.18005697429180145\n",
      "42  train loss:  0.17677365243434906\n",
      "43  train loss:  0.1733740121126175\n",
      "44  train loss:  0.1699356585741043\n",
      "45  train loss:  0.16792497038841248\n",
      "46  train loss:  0.16479435563087463\n",
      "47  train loss:  0.16287606954574585\n",
      "48  train loss:  0.1611989438533783\n",
      "49  train loss:  0.1580546349287033\n",
      "50  train loss:  0.15509358048439026\n",
      "51  train loss:  0.15019169449806213\n",
      "52  train loss:  0.14799703657627106\n",
      "53  train loss:  0.14650912582874298\n",
      "54  train loss:  0.14441262185573578\n",
      "55  train loss:  0.1428809016942978\n",
      "56  train loss:  0.14177542924880981\n",
      "57  train loss:  0.13987863063812256\n",
      "58  train loss:  0.13771092891693115\n",
      "59  train loss:  0.13557052612304688\n",
      "60  train loss:  0.1339462250471115\n",
      "61  train loss:  0.13192784786224365\n",
      "62  train loss:  0.1298867017030716\n",
      "63  train loss:  0.12837828695774078\n",
      "64  train loss:  0.12690195441246033\n",
      "65  train loss:  0.12569370865821838\n",
      "66  train loss:  0.12425301223993301\n",
      "67  train loss:  0.1226399764418602\n",
      "68  train loss:  0.12058765441179276\n",
      "69  train loss:  0.11909925937652588\n",
      "70  train loss:  0.116953045129776\n",
      "71  train loss:  0.11504806578159332\n",
      "72  train loss:  0.11354618519544601\n",
      "73  train loss:  0.11238227784633636\n",
      "74  train loss:  0.11079424619674683\n",
      "75  train loss:  0.10907834023237228\n",
      "76  train loss:  0.10731310397386551\n",
      "77  train loss:  0.10574942827224731\n",
      "78  train loss:  0.10420575737953186\n",
      "79  train loss:  0.10241338610649109\n",
      "80  train loss:  0.10113843530416489\n",
      "81  train loss:  0.09972628951072693\n",
      "82  train loss:  0.09833244979381561\n",
      "83  train loss:  0.09765549004077911\n",
      "84  train loss:  0.09550593048334122\n",
      "85  train loss:  0.0956491157412529\n",
      "86  train loss:  0.09639770537614822\n",
      "87  train loss:  0.09327322244644165\n",
      "88  train loss:  0.09095128625631332\n",
      "89  train loss:  0.09343548119068146\n",
      "90  train loss:  0.08790173381567001\n",
      "91  train loss:  0.09629341214895248\n",
      "92  train loss:  0.08658204972743988\n",
      "93  train loss:  0.09239298105239868\n",
      "94  train loss:  0.08167202770709991\n",
      "95  train loss:  0.0975712388753891\n",
      "96  train loss:  0.08195856213569641\n",
      "97  train loss:  0.08897782862186432\n",
      "98  train loss:  0.08448804169893265\n",
      "99  train loss:  0.07991037517786026\n",
      "test acc (%):  tensor(78.9805)\n",
      "0  train loss:  0.9641603231430054\n",
      "1  train loss:  0.7321419715881348\n",
      "2  train loss:  0.6102834939956665\n",
      "3  train loss:  0.4537663161754608\n",
      "4  train loss:  0.46572980284690857\n",
      "5  train loss:  0.4595130681991577\n",
      "6  train loss:  0.43456071615219116\n",
      "7  train loss:  0.40459221601486206\n",
      "8  train loss:  0.4113278388977051\n",
      "9  train loss:  0.42055898904800415\n",
      "10  train loss:  0.4102427363395691\n",
      "11  train loss:  0.39394018054008484\n",
      "12  train loss:  0.383965402841568\n",
      "13  train loss:  0.3836005926132202\n",
      "14  train loss:  0.37731948494911194\n",
      "15  train loss:  0.3628425896167755\n",
      "16  train loss:  0.35408836603164673\n",
      "17  train loss:  0.34810417890548706\n",
      "18  train loss:  0.33846649527549744\n",
      "19  train loss:  0.3256966471672058\n",
      "20  train loss:  0.31393158435821533\n",
      "21  train loss:  0.3049021363258362\n",
      "22  train loss:  0.30180445313453674\n",
      "23  train loss:  0.3000345230102539\n",
      "24  train loss:  0.2959429621696472\n",
      "25  train loss:  0.28954997658729553\n",
      "26  train loss:  0.28399989008903503\n",
      "27  train loss:  0.2768382728099823\n",
      "28  train loss:  0.273750901222229\n",
      "29  train loss:  0.2694130539894104\n",
      "30  train loss:  0.26582014560699463\n",
      "31  train loss:  0.26230716705322266\n",
      "32  train loss:  0.25890210270881653\n",
      "33  train loss:  0.2532232701778412\n",
      "34  train loss:  0.2485610842704773\n",
      "35  train loss:  0.24635913968086243\n",
      "36  train loss:  0.2443086951971054\n",
      "37  train loss:  0.2409084439277649\n",
      "38  train loss:  0.2390879988670349\n",
      "39  train loss:  0.2369273155927658\n",
      "40  train loss:  0.2341286987066269\n",
      "41  train loss:  0.2311316430568695\n",
      "42  train loss:  0.22864148020744324\n",
      "43  train loss:  0.22625204920768738\n",
      "44  train loss:  0.2241661697626114\n",
      "45  train loss:  0.22230534255504608\n",
      "46  train loss:  0.2197096347808838\n",
      "47  train loss:  0.2179032266139984\n",
      "48  train loss:  0.21568457782268524\n",
      "49  train loss:  0.21388767659664154\n",
      "50  train loss:  0.2117212563753128\n",
      "51  train loss:  0.20926915109157562\n",
      "52  train loss:  0.20730999112129211\n",
      "53  train loss:  0.20533487200737\n",
      "54  train loss:  0.20299096405506134\n",
      "55  train loss:  0.20145541429519653\n",
      "56  train loss:  0.1997469663619995\n",
      "57  train loss:  0.19813396036624908\n",
      "58  train loss:  0.19663292169570923\n",
      "59  train loss:  0.19499270617961884\n",
      "60  train loss:  0.19348667562007904\n",
      "61  train loss:  0.19201698899269104\n",
      "62  train loss:  0.19053810834884644\n",
      "63  train loss:  0.1889180690050125\n",
      "64  train loss:  0.18750351667404175\n",
      "65  train loss:  0.18602503836154938\n",
      "66  train loss:  0.18467698991298676\n",
      "67  train loss:  0.18312622606754303\n",
      "68  train loss:  0.18188199400901794\n",
      "69  train loss:  0.1806955635547638\n",
      "70  train loss:  0.1797323226928711\n",
      "71  train loss:  0.1786268800497055\n",
      "72  train loss:  0.1772426813840866\n",
      "73  train loss:  0.1760932207107544\n",
      "74  train loss:  0.17462415993213654\n",
      "75  train loss:  0.1738205850124359\n",
      "76  train loss:  0.17251335084438324\n",
      "77  train loss:  0.17144663631916046\n",
      "78  train loss:  0.170151486992836\n",
      "79  train loss:  0.1689402014017105\n",
      "80  train loss:  0.16802769899368286\n",
      "81  train loss:  0.1671818345785141\n",
      "82  train loss:  0.16633859276771545\n",
      "83  train loss:  0.16532579064369202\n",
      "84  train loss:  0.1643904596567154\n",
      "85  train loss:  0.16370606422424316\n",
      "86  train loss:  0.1630346029996872\n",
      "87  train loss:  0.16243897378444672\n",
      "88  train loss:  0.1618461161851883\n",
      "89  train loss:  0.16096846759319305\n",
      "90  train loss:  0.16004402935504913\n",
      "91  train loss:  0.15913575887680054\n",
      "92  train loss:  0.15827280282974243\n",
      "93  train loss:  0.15753035247325897\n",
      "94  train loss:  0.15652576088905334\n",
      "95  train loss:  0.1555018126964569\n",
      "96  train loss:  0.15458865463733673\n",
      "97  train loss:  0.1537826508283615\n",
      "98  train loss:  0.1530168205499649\n",
      "99  train loss:  0.1521155834197998\n",
      "test acc (%):  tensor(78.8161)\n",
      "0  train loss:  0.6089110970497131\n",
      "1  train loss:  0.48018303513526917\n",
      "2  train loss:  0.4022808372974396\n",
      "3  train loss:  0.3610195219516754\n",
      "4  train loss:  0.3571901023387909\n",
      "5  train loss:  0.35536593198776245\n",
      "6  train loss:  0.3510976731777191\n",
      "7  train loss:  0.3437977433204651\n",
      "8  train loss:  0.34342214465141296\n",
      "9  train loss:  0.3434681296348572\n",
      "10  train loss:  0.3369027078151703\n",
      "11  train loss:  0.3287476599216461\n",
      "12  train loss:  0.3205696642398834\n",
      "13  train loss:  0.31493425369262695\n",
      "14  train loss:  0.30893534421920776\n",
      "15  train loss:  0.3023069500923157\n",
      "16  train loss:  0.29625385999679565\n",
      "17  train loss:  0.28986427187919617\n",
      "18  train loss:  0.2820628583431244\n",
      "19  train loss:  0.2754622995853424\n",
      "20  train loss:  0.2707855999469757\n",
      "21  train loss:  0.2659425139427185\n",
      "22  train loss:  0.26349201798439026\n",
      "23  train loss:  0.26212847232818604\n",
      "24  train loss:  0.2595769464969635\n",
      "25  train loss:  0.25572359561920166\n",
      "26  train loss:  0.2525104582309723\n",
      "27  train loss:  0.2502877414226532\n",
      "28  train loss:  0.2479296624660492\n",
      "29  train loss:  0.2442581057548523\n",
      "30  train loss:  0.2399434894323349\n",
      "31  train loss:  0.2368859499692917\n",
      "32  train loss:  0.23405499756336212\n",
      "33  train loss:  0.2323184758424759\n",
      "34  train loss:  0.2295326590538025\n",
      "35  train loss:  0.2270556092262268\n",
      "36  train loss:  0.22502200305461884\n",
      "37  train loss:  0.22267840802669525\n",
      "38  train loss:  0.220953568816185\n",
      "39  train loss:  0.21886609494686127\n",
      "40  train loss:  0.2173466980457306\n",
      "41  train loss:  0.21580488979816437\n",
      "42  train loss:  0.21388286352157593\n",
      "43  train loss:  0.2114935964345932\n",
      "44  train loss:  0.20931969583034515\n",
      "45  train loss:  0.20788773894309998\n",
      "46  train loss:  0.20614974200725555\n",
      "47  train loss:  0.20446953177452087\n",
      "48  train loss:  0.2025078535079956\n",
      "49  train loss:  0.20104755461215973\n",
      "50  train loss:  0.19980916380882263\n",
      "51  train loss:  0.19845858216285706\n",
      "52  train loss:  0.19720415771007538\n",
      "53  train loss:  0.1959698647260666\n",
      "54  train loss:  0.19487136602401733\n",
      "55  train loss:  0.1938965916633606\n",
      "56  train loss:  0.1928471177816391\n",
      "57  train loss:  0.19158199429512024\n",
      "58  train loss:  0.19060373306274414\n",
      "59  train loss:  0.1892952024936676\n",
      "60  train loss:  0.1880180537700653\n",
      "61  train loss:  0.18681393563747406\n",
      "62  train loss:  0.18564251065254211\n",
      "63  train loss:  0.1845281571149826\n",
      "64  train loss:  0.18291300535202026\n",
      "65  train loss:  0.18176062405109406\n",
      "66  train loss:  0.18061023950576782\n",
      "67  train loss:  0.17952343821525574\n",
      "68  train loss:  0.17844383418560028\n",
      "69  train loss:  0.17757293581962585\n",
      "70  train loss:  0.1764955073595047\n",
      "71  train loss:  0.17543496191501617\n",
      "72  train loss:  0.1743050068616867\n",
      "73  train loss:  0.17328573763370514\n",
      "74  train loss:  0.17200252413749695\n",
      "75  train loss:  0.17084287106990814\n",
      "76  train loss:  0.16958782076835632\n",
      "77  train loss:  0.1686049848794937\n",
      "78  train loss:  0.16704542934894562\n",
      "79  train loss:  0.16658678650856018\n",
      "80  train loss:  0.16527573764324188\n",
      "81  train loss:  0.16478745639324188\n",
      "82  train loss:  0.16286031901836395\n",
      "83  train loss:  0.16120277345180511\n",
      "84  train loss:  0.15964341163635254\n",
      "85  train loss:  0.15715447068214417\n",
      "86  train loss:  0.15556266903877258\n",
      "87  train loss:  0.15410427749156952\n",
      "88  train loss:  0.15270370244979858\n",
      "89  train loss:  0.15242086350917816\n",
      "90  train loss:  0.15100452303886414\n",
      "91  train loss:  0.1500689685344696\n",
      "92  train loss:  0.1482345014810562\n",
      "93  train loss:  0.14763081073760986\n",
      "94  train loss:  0.14602051675319672\n",
      "95  train loss:  0.14506672322750092\n",
      "96  train loss:  0.1438843309879303\n",
      "97  train loss:  0.1428275853395462\n",
      "98  train loss:  0.14179222285747528\n",
      "99  train loss:  0.1411268264055252\n",
      "test acc (%):  tensor(78.2954)\n",
      "0  train loss:  0.5952813029289246\n",
      "1  train loss:  0.5055832862854004\n",
      "2  train loss:  0.4421331286430359\n",
      "3  train loss:  0.41388508677482605\n",
      "4  train loss:  0.3868199288845062\n",
      "5  train loss:  0.3683190643787384\n",
      "6  train loss:  0.3561042547225952\n",
      "7  train loss:  0.34276366233825684\n",
      "8  train loss:  0.3324619233608246\n",
      "9  train loss:  0.31900346279144287\n",
      "10  train loss:  0.31511053442955017\n",
      "11  train loss:  0.31119051575660706\n",
      "12  train loss:  0.3070910573005676\n",
      "13  train loss:  0.3021579682826996\n",
      "14  train loss:  0.2996339499950409\n",
      "15  train loss:  0.29496851563453674\n",
      "16  train loss:  0.29051679372787476\n",
      "17  train loss:  0.2871374785900116\n",
      "18  train loss:  0.28403374552726746\n",
      "19  train loss:  0.2804664969444275\n",
      "20  train loss:  0.27761635184288025\n",
      "21  train loss:  0.27465304732322693\n",
      "22  train loss:  0.27025240659713745\n",
      "23  train loss:  0.2669770419597626\n",
      "24  train loss:  0.26455122232437134\n",
      "25  train loss:  0.26221203804016113\n",
      "26  train loss:  0.25964251160621643\n",
      "27  train loss:  0.25742775201797485\n",
      "28  train loss:  0.25596433877944946\n",
      "29  train loss:  0.2528529167175293\n",
      "30  train loss:  0.251126766204834\n",
      "31  train loss:  0.2485491782426834\n",
      "32  train loss:  0.24625900387763977\n",
      "33  train loss:  0.24504967033863068\n",
      "34  train loss:  0.24199837446212769\n",
      "35  train loss:  0.2393885850906372\n",
      "36  train loss:  0.2374638170003891\n",
      "37  train loss:  0.2356560230255127\n",
      "38  train loss:  0.23439086973667145\n",
      "39  train loss:  0.23332907259464264\n",
      "40  train loss:  0.23170489072799683\n",
      "41  train loss:  0.2302696704864502\n",
      "42  train loss:  0.228826642036438\n",
      "43  train loss:  0.22689783573150635\n",
      "44  train loss:  0.2249682992696762\n",
      "45  train loss:  0.22324852645397186\n",
      "46  train loss:  0.2213498055934906\n",
      "47  train loss:  0.22071394324302673\n",
      "48  train loss:  0.2179732769727707\n",
      "49  train loss:  0.2169794738292694\n",
      "50  train loss:  0.2155025601387024\n",
      "51  train loss:  0.21371036767959595\n",
      "52  train loss:  0.2129271775484085\n",
      "53  train loss:  0.21133744716644287\n",
      "54  train loss:  0.21037523448467255\n",
      "55  train loss:  0.20939470827579498\n",
      "56  train loss:  0.2085421085357666\n",
      "57  train loss:  0.2075672298669815\n",
      "58  train loss:  0.20619286596775055\n",
      "59  train loss:  0.20526494085788727\n",
      "60  train loss:  0.20462563633918762\n",
      "61  train loss:  0.2037879079580307\n",
      "62  train loss:  0.20280854403972626\n",
      "63  train loss:  0.2015198916196823\n",
      "64  train loss:  0.20049984753131866\n",
      "65  train loss:  0.19976995885372162\n",
      "66  train loss:  0.19885759055614471\n",
      "67  train loss:  0.19793029129505157\n",
      "68  train loss:  0.19577530026435852\n",
      "69  train loss:  0.1947965770959854\n",
      "70  train loss:  0.19394966959953308\n",
      "71  train loss:  0.19318851828575134\n",
      "72  train loss:  0.19241198897361755\n",
      "73  train loss:  0.19164392352104187\n",
      "74  train loss:  0.19072197377681732\n",
      "75  train loss:  0.18941737711429596\n",
      "76  train loss:  0.18812879920005798\n",
      "77  train loss:  0.18715082108974457\n",
      "78  train loss:  0.18620750308036804\n",
      "79  train loss:  0.18513207137584686\n",
      "80  train loss:  0.18396234512329102\n",
      "81  train loss:  0.18291927874088287\n",
      "82  train loss:  0.18199583888053894\n",
      "83  train loss:  0.18113870918750763\n",
      "84  train loss:  0.18044917285442352\n",
      "85  train loss:  0.17983108758926392\n",
      "86  train loss:  0.17913112044334412\n",
      "87  train loss:  0.17865127325057983\n",
      "88  train loss:  0.17791828513145447\n",
      "89  train loss:  0.17676770687103271\n",
      "90  train loss:  0.1758868396282196\n",
      "91  train loss:  0.1749897599220276\n",
      "92  train loss:  0.17394988238811493\n",
      "93  train loss:  0.1727190613746643\n",
      "94  train loss:  0.17121021449565887\n",
      "95  train loss:  0.16983170807361603\n",
      "96  train loss:  0.16887162625789642\n",
      "97  train loss:  0.16775423288345337\n",
      "98  train loss:  0.1669565886259079\n",
      "99  train loss:  0.1659158319234848\n",
      "test acc (%):  tensor(79.0079)\n",
      "0  train loss:  0.5771411657333374\n",
      "1  train loss:  0.4807465374469757\n",
      "2  train loss:  0.43177491426467896\n",
      "3  train loss:  0.40313583612442017\n",
      "4  train loss:  0.3883640468120575\n",
      "5  train loss:  0.3766516447067261\n",
      "6  train loss:  0.362678587436676\n",
      "7  train loss:  0.35583093762397766\n",
      "8  train loss:  0.342126727104187\n",
      "9  train loss:  0.3338657319545746\n",
      "10  train loss:  0.33048200607299805\n",
      "11  train loss:  0.3290613889694214\n",
      "12  train loss:  0.32512927055358887\n",
      "13  train loss:  0.31914106011390686\n",
      "14  train loss:  0.31606850028038025\n",
      "15  train loss:  0.30944374203681946\n",
      "16  train loss:  0.3101392686367035\n",
      "17  train loss:  0.30339211225509644\n",
      "18  train loss:  0.29807600378990173\n",
      "19  train loss:  0.2961481809616089\n",
      "20  train loss:  0.29078900814056396\n",
      "21  train loss:  0.2879319489002228\n",
      "22  train loss:  0.28500816226005554\n",
      "23  train loss:  0.28073838353157043\n",
      "24  train loss:  0.2753140926361084\n",
      "25  train loss:  0.27132585644721985\n",
      "26  train loss:  0.26905500888824463\n",
      "27  train loss:  0.2651439905166626\n",
      "28  train loss:  0.26214107871055603\n",
      "29  train loss:  0.26060763001441956\n",
      "30  train loss:  0.2559613883495331\n",
      "31  train loss:  0.2549988031387329\n",
      "32  train loss:  0.250572144985199\n",
      "33  train loss:  0.24927304685115814\n",
      "34  train loss:  0.2466730773448944\n",
      "35  train loss:  0.24525578320026398\n",
      "36  train loss:  0.24235393106937408\n",
      "37  train loss:  0.24073556065559387\n",
      "38  train loss:  0.23886975646018982\n",
      "39  train loss:  0.23710162937641144\n",
      "40  train loss:  0.23475845158100128\n",
      "41  train loss:  0.2322254180908203\n",
      "42  train loss:  0.2298605591058731\n",
      "43  train loss:  0.22731874883174896\n",
      "44  train loss:  0.22535324096679688\n",
      "45  train loss:  0.223314106464386\n",
      "46  train loss:  0.2211674153804779\n",
      "47  train loss:  0.21933205425739288\n",
      "48  train loss:  0.21784983575344086\n",
      "49  train loss:  0.2161860316991806\n",
      "50  train loss:  0.21463949978351593\n",
      "51  train loss:  0.21331724524497986\n",
      "52  train loss:  0.2116420567035675\n",
      "53  train loss:  0.21014006435871124\n",
      "54  train loss:  0.20855651795864105\n",
      "55  train loss:  0.20702189207077026\n",
      "56  train loss:  0.20546869933605194\n",
      "57  train loss:  0.20358382165431976\n",
      "58  train loss:  0.20161187648773193\n",
      "59  train loss:  0.1999509632587433\n",
      "60  train loss:  0.19840428233146667\n",
      "61  train loss:  0.19734624028205872\n",
      "62  train loss:  0.19577433168888092\n",
      "63  train loss:  0.19441799819469452\n",
      "64  train loss:  0.19061937928199768\n",
      "65  train loss:  0.18886874616146088\n",
      "66  train loss:  0.1856745332479477\n",
      "67  train loss:  0.18417276442050934\n",
      "68  train loss:  0.18325598537921906\n",
      "69  train loss:  0.18297193944454193\n",
      "70  train loss:  0.1815820038318634\n",
      "71  train loss:  0.1807638555765152\n",
      "72  train loss:  0.17969505488872528\n",
      "73  train loss:  0.17948313057422638\n",
      "74  train loss:  0.17822197079658508\n",
      "75  train loss:  0.17775873839855194\n",
      "76  train loss:  0.17657414078712463\n",
      "77  train loss:  0.17598627507686615\n",
      "78  train loss:  0.17513909935951233\n",
      "79  train loss:  0.17469018697738647\n",
      "80  train loss:  0.17368339002132416\n",
      "81  train loss:  0.17328894138336182\n",
      "82  train loss:  0.17251737415790558\n",
      "83  train loss:  0.1717177778482437\n",
      "84  train loss:  0.17146721482276917\n",
      "85  train loss:  0.17030486464500427\n",
      "86  train loss:  0.16985498368740082\n",
      "87  train loss:  0.16887836158275604\n",
      "88  train loss:  0.16800309717655182\n",
      "89  train loss:  0.16706997156143188\n",
      "90  train loss:  0.165411114692688\n",
      "91  train loss:  0.16348186135292053\n",
      "92  train loss:  0.16308051347732544\n",
      "93  train loss:  0.16179297864437103\n",
      "94  train loss:  0.16157804429531097\n",
      "95  train loss:  0.16089114546775818\n",
      "96  train loss:  0.15974614024162292\n",
      "97  train loss:  0.1583767533302307\n",
      "98  train loss:  0.15876126289367676\n",
      "99  train loss:  0.15773765742778778\n",
      "test acc (%):  tensor(77.7473)\n",
      "0  train loss:  0.5730273723602295\n",
      "1  train loss:  0.48495417833328247\n",
      "2  train loss:  0.42325544357299805\n",
      "3  train loss:  0.40893468260765076\n",
      "4  train loss:  0.38337087631225586\n",
      "5  train loss:  0.38224831223487854\n",
      "6  train loss:  0.368310809135437\n",
      "7  train loss:  0.3680822253227234\n",
      "8  train loss:  0.3646523356437683\n",
      "9  train loss:  0.36877307295799255\n",
      "10  train loss:  0.37503522634506226\n",
      "11  train loss:  0.37641441822052\n",
      "12  train loss:  0.3714218735694885\n",
      "13  train loss:  0.3611218333244324\n",
      "14  train loss:  0.3459044396877289\n",
      "15  train loss:  0.3300265371799469\n",
      "16  train loss:  0.31628817319869995\n",
      "17  train loss:  0.31875595450401306\n",
      "18  train loss:  0.3237794041633606\n",
      "19  train loss:  0.30634215474128723\n",
      "20  train loss:  0.3196316957473755\n",
      "21  train loss:  0.3111588656902313\n",
      "22  train loss:  0.295938640832901\n",
      "23  train loss:  0.29463544487953186\n",
      "24  train loss:  0.29078754782676697\n",
      "25  train loss:  0.2978917360305786\n",
      "26  train loss:  0.28964099287986755\n",
      "27  train loss:  0.29986631870269775\n",
      "28  train loss:  0.31719186902046204\n",
      "29  train loss:  0.3161481022834778\n",
      "30  train loss:  0.30495959520339966\n",
      "31  train loss:  0.2881273627281189\n",
      "32  train loss:  0.28270700573921204\n",
      "33  train loss:  0.2782202363014221\n",
      "34  train loss:  0.27315959334373474\n",
      "35  train loss:  0.2686854898929596\n",
      "36  train loss:  0.2656176686286926\n",
      "37  train loss:  0.26480722427368164\n",
      "38  train loss:  0.26495596766471863\n",
      "39  train loss:  0.26158982515335083\n",
      "40  train loss:  0.2579096257686615\n",
      "41  train loss:  0.2568899095058441\n",
      "42  train loss:  0.25399696826934814\n",
      "43  train loss:  0.25035837292671204\n",
      "44  train loss:  0.2489178478717804\n",
      "45  train loss:  0.2468435913324356\n",
      "46  train loss:  0.24482513964176178\n",
      "47  train loss:  0.2431846261024475\n",
      "48  train loss:  0.24066013097763062\n",
      "49  train loss:  0.23879149556159973\n",
      "50  train loss:  0.23650145530700684\n",
      "51  train loss:  0.23415227234363556\n",
      "52  train loss:  0.23262189328670502\n",
      "53  train loss:  0.23196116089820862\n",
      "54  train loss:  0.23044821619987488\n",
      "55  train loss:  0.22817741334438324\n",
      "56  train loss:  0.22685198485851288\n",
      "57  train loss:  0.22414469718933105\n",
      "58  train loss:  0.22181545197963715\n",
      "59  train loss:  0.22153934836387634\n",
      "60  train loss:  0.21906204521656036\n",
      "61  train loss:  0.21817171573638916\n",
      "62  train loss:  0.21766336262226105\n",
      "63  train loss:  0.2157042771577835\n",
      "64  train loss:  0.2156621217727661\n",
      "65  train loss:  0.21391813457012177\n",
      "66  train loss:  0.2123705893754959\n",
      "67  train loss:  0.21184560656547546\n",
      "68  train loss:  0.20984283089637756\n",
      "69  train loss:  0.20775121450424194\n",
      "70  train loss:  0.20680420100688934\n",
      "71  train loss:  0.20579835772514343\n",
      "72  train loss:  0.20433159172534943\n",
      "73  train loss:  0.20289087295532227\n",
      "74  train loss:  0.2020353227853775\n",
      "75  train loss:  0.20108650624752045\n",
      "76  train loss:  0.2000773549079895\n",
      "77  train loss:  0.1991836428642273\n",
      "78  train loss:  0.19779689610004425\n",
      "79  train loss:  0.19588394463062286\n",
      "80  train loss:  0.19539837539196014\n",
      "81  train loss:  0.19393675029277802\n",
      "82  train loss:  0.19338549673557281\n",
      "83  train loss:  0.19262388348579407\n",
      "84  train loss:  0.19119009375572205\n",
      "85  train loss:  0.19045639038085938\n",
      "86  train loss:  0.18929460644721985\n",
      "87  train loss:  0.18894948065280914\n",
      "88  train loss:  0.1878582239151001\n",
      "89  train loss:  0.1869521141052246\n",
      "90  train loss:  0.18614009022712708\n",
      "91  train loss:  0.1853276640176773\n",
      "92  train loss:  0.18471460044384003\n",
      "93  train loss:  0.18393760919570923\n",
      "94  train loss:  0.1831366866827011\n",
      "95  train loss:  0.18251989781856537\n",
      "96  train loss:  0.181794673204422\n",
      "97  train loss:  0.1806105375289917\n",
      "98  train loss:  0.17962771654129028\n",
      "99  train loss:  0.17859043180942535\n",
      "test acc (%):  tensor(80.1315)\n",
      "0  train loss:  0.5817544460296631\n",
      "1  train loss:  0.491591215133667\n",
      "2  train loss:  0.44177889823913574\n",
      "3  train loss:  0.41296109557151794\n",
      "4  train loss:  0.3838618993759155\n",
      "5  train loss:  0.36919814348220825\n",
      "6  train loss:  0.3642840087413788\n",
      "7  train loss:  0.3604939877986908\n",
      "8  train loss:  0.35489121079444885\n",
      "9  train loss:  0.35153403878211975\n",
      "10  train loss:  0.34786200523376465\n",
      "11  train loss:  0.3407573699951172\n",
      "12  train loss:  0.33745718002319336\n",
      "13  train loss:  0.3339904546737671\n",
      "14  train loss:  0.32715708017349243\n",
      "15  train loss:  0.31972619891166687\n",
      "16  train loss:  0.31587544083595276\n",
      "17  train loss:  0.30886414647102356\n",
      "18  train loss:  0.30100950598716736\n",
      "19  train loss:  0.297524094581604\n",
      "20  train loss:  0.29226621985435486\n",
      "21  train loss:  0.28513556718826294\n",
      "22  train loss:  0.27996182441711426\n",
      "23  train loss:  0.2740650773048401\n",
      "24  train loss:  0.2704025208950043\n",
      "25  train loss:  0.2633655369281769\n",
      "26  train loss:  0.25993311405181885\n",
      "27  train loss:  0.2562559247016907\n",
      "28  train loss:  0.2536860704421997\n",
      "29  train loss:  0.25200897455215454\n",
      "30  train loss:  0.2498982697725296\n",
      "31  train loss:  0.2501794099807739\n",
      "32  train loss:  0.25014129281044006\n",
      "33  train loss:  0.2481384128332138\n",
      "34  train loss:  0.24431565403938293\n",
      "35  train loss:  0.24051916599273682\n",
      "36  train loss:  0.24195356667041779\n",
      "37  train loss:  0.23643146455287933\n",
      "38  train loss:  0.23907482624053955\n",
      "39  train loss:  0.23534812033176422\n",
      "40  train loss:  0.23019805550575256\n",
      "41  train loss:  0.22965899109840393\n",
      "42  train loss:  0.22840698063373566\n",
      "43  train loss:  0.22432391345500946\n",
      "44  train loss:  0.22260667383670807\n",
      "45  train loss:  0.2226419597864151\n",
      "46  train loss:  0.22012002766132355\n",
      "47  train loss:  0.2177484631538391\n",
      "48  train loss:  0.21745792031288147\n",
      "49  train loss:  0.21485565602779388\n",
      "50  train loss:  0.21330209076404572\n",
      "51  train loss:  0.21203109622001648\n",
      "52  train loss:  0.21105428040027618\n",
      "53  train loss:  0.20862528681755066\n",
      "54  train loss:  0.2076612114906311\n",
      "55  train loss:  0.20658966898918152\n",
      "56  train loss:  0.20551569759845734\n",
      "57  train loss:  0.20363855361938477\n",
      "58  train loss:  0.2029455304145813\n",
      "59  train loss:  0.2014913111925125\n",
      "60  train loss:  0.19935156404972076\n",
      "61  train loss:  0.19851312041282654\n",
      "62  train loss:  0.19608454406261444\n",
      "63  train loss:  0.1950528770685196\n",
      "64  train loss:  0.19321274757385254\n",
      "65  train loss:  0.1918725222349167\n",
      "66  train loss:  0.19089239835739136\n",
      "67  train loss:  0.18889816105365753\n",
      "68  train loss:  0.1878662258386612\n",
      "69  train loss:  0.1861565113067627\n",
      "70  train loss:  0.18476954102516174\n",
      "71  train loss:  0.183688685297966\n",
      "72  train loss:  0.18260319530963898\n",
      "73  train loss:  0.18172013759613037\n",
      "74  train loss:  0.18037967383861542\n",
      "75  train loss:  0.18000757694244385\n",
      "76  train loss:  0.1793496459722519\n",
      "77  train loss:  0.17885854840278625\n",
      "78  train loss:  0.17712678015232086\n",
      "79  train loss:  0.17730660736560822\n",
      "80  train loss:  0.1749563217163086\n",
      "81  train loss:  0.17514243721961975\n",
      "82  train loss:  0.17371340095996857\n",
      "83  train loss:  0.1728793978691101\n",
      "84  train loss:  0.17274510860443115\n",
      "85  train loss:  0.17112143337726593\n",
      "86  train loss:  0.17114968597888947\n",
      "87  train loss:  0.16969023644924164\n",
      "88  train loss:  0.16841596364974976\n",
      "89  train loss:  0.16726547479629517\n",
      "90  train loss:  0.16648685932159424\n",
      "91  train loss:  0.16461168229579926\n",
      "92  train loss:  0.16469797492027283\n",
      "93  train loss:  0.16352613270282745\n",
      "94  train loss:  0.1636880338191986\n",
      "95  train loss:  0.16556313633918762\n",
      "96  train loss:  0.16053473949432373\n",
      "97  train loss:  0.1632620245218277\n",
      "98  train loss:  0.16651812195777893\n",
      "99  train loss:  0.15955163538455963\n",
      "test acc (%):  tensor(77.7199)\n",
      "0  train loss:  0.592974066734314\n",
      "1  train loss:  0.46384337544441223\n",
      "2  train loss:  0.422057181596756\n",
      "3  train loss:  0.39216023683547974\n",
      "4  train loss:  0.38441309332847595\n",
      "5  train loss:  0.3581271469593048\n",
      "6  train loss:  0.35272854566574097\n",
      "7  train loss:  0.34976518154144287\n",
      "8  train loss:  0.32897186279296875\n",
      "9  train loss:  0.322250634431839\n",
      "10  train loss:  0.3263651132583618\n",
      "11  train loss:  0.32458046078681946\n",
      "12  train loss:  0.32103246450424194\n",
      "13  train loss:  0.3150913119316101\n",
      "14  train loss:  0.30792465806007385\n",
      "15  train loss:  0.3015420138835907\n",
      "16  train loss:  0.2976868748664856\n",
      "17  train loss:  0.2944239377975464\n",
      "18  train loss:  0.2896953821182251\n",
      "19  train loss:  0.28546518087387085\n",
      "20  train loss:  0.278917521238327\n",
      "21  train loss:  0.27522537112236023\n",
      "22  train loss:  0.27106979489326477\n",
      "23  train loss:  0.26676318049430847\n",
      "24  train loss:  0.26318323612213135\n",
      "25  train loss:  0.259846568107605\n",
      "26  train loss:  0.25525689125061035\n",
      "27  train loss:  0.2506660223007202\n",
      "28  train loss:  0.2483101487159729\n",
      "29  train loss:  0.2439550757408142\n",
      "30  train loss:  0.24313493072986603\n",
      "31  train loss:  0.24031534790992737\n",
      "32  train loss:  0.23860614001750946\n",
      "33  train loss:  0.2371603399515152\n",
      "34  train loss:  0.2350171059370041\n",
      "35  train loss:  0.23292183876037598\n",
      "36  train loss:  0.231180340051651\n",
      "37  train loss:  0.22892895340919495\n",
      "38  train loss:  0.22631897032260895\n",
      "39  train loss:  0.2243862897157669\n",
      "40  train loss:  0.2224051058292389\n",
      "41  train loss:  0.220992311835289\n",
      "42  train loss:  0.2196309119462967\n",
      "43  train loss:  0.2177693247795105\n",
      "44  train loss:  0.21629613637924194\n",
      "45  train loss:  0.2150784730911255\n",
      "46  train loss:  0.21402637660503387\n",
      "47  train loss:  0.21300195157527924\n",
      "48  train loss:  0.21176137030124664\n",
      "49  train loss:  0.2112223505973816\n",
      "50  train loss:  0.21019750833511353\n",
      "51  train loss:  0.20890837907791138\n",
      "52  train loss:  0.20784838497638702\n",
      "53  train loss:  0.20540675520896912\n",
      "54  train loss:  0.20364797115325928\n",
      "55  train loss:  0.20186489820480347\n",
      "56  train loss:  0.20077252388000488\n",
      "57  train loss:  0.1994427591562271\n",
      "58  train loss:  0.19868187606334686\n",
      "59  train loss:  0.1979386955499649\n",
      "60  train loss:  0.19718000292778015\n",
      "61  train loss:  0.19629843533039093\n",
      "62  train loss:  0.1954527050256729\n",
      "63  train loss:  0.19484783709049225\n",
      "64  train loss:  0.19420990347862244\n",
      "65  train loss:  0.19367626309394836\n",
      "66  train loss:  0.19303035736083984\n",
      "67  train loss:  0.19253623485565186\n",
      "68  train loss:  0.1920628547668457\n",
      "69  train loss:  0.1913193017244339\n",
      "70  train loss:  0.19018909335136414\n",
      "71  train loss:  0.18920254707336426\n",
      "72  train loss:  0.18909847736358643\n",
      "73  train loss:  0.1874624490737915\n",
      "74  train loss:  0.18791081011295319\n",
      "75  train loss:  0.18671225011348724\n",
      "76  train loss:  0.185905322432518\n",
      "77  train loss:  0.1860475391149521\n",
      "78  train loss:  0.18534010648727417\n",
      "79  train loss:  0.18476790189743042\n",
      "80  train loss:  0.18412275612354279\n",
      "81  train loss:  0.1837327480316162\n",
      "82  train loss:  0.18335773050785065\n",
      "83  train loss:  0.18303266167640686\n",
      "84  train loss:  0.18234235048294067\n",
      "85  train loss:  0.1818164736032486\n",
      "86  train loss:  0.1814877688884735\n",
      "87  train loss:  0.1811569780111313\n",
      "88  train loss:  0.18043112754821777\n",
      "89  train loss:  0.1799660474061966\n",
      "90  train loss:  0.17883315682411194\n",
      "91  train loss:  0.18114334344863892\n",
      "92  train loss:  0.17836876213550568\n",
      "93  train loss:  0.18500955402851105\n",
      "94  train loss:  0.17958132922649384\n",
      "95  train loss:  0.17709583044052124\n",
      "96  train loss:  0.18565905094146729\n",
      "97  train loss:  0.17686457931995392\n",
      "98  train loss:  0.1856512874364853\n",
      "99  train loss:  0.17513708770275116\n",
      "test acc (%):  tensor(78.8709)\n",
      "0  train loss:  0.711901068687439\n",
      "1  train loss:  0.5186682939529419\n",
      "2  train loss:  0.4483875036239624\n",
      "3  train loss:  0.4016226828098297\n",
      "4  train loss:  0.3741116225719452\n",
      "5  train loss:  0.37127432227134705\n",
      "6  train loss:  0.35213637351989746\n",
      "7  train loss:  0.3453505337238312\n",
      "8  train loss:  0.34819021821022034\n",
      "9  train loss:  0.3445453345775604\n",
      "10  train loss:  0.33578458428382874\n",
      "11  train loss:  0.32342076301574707\n",
      "12  train loss:  0.31589141488075256\n",
      "13  train loss:  0.30855125188827515\n",
      "14  train loss:  0.3062843680381775\n",
      "15  train loss:  0.3019377291202545\n",
      "16  train loss:  0.2968076169490814\n",
      "17  train loss:  0.289471298456192\n",
      "18  train loss:  0.2812657952308655\n",
      "19  train loss:  0.2828906774520874\n",
      "20  train loss:  0.2766992449760437\n",
      "21  train loss:  0.2700127363204956\n",
      "22  train loss:  0.27097445726394653\n",
      "23  train loss:  0.26913273334503174\n",
      "24  train loss:  0.2614891231060028\n",
      "25  train loss:  0.26149845123291016\n",
      "26  train loss:  0.2609107792377472\n",
      "27  train loss:  0.2552841603755951\n",
      "28  train loss:  0.25034233927726746\n",
      "29  train loss:  0.25001809000968933\n",
      "30  train loss:  0.2467968463897705\n",
      "31  train loss:  0.24245122075080872\n",
      "32  train loss:  0.2415924221277237\n",
      "33  train loss:  0.24034248292446136\n",
      "34  train loss:  0.23749050498008728\n",
      "35  train loss:  0.2345636636018753\n",
      "36  train loss:  0.23389658331871033\n",
      "37  train loss:  0.2310274839401245\n",
      "38  train loss:  0.22929544746875763\n",
      "39  train loss:  0.22763343155384064\n",
      "40  train loss:  0.22565345466136932\n",
      "41  train loss:  0.2222772091627121\n",
      "42  train loss:  0.22015982866287231\n",
      "43  train loss:  0.2187354862689972\n",
      "44  train loss:  0.2170388549566269\n",
      "45  train loss:  0.21505902707576752\n",
      "46  train loss:  0.21287859976291656\n",
      "47  train loss:  0.21121780574321747\n",
      "48  train loss:  0.2094396948814392\n",
      "49  train loss:  0.20766916871070862\n",
      "50  train loss:  0.20592227578163147\n",
      "51  train loss:  0.20447401702404022\n",
      "52  train loss:  0.20335842669010162\n",
      "53  train loss:  0.2019915133714676\n",
      "54  train loss:  0.20052485167980194\n",
      "55  train loss:  0.19870202243328094\n",
      "56  train loss:  0.197114497423172\n",
      "57  train loss:  0.19587303698062897\n",
      "58  train loss:  0.19447605311870575\n",
      "59  train loss:  0.1933315545320511\n",
      "60  train loss:  0.19216138124465942\n",
      "61  train loss:  0.19037215411663055\n",
      "62  train loss:  0.18995216488838196\n",
      "63  train loss:  0.18867968022823334\n",
      "64  train loss:  0.18804772198200226\n",
      "65  train loss:  0.1870095133781433\n",
      "66  train loss:  0.18551313877105713\n",
      "67  train loss:  0.18459832668304443\n",
      "68  train loss:  0.1835726946592331\n",
      "69  train loss:  0.1824585497379303\n",
      "70  train loss:  0.1816222071647644\n",
      "71  train loss:  0.18038702011108398\n",
      "72  train loss:  0.17928341031074524\n",
      "73  train loss:  0.17816747725009918\n",
      "74  train loss:  0.17662453651428223\n",
      "75  train loss:  0.1754871904850006\n",
      "76  train loss:  0.17492413520812988\n",
      "77  train loss:  0.17401237785816193\n",
      "78  train loss:  0.17276246845722198\n",
      "79  train loss:  0.17225629091262817\n",
      "80  train loss:  0.17161621153354645\n",
      "81  train loss:  0.1708257794380188\n",
      "82  train loss:  0.17020682990550995\n",
      "83  train loss:  0.16952906548976898\n",
      "84  train loss:  0.1688421368598938\n",
      "85  train loss:  0.16793616116046906\n",
      "86  train loss:  0.1671665608882904\n",
      "87  train loss:  0.1664593368768692\n",
      "88  train loss:  0.16555358469486237\n",
      "89  train loss:  0.16493065655231476\n",
      "90  train loss:  0.1646207720041275\n",
      "91  train loss:  0.1638265997171402\n",
      "92  train loss:  0.1630696952342987\n",
      "93  train loss:  0.1623358279466629\n",
      "94  train loss:  0.16150549054145813\n",
      "95  train loss:  0.1606411635875702\n",
      "96  train loss:  0.15999414026737213\n",
      "97  train loss:  0.1592969298362732\n",
      "98  train loss:  0.15872295200824738\n",
      "99  train loss:  0.1577826589345932\n",
      "test acc (%):  tensor(80.1590)\n",
      "0  train loss:  0.5567309856414795\n",
      "1  train loss:  0.40858107805252075\n",
      "2  train loss:  0.36619919538497925\n",
      "3  train loss:  0.34453895688056946\n",
      "4  train loss:  0.3332791328430176\n",
      "5  train loss:  0.3242611885070801\n",
      "6  train loss:  0.31138864159584045\n",
      "7  train loss:  0.30325332283973694\n",
      "8  train loss:  0.29955676198005676\n",
      "9  train loss:  0.29646581411361694\n",
      "10  train loss:  0.2899335026741028\n",
      "11  train loss:  0.2841472923755646\n",
      "12  train loss:  0.27955126762390137\n",
      "13  train loss:  0.27441319823265076\n",
      "14  train loss:  0.26940304040908813\n",
      "15  train loss:  0.26388847827911377\n",
      "16  train loss:  0.25881263613700867\n",
      "17  train loss:  0.2552766799926758\n",
      "18  train loss:  0.25088828802108765\n",
      "19  train loss:  0.24821197986602783\n",
      "20  train loss:  0.2434455305337906\n",
      "21  train loss:  0.23878656327724457\n",
      "22  train loss:  0.2348984032869339\n",
      "23  train loss:  0.2320583611726761\n",
      "24  train loss:  0.22947664558887482\n",
      "25  train loss:  0.22634321451187134\n",
      "26  train loss:  0.22630003094673157\n",
      "27  train loss:  0.22381579875946045\n",
      "28  train loss:  0.22179318964481354\n",
      "29  train loss:  0.21927478909492493\n",
      "30  train loss:  0.2179505079984665\n",
      "31  train loss:  0.21595045924186707\n",
      "32  train loss:  0.2143687605857849\n",
      "33  train loss:  0.21232984960079193\n",
      "34  train loss:  0.21023547649383545\n",
      "35  train loss:  0.20787404477596283\n",
      "36  train loss:  0.20648865401744843\n",
      "37  train loss:  0.20480260252952576\n",
      "38  train loss:  0.20330902934074402\n",
      "39  train loss:  0.20158539712429047\n",
      "40  train loss:  0.19999340176582336\n",
      "41  train loss:  0.19854271411895752\n",
      "42  train loss:  0.1977454125881195\n",
      "43  train loss:  0.195806622505188\n",
      "44  train loss:  0.19318975508213043\n",
      "45  train loss:  0.1928635984659195\n",
      "46  train loss:  0.1900414377450943\n",
      "47  train loss:  0.18850693106651306\n",
      "48  train loss:  0.18652300536632538\n",
      "49  train loss:  0.1851169317960739\n",
      "50  train loss:  0.18209120631217957\n",
      "51  train loss:  0.18165655434131622\n",
      "52  train loss:  0.18002654612064362\n",
      "53  train loss:  0.17775559425354004\n",
      "54  train loss:  0.17676584422588348\n",
      "55  train loss:  0.17498166859149933\n",
      "56  train loss:  0.17394503951072693\n",
      "57  train loss:  0.17271271347999573\n",
      "58  train loss:  0.17092041671276093\n",
      "59  train loss:  0.17119652032852173\n",
      "60  train loss:  0.17024260759353638\n",
      "61  train loss:  0.16851581633090973\n",
      "62  train loss:  0.17107747495174408\n",
      "63  train loss:  0.17052680253982544\n",
      "64  train loss:  0.16991250216960907\n",
      "65  train loss:  0.16772456467151642\n",
      "66  train loss:  0.16579821705818176\n",
      "67  train loss:  0.16557788848876953\n",
      "68  train loss:  0.16379018127918243\n",
      "69  train loss:  0.16297686100006104\n",
      "70  train loss:  0.16220064461231232\n",
      "71  train loss:  0.16160482168197632\n",
      "72  train loss:  0.1594519466161728\n",
      "73  train loss:  0.15750151872634888\n",
      "74  train loss:  0.1552274227142334\n",
      "75  train loss:  0.15524853765964508\n",
      "76  train loss:  0.15519355237483978\n",
      "77  train loss:  0.15486735105514526\n",
      "78  train loss:  0.15134543180465698\n",
      "79  train loss:  0.1516055464744568\n",
      "80  train loss:  0.15104693174362183\n",
      "81  train loss:  0.1499962955713272\n",
      "82  train loss:  0.1488877683877945\n",
      "83  train loss:  0.14691796898841858\n",
      "84  train loss:  0.1492803990840912\n",
      "85  train loss:  0.1457207053899765\n",
      "86  train loss:  0.14843589067459106\n",
      "87  train loss:  0.14550626277923584\n",
      "88  train loss:  0.1453947126865387\n",
      "89  train loss:  0.1439249962568283\n",
      "90  train loss:  0.1422545313835144\n",
      "91  train loss:  0.1416568011045456\n",
      "92  train loss:  0.14207369089126587\n",
      "93  train loss:  0.1399102509021759\n",
      "94  train loss:  0.13949479162693024\n",
      "95  train loss:  0.138963982462883\n",
      "96  train loss:  0.1391357183456421\n",
      "97  train loss:  0.13712209463119507\n",
      "98  train loss:  0.13609124720096588\n",
      "99  train loss:  0.1357266753911972\n",
      "test acc (%):  tensor(79.1176)\n",
      "0  train loss:  0.6840641498565674\n",
      "1  train loss:  0.5520381331443787\n",
      "2  train loss:  0.49883899092674255\n",
      "3  train loss:  0.5030409097671509\n",
      "4  train loss:  0.4432462453842163\n",
      "5  train loss:  0.4354187846183777\n",
      "6  train loss:  0.41917723417282104\n",
      "7  train loss:  0.42072048783302307\n",
      "8  train loss:  0.41511812806129456\n",
      "9  train loss:  0.393966943025589\n",
      "10  train loss:  0.3875270485877991\n",
      "11  train loss:  0.38212713599205017\n",
      "12  train loss:  0.3749827444553375\n",
      "13  train loss:  0.3681817948818207\n",
      "14  train loss:  0.363163560628891\n",
      "15  train loss:  0.35611727833747864\n",
      "16  train loss:  0.35021263360977173\n",
      "17  train loss:  0.3455955386161804\n",
      "18  train loss:  0.3401397466659546\n",
      "19  train loss:  0.32972919940948486\n",
      "20  train loss:  0.31806936860084534\n",
      "21  train loss:  0.3093687891960144\n",
      "22  train loss:  0.30356892943382263\n",
      "23  train loss:  0.3000764548778534\n",
      "24  train loss:  0.29629820585250854\n",
      "25  train loss:  0.29424360394477844\n",
      "26  train loss:  0.29255375266075134\n",
      "27  train loss:  0.28859129548072815\n",
      "28  train loss:  0.2886642515659332\n",
      "29  train loss:  0.28037264943122864\n",
      "30  train loss:  0.2771550118923187\n",
      "31  train loss:  0.27575430274009705\n",
      "32  train loss:  0.2733018398284912\n",
      "33  train loss:  0.2690998911857605\n",
      "34  train loss:  0.2674625813961029\n",
      "35  train loss:  0.26674461364746094\n",
      "36  train loss:  0.26392489671707153\n",
      "37  train loss:  0.2596268951892853\n",
      "38  train loss:  0.2565275728702545\n",
      "39  train loss:  0.2547333836555481\n",
      "40  train loss:  0.253073513507843\n",
      "41  train loss:  0.2500613033771515\n",
      "42  train loss:  0.24796094000339508\n",
      "43  train loss:  0.2462015300989151\n",
      "44  train loss:  0.2440703809261322\n",
      "45  train loss:  0.24163447320461273\n",
      "46  train loss:  0.24023278057575226\n",
      "47  train loss:  0.23861557245254517\n",
      "48  train loss:  0.23647575080394745\n",
      "49  train loss:  0.2340199500322342\n",
      "50  train loss:  0.2315341681241989\n",
      "51  train loss:  0.22916820645332336\n",
      "52  train loss:  0.22696621716022491\n",
      "53  train loss:  0.22546210885047913\n",
      "54  train loss:  0.22367647290229797\n",
      "55  train loss:  0.2219349592924118\n",
      "56  train loss:  0.22025024890899658\n",
      "57  train loss:  0.2188616842031479\n",
      "58  train loss:  0.217411607503891\n",
      "59  train loss:  0.21620364487171173\n",
      "60  train loss:  0.21477067470550537\n",
      "61  train loss:  0.21368710696697235\n",
      "62  train loss:  0.21231943368911743\n",
      "63  train loss:  0.21069954335689545\n",
      "64  train loss:  0.20959247648715973\n",
      "65  train loss:  0.20826663076877594\n",
      "66  train loss:  0.2069261074066162\n",
      "67  train loss:  0.20595380663871765\n",
      "68  train loss:  0.20457851886749268\n",
      "69  train loss:  0.2034774273633957\n",
      "70  train loss:  0.20187874138355255\n",
      "71  train loss:  0.2006421834230423\n",
      "72  train loss:  0.19947347044944763\n",
      "73  train loss:  0.19837459921836853\n",
      "74  train loss:  0.19656971096992493\n",
      "75  train loss:  0.19570055603981018\n",
      "76  train loss:  0.1942492127418518\n",
      "77  train loss:  0.1934385448694229\n",
      "78  train loss:  0.19129177927970886\n",
      "79  train loss:  0.1901848465204239\n",
      "80  train loss:  0.18861214816570282\n",
      "81  train loss:  0.18771059811115265\n",
      "82  train loss:  0.1873513162136078\n",
      "83  train loss:  0.18549491465091705\n",
      "84  train loss:  0.18476638197898865\n",
      "85  train loss:  0.18445175886154175\n",
      "86  train loss:  0.18305885791778564\n",
      "87  train loss:  0.18094192445278168\n",
      "88  train loss:  0.17925916612148285\n",
      "89  train loss:  0.17855232954025269\n",
      "90  train loss:  0.17795754969120026\n",
      "91  train loss:  0.17615269124507904\n",
      "92  train loss:  0.17367325723171234\n",
      "93  train loss:  0.1736932098865509\n",
      "94  train loss:  0.17260926961898804\n",
      "95  train loss:  0.1727253943681717\n",
      "96  train loss:  0.1697898805141449\n",
      "97  train loss:  0.1693972647190094\n",
      "98  train loss:  0.16877995431423187\n",
      "99  train loss:  0.16725055873394012\n",
      "test acc (%):  tensor(80.1315)\n",
      "0  train loss:  0.6114200353622437\n",
      "1  train loss:  0.5353895425796509\n",
      "2  train loss:  0.4500758945941925\n",
      "3  train loss:  0.4183659553527832\n",
      "4  train loss:  0.3985878825187683\n",
      "5  train loss:  0.39583730697631836\n",
      "6  train loss:  0.385140985250473\n",
      "7  train loss:  0.3720773756504059\n",
      "8  train loss:  0.36037740111351013\n",
      "9  train loss:  0.3482867181301117\n",
      "10  train loss:  0.3400479853153229\n",
      "11  train loss:  0.3307840824127197\n",
      "12  train loss:  0.32490530610084534\n",
      "13  train loss:  0.3175618052482605\n",
      "14  train loss:  0.3141036331653595\n",
      "15  train loss:  0.3090236186981201\n",
      "16  train loss:  0.30317941308021545\n",
      "17  train loss:  0.2985832989215851\n",
      "18  train loss:  0.2922165095806122\n",
      "19  train loss:  0.2895668148994446\n",
      "20  train loss:  0.2858416438102722\n",
      "21  train loss:  0.28071507811546326\n",
      "22  train loss:  0.279689222574234\n",
      "23  train loss:  0.2773189842700958\n",
      "24  train loss:  0.27527686953544617\n",
      "25  train loss:  0.27123668789863586\n",
      "26  train loss:  0.2681867480278015\n",
      "27  train loss:  0.2645511329174042\n",
      "28  train loss:  0.26391905546188354\n",
      "29  train loss:  0.2611381411552429\n",
      "30  train loss:  0.25740641355514526\n",
      "31  train loss:  0.2541201412677765\n",
      "32  train loss:  0.25092998147010803\n",
      "33  train loss:  0.24772176146507263\n",
      "34  train loss:  0.24514058232307434\n",
      "35  train loss:  0.2433077096939087\n",
      "36  train loss:  0.2410127967596054\n",
      "37  train loss:  0.23818133771419525\n",
      "38  train loss:  0.23585523664951324\n",
      "39  train loss:  0.23507261276245117\n",
      "40  train loss:  0.23269514739513397\n",
      "41  train loss:  0.23071281611919403\n",
      "42  train loss:  0.22874006628990173\n",
      "43  train loss:  0.22675523161888123\n",
      "44  train loss:  0.22516275942325592\n",
      "45  train loss:  0.22350436449050903\n",
      "46  train loss:  0.2217433601617813\n",
      "47  train loss:  0.22002989053726196\n",
      "48  train loss:  0.21911998093128204\n",
      "49  train loss:  0.21755996346473694\n",
      "50  train loss:  0.21574154496192932\n",
      "51  train loss:  0.21423570811748505\n",
      "52  train loss:  0.212269127368927\n",
      "53  train loss:  0.21249981224536896\n",
      "54  train loss:  0.2103714644908905\n",
      "55  train loss:  0.20896083116531372\n",
      "56  train loss:  0.20782841742038727\n",
      "57  train loss:  0.20642895996570587\n",
      "58  train loss:  0.20451629161834717\n",
      "59  train loss:  0.20355018973350525\n",
      "60  train loss:  0.20266905426979065\n",
      "61  train loss:  0.20128870010375977\n",
      "62  train loss:  0.19970501959323883\n",
      "63  train loss:  0.19888630509376526\n",
      "64  train loss:  0.19778160750865936\n",
      "65  train loss:  0.19591233134269714\n",
      "66  train loss:  0.19484484195709229\n",
      "67  train loss:  0.19355525076389313\n",
      "68  train loss:  0.19350716471672058\n",
      "69  train loss:  0.19237858057022095\n",
      "70  train loss:  0.1912710964679718\n",
      "71  train loss:  0.19095849990844727\n",
      "72  train loss:  0.18931572139263153\n",
      "73  train loss:  0.18873068690299988\n",
      "74  train loss:  0.18774396181106567\n",
      "75  train loss:  0.18690475821495056\n",
      "76  train loss:  0.18595853447914124\n",
      "77  train loss:  0.18558986485004425\n",
      "78  train loss:  0.1846429407596588\n",
      "79  train loss:  0.18376986682415009\n",
      "80  train loss:  0.18319344520568848\n",
      "81  train loss:  0.18250297009944916\n",
      "82  train loss:  0.1818494200706482\n",
      "83  train loss:  0.18102529644966125\n",
      "84  train loss:  0.1804835945367813\n",
      "85  train loss:  0.1797480285167694\n",
      "86  train loss:  0.17851878702640533\n",
      "87  train loss:  0.17729534208774567\n",
      "88  train loss:  0.17653261125087738\n",
      "89  train loss:  0.17533494532108307\n",
      "90  train loss:  0.17468798160552979\n",
      "91  train loss:  0.1738429069519043\n",
      "92  train loss:  0.1729579120874405\n",
      "93  train loss:  0.17232590913772583\n",
      "94  train loss:  0.171373188495636\n",
      "95  train loss:  0.17079073190689087\n",
      "96  train loss:  0.17043182253837585\n",
      "97  train loss:  0.1697102189064026\n",
      "98  train loss:  0.16912919282913208\n",
      "99  train loss:  0.1686021387577057\n",
      "test acc (%):  tensor(79.0354)\n",
      "0  train loss:  0.6041744947433472\n",
      "1  train loss:  0.5263702273368835\n",
      "2  train loss:  0.4566992521286011\n",
      "3  train loss:  0.4136880934238434\n",
      "4  train loss:  0.4005473256111145\n",
      "5  train loss:  0.38911953568458557\n",
      "6  train loss:  0.3735165596008301\n",
      "7  train loss:  0.363187700510025\n",
      "8  train loss:  0.3523734211921692\n",
      "9  train loss:  0.3490130305290222\n",
      "10  train loss:  0.34701263904571533\n",
      "11  train loss:  0.3430872857570648\n",
      "12  train loss:  0.33321788907051086\n",
      "13  train loss:  0.3231770992279053\n",
      "14  train loss:  0.3203263282775879\n",
      "15  train loss:  0.31374478340148926\n",
      "16  train loss:  0.3032434284687042\n",
      "17  train loss:  0.29888850450515747\n",
      "18  train loss:  0.29603296518325806\n",
      "19  train loss:  0.2930147051811218\n",
      "20  train loss:  0.28859931230545044\n",
      "21  train loss:  0.28311216831207275\n",
      "22  train loss:  0.27794796228408813\n",
      "23  train loss:  0.27420109510421753\n",
      "24  train loss:  0.27137333154678345\n",
      "25  train loss:  0.266561359167099\n",
      "26  train loss:  0.26074543595314026\n",
      "27  train loss:  0.2603509724140167\n",
      "28  train loss:  0.25811493396759033\n",
      "29  train loss:  0.2560901939868927\n",
      "30  train loss:  0.2544091045856476\n",
      "31  train loss:  0.2523742914199829\n",
      "32  train loss:  0.2511559724807739\n",
      "33  train loss:  0.24942342936992645\n",
      "34  train loss:  0.24761810898780823\n",
      "35  train loss:  0.24634940922260284\n",
      "36  train loss:  0.24469634890556335\n",
      "37  train loss:  0.24321676790714264\n",
      "38  train loss:  0.24237996339797974\n",
      "39  train loss:  0.2413814514875412\n",
      "40  train loss:  0.239923894405365\n",
      "41  train loss:  0.23871102929115295\n",
      "42  train loss:  0.23768669366836548\n",
      "43  train loss:  0.2358642816543579\n",
      "44  train loss:  0.23470112681388855\n",
      "45  train loss:  0.23379842936992645\n",
      "46  train loss:  0.23283959925174713\n",
      "47  train loss:  0.23140165209770203\n",
      "48  train loss:  0.2300713211297989\n",
      "49  train loss:  0.22928999364376068\n",
      "50  train loss:  0.22807729244232178\n",
      "51  train loss:  0.22704409062862396\n",
      "52  train loss:  0.22565610706806183\n",
      "53  train loss:  0.2248828411102295\n",
      "54  train loss:  0.22312800586223602\n",
      "55  train loss:  0.22221161425113678\n",
      "56  train loss:  0.22093315422534943\n",
      "57  train loss:  0.21975727379322052\n",
      "58  train loss:  0.21871943771839142\n",
      "59  train loss:  0.21788649260997772\n",
      "60  train loss:  0.2173539251089096\n",
      "61  train loss:  0.2159881442785263\n",
      "62  train loss:  0.21497733891010284\n",
      "63  train loss:  0.21419720351696014\n",
      "64  train loss:  0.2131423056125641\n",
      "65  train loss:  0.2121550738811493\n",
      "66  train loss:  0.21126483380794525\n",
      "67  train loss:  0.21054428815841675\n",
      "68  train loss:  0.2097816914319992\n",
      "69  train loss:  0.20888620615005493\n",
      "70  train loss:  0.20856381952762604\n",
      "71  train loss:  0.20755892992019653\n",
      "72  train loss:  0.20699366927146912\n",
      "73  train loss:  0.20530255138874054\n",
      "74  train loss:  0.20425662398338318\n",
      "75  train loss:  0.20321126282215118\n",
      "76  train loss:  0.20253178477287292\n",
      "77  train loss:  0.2014809399843216\n",
      "78  train loss:  0.20062507688999176\n",
      "79  train loss:  0.20035997033119202\n",
      "80  train loss:  0.19938404858112335\n",
      "81  train loss:  0.19913145899772644\n",
      "82  train loss:  0.1983511596918106\n",
      "83  train loss:  0.1977236270904541\n",
      "84  train loss:  0.1967252492904663\n",
      "85  train loss:  0.19640542566776276\n",
      "86  train loss:  0.19565899670124054\n",
      "87  train loss:  0.1951787769794464\n",
      "88  train loss:  0.19421078264713287\n",
      "89  train loss:  0.19347414374351501\n",
      "90  train loss:  0.19342410564422607\n",
      "91  train loss:  0.19215257465839386\n",
      "92  train loss:  0.19143064320087433\n",
      "93  train loss:  0.19114303588867188\n",
      "94  train loss:  0.19116248190402985\n",
      "95  train loss:  0.1904243379831314\n",
      "96  train loss:  0.18932229280471802\n",
      "97  train loss:  0.18938730657100677\n",
      "98  train loss:  0.1892208755016327\n",
      "99  train loss:  0.18931294977664948\n",
      "test acc (%):  tensor(77.9392)\n",
      "0  train loss:  0.5519753098487854\n",
      "1  train loss:  0.4942505955696106\n",
      "2  train loss:  0.44619104266166687\n",
      "3  train loss:  0.41124075651168823\n",
      "4  train loss:  0.38385969400405884\n",
      "5  train loss:  0.3708910346031189\n",
      "6  train loss:  0.367607057094574\n",
      "7  train loss:  0.3556067943572998\n",
      "8  train loss:  0.35013678669929504\n",
      "9  train loss:  0.3473202884197235\n",
      "10  train loss:  0.34755823016166687\n",
      "11  train loss:  0.3459708094596863\n",
      "12  train loss:  0.33868759870529175\n",
      "13  train loss:  0.33682259917259216\n",
      "14  train loss:  0.3293391466140747\n",
      "15  train loss:  0.3251451849937439\n",
      "16  train loss:  0.32100406289100647\n",
      "17  train loss:  0.3167492151260376\n",
      "18  train loss:  0.3104782998561859\n",
      "19  train loss:  0.30669867992401123\n",
      "20  train loss:  0.3052791953086853\n",
      "21  train loss:  0.3018893599510193\n",
      "22  train loss:  0.29841348528862\n",
      "23  train loss:  0.2953382432460785\n",
      "24  train loss:  0.2927437126636505\n",
      "25  train loss:  0.29130813479423523\n",
      "26  train loss:  0.28756314516067505\n",
      "27  train loss:  0.2841474711894989\n",
      "28  train loss:  0.28130456805229187\n",
      "29  train loss:  0.2785758078098297\n",
      "30  train loss:  0.2761108875274658\n",
      "31  train loss:  0.2744326889514923\n",
      "32  train loss:  0.2718749940395355\n",
      "33  train loss:  0.27120667695999146\n",
      "34  train loss:  0.26884377002716064\n",
      "35  train loss:  0.2669755220413208\n",
      "36  train loss:  0.2651946544647217\n",
      "37  train loss:  0.26353251934051514\n",
      "38  train loss:  0.2616511583328247\n",
      "39  train loss:  0.25900799036026\n",
      "40  train loss:  0.2587043344974518\n",
      "41  train loss:  0.256852388381958\n",
      "42  train loss:  0.2547115981578827\n",
      "43  train loss:  0.2538990378379822\n",
      "44  train loss:  0.25261589884757996\n",
      "45  train loss:  0.25086498260498047\n",
      "46  train loss:  0.24898575246334076\n",
      "47  train loss:  0.24740146100521088\n",
      "48  train loss:  0.24614931643009186\n",
      "49  train loss:  0.24453654885292053\n",
      "50  train loss:  0.24330905079841614\n",
      "51  train loss:  0.24018165469169617\n",
      "52  train loss:  0.23897571861743927\n",
      "53  train loss:  0.23693440854549408\n",
      "54  train loss:  0.23548288643360138\n",
      "55  train loss:  0.2339320182800293\n",
      "56  train loss:  0.23231241106987\n",
      "57  train loss:  0.23134922981262207\n",
      "58  train loss:  0.2293858379125595\n",
      "59  train loss:  0.22909456491470337\n",
      "60  train loss:  0.22943374514579773\n",
      "61  train loss:  0.22734135389328003\n",
      "62  train loss:  0.22840644419193268\n",
      "63  train loss:  0.22429412603378296\n",
      "64  train loss:  0.22641439735889435\n",
      "65  train loss:  0.22361136972904205\n",
      "66  train loss:  0.22319941222667694\n",
      "67  train loss:  0.21857795119285583\n",
      "68  train loss:  0.21920877695083618\n",
      "69  train loss:  0.21535184979438782\n",
      "70  train loss:  0.21573321521282196\n",
      "71  train loss:  0.21285861730575562\n",
      "72  train loss:  0.21322794258594513\n",
      "73  train loss:  0.2113233357667923\n",
      "74  train loss:  0.21069380640983582\n",
      "75  train loss:  0.20752909779548645\n",
      "76  train loss:  0.20711946487426758\n",
      "77  train loss:  0.2045476883649826\n",
      "78  train loss:  0.2046639621257782\n",
      "79  train loss:  0.20295579731464386\n",
      "80  train loss:  0.2018073946237564\n",
      "81  train loss:  0.20036056637763977\n",
      "82  train loss:  0.19994066655635834\n",
      "83  train loss:  0.1992650032043457\n",
      "84  train loss:  0.19871430099010468\n",
      "85  train loss:  0.19737109541893005\n",
      "86  train loss:  0.19648267328739166\n",
      "87  train loss:  0.1965305656194687\n",
      "88  train loss:  0.19530758261680603\n",
      "89  train loss:  0.19441761076450348\n",
      "90  train loss:  0.19390931725502014\n",
      "91  train loss:  0.19354192912578583\n",
      "92  train loss:  0.1926659196615219\n",
      "93  train loss:  0.19299815595149994\n",
      "94  train loss:  0.19162912666797638\n",
      "95  train loss:  0.19165527820587158\n",
      "96  train loss:  0.19104450941085815\n",
      "97  train loss:  0.19102372229099274\n",
      "98  train loss:  0.18947963416576385\n",
      "99  train loss:  0.18866248428821564\n",
      "test acc (%):  tensor(78.7065)\n",
      "0  train loss:  0.5418712496757507\n",
      "1  train loss:  0.4741612672805786\n",
      "2  train loss:  0.4139736294746399\n",
      "3  train loss:  0.37578248977661133\n",
      "4  train loss:  0.373047411441803\n",
      "5  train loss:  0.3661729693412781\n",
      "6  train loss:  0.3581385314464569\n",
      "7  train loss:  0.3545151948928833\n",
      "8  train loss:  0.3470790386199951\n",
      "9  train loss:  0.33707404136657715\n",
      "10  train loss:  0.3311542570590973\n",
      "11  train loss:  0.33235904574394226\n",
      "12  train loss:  0.32138580083847046\n",
      "13  train loss:  0.30915212631225586\n",
      "14  train loss:  0.31019076704978943\n",
      "15  train loss:  0.31524330377578735\n",
      "16  train loss:  0.317322701215744\n",
      "17  train loss:  0.3117923438549042\n",
      "18  train loss:  0.30597373843193054\n",
      "19  train loss:  0.299784392118454\n",
      "20  train loss:  0.2935829162597656\n",
      "21  train loss:  0.29045042395591736\n",
      "22  train loss:  0.29213932156562805\n",
      "23  train loss:  0.2894085645675659\n",
      "24  train loss:  0.2849763333797455\n",
      "25  train loss:  0.28090524673461914\n",
      "26  train loss:  0.27521568536758423\n",
      "27  train loss:  0.27497899532318115\n",
      "28  train loss:  0.27349066734313965\n",
      "29  train loss:  0.2666953504085541\n",
      "30  train loss:  0.26587623357772827\n",
      "31  train loss:  0.26548662781715393\n",
      "32  train loss:  0.26060518622398376\n",
      "33  train loss:  0.26091524958610535\n",
      "34  train loss:  0.25812384486198425\n",
      "35  train loss:  0.2601921558380127\n",
      "36  train loss:  0.2586613595485687\n",
      "37  train loss:  0.25518152117729187\n",
      "38  train loss:  0.25435400009155273\n",
      "39  train loss:  0.2541506886482239\n",
      "40  train loss:  0.2517724931240082\n",
      "41  train loss:  0.250162810087204\n",
      "42  train loss:  0.24792882800102234\n",
      "43  train loss:  0.2455330640077591\n",
      "44  train loss:  0.2444598227739334\n",
      "45  train loss:  0.2427578866481781\n",
      "46  train loss:  0.24521660804748535\n",
      "47  train loss:  0.2410658299922943\n",
      "48  train loss:  0.239211305975914\n",
      "49  train loss:  0.23912853002548218\n",
      "50  train loss:  0.23419465124607086\n",
      "51  train loss:  0.23134182393550873\n",
      "52  train loss:  0.23085826635360718\n",
      "53  train loss:  0.22901630401611328\n",
      "54  train loss:  0.2270713597536087\n",
      "55  train loss:  0.22429855167865753\n",
      "56  train loss:  0.22124211490154266\n",
      "57  train loss:  0.22060546278953552\n",
      "58  train loss:  0.21866731345653534\n",
      "59  train loss:  0.21815529465675354\n",
      "60  train loss:  0.21656261384487152\n",
      "61  train loss:  0.21444426476955414\n",
      "62  train loss:  0.21500204503536224\n",
      "63  train loss:  0.21481503546237946\n",
      "64  train loss:  0.20998337864875793\n",
      "65  train loss:  0.21176239848136902\n",
      "66  train loss:  0.2092413604259491\n",
      "67  train loss:  0.2068110853433609\n",
      "68  train loss:  0.20654286444187164\n",
      "69  train loss:  0.20510007441043854\n",
      "70  train loss:  0.20278042554855347\n",
      "71  train loss:  0.2004634290933609\n",
      "72  train loss:  0.19942797720432281\n",
      "73  train loss:  0.1981634497642517\n",
      "74  train loss:  0.19705979526042938\n",
      "75  train loss:  0.19580835103988647\n",
      "76  train loss:  0.193788081407547\n",
      "77  train loss:  0.19292497634887695\n",
      "78  train loss:  0.19132238626480103\n",
      "79  train loss:  0.19014137983322144\n",
      "80  train loss:  0.18956759572029114\n",
      "81  train loss:  0.1873035728931427\n",
      "82  train loss:  0.18668261170387268\n",
      "83  train loss:  0.18558500707149506\n",
      "84  train loss:  0.18428805470466614\n",
      "85  train loss:  0.1829051971435547\n",
      "86  train loss:  0.18437442183494568\n",
      "87  train loss:  0.18419216573238373\n",
      "88  train loss:  0.18474064767360687\n",
      "89  train loss:  0.18619416654109955\n",
      "90  train loss:  0.18550319969654083\n",
      "91  train loss:  0.18425804376602173\n",
      "92  train loss:  0.18093764781951904\n",
      "93  train loss:  0.17526136338710785\n",
      "94  train loss:  0.17484362423419952\n",
      "95  train loss:  0.17310747504234314\n",
      "96  train loss:  0.17179729044437408\n",
      "97  train loss:  0.16987234354019165\n",
      "98  train loss:  0.1690383106470108\n",
      "99  train loss:  0.1672309935092926\n",
      "test acc (%):  tensor(79.0902)\n",
      "0  train loss:  0.419313907623291\n",
      "1  train loss:  0.3919086456298828\n",
      "2  train loss:  0.3577655553817749\n",
      "3  train loss:  0.337448388338089\n",
      "4  train loss:  0.32575199007987976\n",
      "5  train loss:  0.31554821133613586\n",
      "6  train loss:  0.322258859872818\n",
      "7  train loss:  0.3090461194515228\n",
      "8  train loss:  0.3068285584449768\n",
      "9  train loss:  0.29883697628974915\n",
      "10  train loss:  0.285212904214859\n",
      "11  train loss:  0.2707720696926117\n",
      "12  train loss:  0.26744458079338074\n",
      "13  train loss:  0.2651194632053375\n",
      "14  train loss:  0.26101428270339966\n",
      "15  train loss:  0.2504529058933258\n",
      "16  train loss:  0.24918407201766968\n",
      "17  train loss:  0.24730780720710754\n",
      "18  train loss:  0.24226975440979004\n",
      "19  train loss:  0.23744569718837738\n",
      "20  train loss:  0.23466713726520538\n",
      "21  train loss:  0.23150114715099335\n",
      "22  train loss:  0.22413167357444763\n",
      "23  train loss:  0.22047452628612518\n",
      "24  train loss:  0.2213721126317978\n",
      "25  train loss:  0.2153606414794922\n",
      "26  train loss:  0.21405845880508423\n",
      "27  train loss:  0.20767419040203094\n",
      "28  train loss:  0.20864316821098328\n",
      "29  train loss:  0.20162028074264526\n",
      "30  train loss:  0.1975843757390976\n",
      "31  train loss:  0.1981816589832306\n",
      "32  train loss:  0.19618353247642517\n",
      "33  train loss:  0.18965360522270203\n",
      "34  train loss:  0.18431459367275238\n",
      "35  train loss:  0.18687580525875092\n",
      "36  train loss:  0.18155673146247864\n",
      "37  train loss:  0.1795184165239334\n",
      "38  train loss:  0.17765332758426666\n",
      "39  train loss:  0.17826803028583527\n",
      "40  train loss:  0.17732110619544983\n",
      "41  train loss:  0.17079396545886993\n",
      "42  train loss:  0.1670139729976654\n",
      "43  train loss:  0.1654503494501114\n",
      "44  train loss:  0.16299307346343994\n",
      "45  train loss:  0.16255003213882446\n",
      "46  train loss:  0.16276079416275024\n",
      "47  train loss:  0.1605825573205948\n",
      "48  train loss:  0.15848706662654877\n",
      "49  train loss:  0.1552586704492569\n",
      "50  train loss:  0.15277555584907532\n",
      "51  train loss:  0.15471766889095306\n",
      "52  train loss:  0.15338388085365295\n",
      "53  train loss:  0.15032221376895905\n",
      "54  train loss:  0.14797350764274597\n",
      "55  train loss:  0.14701920747756958\n",
      "56  train loss:  0.1457541435956955\n",
      "57  train loss:  0.1442173421382904\n",
      "58  train loss:  0.14288175106048584\n",
      "59  train loss:  0.14206169545650482\n",
      "60  train loss:  0.14056146144866943\n",
      "61  train loss:  0.1406714767217636\n",
      "62  train loss:  0.14094935357570648\n",
      "63  train loss:  0.13831622898578644\n",
      "64  train loss:  0.13806912302970886\n",
      "65  train loss:  0.1372797191143036\n",
      "66  train loss:  0.1335681527853012\n",
      "67  train loss:  0.1327471286058426\n",
      "68  train loss:  0.1315203458070755\n",
      "69  train loss:  0.12953659892082214\n",
      "70  train loss:  0.12827593088150024\n",
      "71  train loss:  0.12768714129924774\n",
      "72  train loss:  0.12657903134822845\n",
      "73  train loss:  0.12506043910980225\n",
      "74  train loss:  0.12460087239742279\n",
      "75  train loss:  0.12440893054008484\n",
      "76  train loss:  0.12489677220582962\n",
      "77  train loss:  0.12406014651060104\n",
      "78  train loss:  0.12384887784719467\n",
      "79  train loss:  0.12259965389966965\n",
      "80  train loss:  0.12189584970474243\n",
      "81  train loss:  0.12175378948450089\n",
      "82  train loss:  0.12124098092317581\n",
      "83  train loss:  0.12069657444953918\n",
      "84  train loss:  0.12239166349172592\n",
      "85  train loss:  0.11923661828041077\n",
      "86  train loss:  0.11802909523248672\n",
      "87  train loss:  0.11596785485744476\n",
      "88  train loss:  0.11449824273586273\n",
      "89  train loss:  0.11447632312774658\n",
      "90  train loss:  0.11339718103408813\n",
      "91  train loss:  0.1145142912864685\n",
      "92  train loss:  0.1148027628660202\n",
      "93  train loss:  0.11309538036584854\n",
      "94  train loss:  0.11416081339120865\n",
      "95  train loss:  0.11283642053604126\n",
      "96  train loss:  0.11379554122686386\n",
      "97  train loss:  0.11358903348445892\n",
      "98  train loss:  0.11331617832183838\n",
      "99  train loss:  0.11908213794231415\n",
      "test acc (%):  tensor(79.3642)\n",
      "0  train loss:  0.5931968688964844\n",
      "1  train loss:  0.5049847960472107\n",
      "2  train loss:  0.4665203094482422\n",
      "3  train loss:  0.39319589734077454\n",
      "4  train loss:  0.36698850989341736\n",
      "5  train loss:  0.35384562611579895\n",
      "6  train loss:  0.3470519185066223\n",
      "7  train loss:  0.3448760211467743\n",
      "8  train loss:  0.3469997048377991\n",
      "9  train loss:  0.3490040600299835\n",
      "10  train loss:  0.34504830837249756\n",
      "11  train loss:  0.33171677589416504\n",
      "12  train loss:  0.3284170925617218\n",
      "13  train loss:  0.3245954215526581\n",
      "14  train loss:  0.315295934677124\n",
      "15  train loss:  0.31239333748817444\n",
      "16  train loss:  0.308295875787735\n",
      "17  train loss:  0.30263733863830566\n",
      "18  train loss:  0.29794928431510925\n",
      "19  train loss:  0.2936634123325348\n",
      "20  train loss:  0.28735631704330444\n",
      "21  train loss:  0.284995973110199\n",
      "22  train loss:  0.28571024537086487\n",
      "23  train loss:  0.2813462018966675\n",
      "24  train loss:  0.2744874060153961\n",
      "25  train loss:  0.2735934853553772\n",
      "26  train loss:  0.27339091897010803\n",
      "27  train loss:  0.26617488265037537\n",
      "28  train loss:  0.26176512241363525\n",
      "29  train loss:  0.26511651277542114\n",
      "30  train loss:  0.26252058148384094\n",
      "31  train loss:  0.25408488512039185\n",
      "32  train loss:  0.25221019983291626\n",
      "33  train loss:  0.25252029299736023\n",
      "34  train loss:  0.25056928396224976\n",
      "35  train loss:  0.2480728030204773\n",
      "36  train loss:  0.24576684832572937\n",
      "37  train loss:  0.24983035027980804\n",
      "38  train loss:  0.24411062896251678\n",
      "39  train loss:  0.24028624594211578\n",
      "40  train loss:  0.23891247808933258\n",
      "41  train loss:  0.23746921122074127\n",
      "42  train loss:  0.23492175340652466\n",
      "43  train loss:  0.23212076723575592\n",
      "44  train loss:  0.23008236289024353\n",
      "45  train loss:  0.2275669425725937\n",
      "46  train loss:  0.22735148668289185\n",
      "47  train loss:  0.22394222021102905\n",
      "48  train loss:  0.22216084599494934\n",
      "49  train loss:  0.22356849908828735\n",
      "50  train loss:  0.223967045545578\n",
      "51  train loss:  0.21866467595100403\n",
      "52  train loss:  0.2183046191930771\n",
      "53  train loss:  0.21858003735542297\n",
      "54  train loss:  0.2148044854402542\n",
      "55  train loss:  0.21296939253807068\n",
      "56  train loss:  0.21126186847686768\n",
      "57  train loss:  0.2092229574918747\n",
      "58  train loss:  0.20771807432174683\n",
      "59  train loss:  0.206076517701149\n",
      "60  train loss:  0.20515502989292145\n",
      "61  train loss:  0.20478567481040955\n",
      "62  train loss:  0.20625784993171692\n",
      "63  train loss:  0.20664775371551514\n",
      "64  train loss:  0.2044845074415207\n",
      "65  train loss:  0.20233431458473206\n",
      "66  train loss:  0.20078492164611816\n",
      "67  train loss:  0.20436659455299377\n",
      "68  train loss:  0.20413681864738464\n",
      "69  train loss:  0.20147180557250977\n",
      "70  train loss:  0.20193664729595184\n",
      "71  train loss:  0.1989995688199997\n",
      "72  train loss:  0.19923578202724457\n",
      "73  train loss:  0.19874097406864166\n",
      "74  train loss:  0.19881385564804077\n",
      "75  train loss:  0.19854488968849182\n",
      "76  train loss:  0.1980692744255066\n",
      "77  train loss:  0.1965075135231018\n",
      "78  train loss:  0.19459161162376404\n",
      "79  train loss:  0.19350473582744598\n",
      "80  train loss:  0.19362708926200867\n",
      "81  train loss:  0.19158266484737396\n",
      "82  train loss:  0.19020292162895203\n",
      "83  train loss:  0.18918968737125397\n",
      "84  train loss:  0.18878701329231262\n",
      "85  train loss:  0.1879098266363144\n",
      "86  train loss:  0.18769052624702454\n",
      "87  train loss:  0.1865214705467224\n",
      "88  train loss:  0.1871008574962616\n",
      "89  train loss:  0.18579411506652832\n",
      "90  train loss:  0.18529123067855835\n",
      "91  train loss:  0.18476302921772003\n",
      "92  train loss:  0.18401730060577393\n",
      "93  train loss:  0.1830914467573166\n",
      "94  train loss:  0.18198291957378387\n",
      "95  train loss:  0.18224714696407318\n",
      "96  train loss:  0.18303580582141876\n",
      "97  train loss:  0.1816646158695221\n",
      "98  train loss:  0.17894679307937622\n",
      "99  train loss:  0.17928704619407654\n",
      "test acc (%):  tensor(80.3782)\n",
      "0  train loss:  0.779892086982727\n",
      "1  train loss:  0.5285781025886536\n",
      "2  train loss:  0.4427889287471771\n",
      "3  train loss:  0.42904746532440186\n",
      "4  train loss:  0.3879004418849945\n",
      "5  train loss:  0.3830606937408447\n",
      "6  train loss:  0.39500924944877625\n",
      "7  train loss:  0.407600075006485\n",
      "8  train loss:  0.39955371618270874\n",
      "9  train loss:  0.3879989683628082\n",
      "10  train loss:  0.37610355019569397\n",
      "11  train loss:  0.3680046498775482\n",
      "12  train loss:  0.3682119846343994\n",
      "13  train loss:  0.36838316917419434\n",
      "14  train loss:  0.36402714252471924\n",
      "15  train loss:  0.35962367057800293\n",
      "16  train loss:  0.3572593033313751\n",
      "17  train loss:  0.35689541697502136\n",
      "18  train loss:  0.35361430048942566\n",
      "19  train loss:  0.3503580391407013\n",
      "20  train loss:  0.34326574206352234\n",
      "21  train loss:  0.3389669954776764\n",
      "22  train loss:  0.3348970413208008\n",
      "23  train loss:  0.3326314389705658\n",
      "24  train loss:  0.3293024003505707\n",
      "25  train loss:  0.32577720284461975\n",
      "26  train loss:  0.32302820682525635\n",
      "27  train loss:  0.31946298480033875\n",
      "28  train loss:  0.31727370619773865\n",
      "29  train loss:  0.3151414394378662\n",
      "30  train loss:  0.3104957640171051\n",
      "31  train loss:  0.3089068830013275\n",
      "32  train loss:  0.30676987767219543\n",
      "33  train loss:  0.3014415204524994\n",
      "34  train loss:  0.3031631410121918\n",
      "35  train loss:  0.29689309000968933\n",
      "36  train loss:  0.2938917279243469\n",
      "37  train loss:  0.29160720109939575\n",
      "38  train loss:  0.28940388560295105\n",
      "39  train loss:  0.2879936099052429\n",
      "40  train loss:  0.2854931354522705\n",
      "41  train loss:  0.2839309275150299\n",
      "42  train loss:  0.28296977281570435\n",
      "43  train loss:  0.2809965908527374\n",
      "44  train loss:  0.2791936993598938\n",
      "45  train loss:  0.2770955562591553\n",
      "46  train loss:  0.2753514051437378\n",
      "47  train loss:  0.2738204300403595\n",
      "48  train loss:  0.2709049880504608\n",
      "49  train loss:  0.2680197060108185\n",
      "50  train loss:  0.265937477350235\n",
      "51  train loss:  0.2645299732685089\n",
      "52  train loss:  0.2613031566143036\n",
      "53  train loss:  0.25996315479278564\n",
      "54  train loss:  0.2590421736240387\n",
      "55  train loss:  0.2567804753780365\n",
      "56  train loss:  0.25557538866996765\n",
      "57  train loss:  0.254146546125412\n",
      "58  train loss:  0.25255054235458374\n",
      "59  train loss:  0.2506401836872101\n",
      "60  train loss:  0.24932703375816345\n",
      "61  train loss:  0.2475021332502365\n",
      "62  train loss:  0.24592670798301697\n",
      "63  train loss:  0.24468402564525604\n",
      "64  train loss:  0.24327033758163452\n",
      "65  train loss:  0.24114815890789032\n",
      "66  train loss:  0.24040035903453827\n",
      "67  train loss:  0.23937326669692993\n",
      "68  train loss:  0.23854196071624756\n",
      "69  train loss:  0.23670288920402527\n",
      "70  train loss:  0.2351468801498413\n",
      "71  train loss:  0.23287393152713776\n",
      "72  train loss:  0.23090705275535583\n",
      "73  train loss:  0.2309350222349167\n",
      "74  train loss:  0.23136413097381592\n",
      "75  train loss:  0.2280123084783554\n",
      "76  train loss:  0.22985625267028809\n",
      "77  train loss:  0.22898004949092865\n",
      "78  train loss:  0.22703926265239716\n",
      "79  train loss:  0.22388066351413727\n",
      "80  train loss:  0.22578299045562744\n",
      "81  train loss:  0.22907832264900208\n",
      "82  train loss:  0.22138552367687225\n",
      "83  train loss:  0.2209540456533432\n",
      "84  train loss:  0.22017644345760345\n",
      "85  train loss:  0.21861733496189117\n",
      "86  train loss:  0.21844294667243958\n",
      "87  train loss:  0.2164582759141922\n",
      "88  train loss:  0.21402643620967865\n",
      "89  train loss:  0.22073489427566528\n",
      "90  train loss:  0.21380987763404846\n",
      "91  train loss:  0.21415787935256958\n",
      "92  train loss:  0.21243028342723846\n",
      "93  train loss:  0.21057826280593872\n",
      "94  train loss:  0.21026603877544403\n",
      "95  train loss:  0.2072027325630188\n",
      "96  train loss:  0.2049543559551239\n",
      "97  train loss:  0.20714959502220154\n",
      "98  train loss:  0.20507867634296417\n",
      "99  train loss:  0.20228448510169983\n",
      "test acc (%):  tensor(79.9945)\n",
      "0  train loss:  0.5270081758499146\n",
      "1  train loss:  0.4452088475227356\n",
      "2  train loss:  0.4003838002681732\n",
      "3  train loss:  0.3743215799331665\n",
      "4  train loss:  0.35290008783340454\n",
      "5  train loss:  0.34674912691116333\n",
      "6  train loss:  0.3446754217147827\n",
      "7  train loss:  0.34490522742271423\n",
      "8  train loss:  0.34865230321884155\n",
      "9  train loss:  0.35115593671798706\n",
      "10  train loss:  0.34886056184768677\n",
      "11  train loss:  0.337906152009964\n",
      "12  train loss:  0.3299631178379059\n",
      "13  train loss:  0.3221539258956909\n",
      "14  train loss:  0.31722307205200195\n",
      "15  train loss:  0.3116343915462494\n",
      "16  train loss:  0.30770808458328247\n",
      "17  train loss:  0.3066427707672119\n",
      "18  train loss:  0.30451932549476624\n",
      "19  train loss:  0.29890695214271545\n",
      "20  train loss:  0.29173487424850464\n",
      "21  train loss:  0.28972116112709045\n",
      "22  train loss:  0.2880275547504425\n",
      "23  train loss:  0.28472286462783813\n",
      "24  train loss:  0.28345704078674316\n",
      "25  train loss:  0.2809726893901825\n",
      "26  train loss:  0.2770031690597534\n",
      "27  train loss:  0.274569571018219\n",
      "28  train loss:  0.2705240249633789\n",
      "29  train loss:  0.26908281445503235\n",
      "30  train loss:  0.2656627893447876\n",
      "31  train loss:  0.2623465061187744\n",
      "32  train loss:  0.26072993874549866\n",
      "33  train loss:  0.2597951292991638\n",
      "34  train loss:  0.2567378878593445\n",
      "35  train loss:  0.2532202899456024\n",
      "36  train loss:  0.25079938769340515\n",
      "37  train loss:  0.24992668628692627\n",
      "38  train loss:  0.24822568893432617\n",
      "39  train loss:  0.24699528515338898\n",
      "40  train loss:  0.24583552777767181\n",
      "41  train loss:  0.24446821212768555\n",
      "42  train loss:  0.24289973080158234\n",
      "43  train loss:  0.24119696021080017\n",
      "44  train loss:  0.24013295769691467\n",
      "45  train loss:  0.23817214369773865\n",
      "46  train loss:  0.2351003736257553\n",
      "47  train loss:  0.23454104363918304\n",
      "48  train loss:  0.23198120296001434\n",
      "49  train loss:  0.2303503304719925\n",
      "50  train loss:  0.22979989647865295\n",
      "51  train loss:  0.22873149812221527\n",
      "52  train loss:  0.22782939672470093\n",
      "53  train loss:  0.22696124017238617\n",
      "54  train loss:  0.22686423361301422\n",
      "55  train loss:  0.2255454808473587\n",
      "56  train loss:  0.2247857302427292\n",
      "57  train loss:  0.2256573736667633\n",
      "58  train loss:  0.22246874868869781\n",
      "59  train loss:  0.22266927361488342\n",
      "60  train loss:  0.22325773537158966\n",
      "61  train loss:  0.22035075724124908\n",
      "62  train loss:  0.22232019901275635\n",
      "63  train loss:  0.22095847129821777\n",
      "64  train loss:  0.2172204852104187\n",
      "65  train loss:  0.21764355897903442\n",
      "66  train loss:  0.21659299731254578\n",
      "67  train loss:  0.21417143940925598\n",
      "68  train loss:  0.21396061778068542\n",
      "69  train loss:  0.2120668888092041\n",
      "70  train loss:  0.21005234122276306\n",
      "71  train loss:  0.21001729369163513\n",
      "72  train loss:  0.20787128806114197\n",
      "73  train loss:  0.20627270638942719\n",
      "74  train loss:  0.20553714036941528\n",
      "75  train loss:  0.20408138632774353\n",
      "76  train loss:  0.20272624492645264\n",
      "77  train loss:  0.20170919597148895\n",
      "78  train loss:  0.2007441222667694\n",
      "79  train loss:  0.19959168136119843\n",
      "80  train loss:  0.19832032918930054\n",
      "81  train loss:  0.1972685009241104\n",
      "82  train loss:  0.1961175799369812\n",
      "83  train loss:  0.19512952864170074\n",
      "84  train loss:  0.1946156769990921\n",
      "85  train loss:  0.19348680973052979\n",
      "86  train loss:  0.1936202347278595\n",
      "87  train loss:  0.19203516840934753\n",
      "88  train loss:  0.1907370686531067\n",
      "89  train loss:  0.191383495926857\n",
      "90  train loss:  0.1899336874485016\n",
      "91  train loss:  0.18954290449619293\n",
      "92  train loss:  0.18865719437599182\n",
      "93  train loss:  0.18813395500183105\n",
      "94  train loss:  0.18765291571617126\n",
      "95  train loss:  0.18673215806484222\n",
      "96  train loss:  0.18705613911151886\n",
      "97  train loss:  0.1861451268196106\n",
      "98  train loss:  0.18562151491641998\n",
      "99  train loss:  0.18540553748607635\n",
      "test acc (%):  tensor(78.6243)\n",
      "0  train loss:  0.6894023418426514\n",
      "1  train loss:  0.5766550898551941\n",
      "2  train loss:  0.47453200817108154\n",
      "3  train loss:  0.41319987177848816\n",
      "4  train loss:  0.3951394259929657\n",
      "5  train loss:  0.3726368248462677\n",
      "6  train loss:  0.35901835560798645\n",
      "7  train loss:  0.34944406151771545\n",
      "8  train loss:  0.34573546051979065\n",
      "9  train loss:  0.34307044744491577\n",
      "10  train loss:  0.34336304664611816\n",
      "11  train loss:  0.3418906331062317\n",
      "12  train loss:  0.3386153280735016\n",
      "13  train loss:  0.33517464995384216\n",
      "14  train loss:  0.33007049560546875\n",
      "15  train loss:  0.32439950108528137\n",
      "16  train loss:  0.31813690066337585\n",
      "17  train loss:  0.31812575459480286\n",
      "18  train loss:  0.31197500228881836\n",
      "19  train loss:  0.31153368949890137\n",
      "20  train loss:  0.3081589937210083\n",
      "21  train loss:  0.3063543438911438\n",
      "22  train loss:  0.30462706089019775\n",
      "23  train loss:  0.2998569905757904\n",
      "24  train loss:  0.29734331369400024\n",
      "25  train loss:  0.29347527027130127\n",
      "26  train loss:  0.293811172246933\n",
      "27  train loss:  0.2934957444667816\n",
      "28  train loss:  0.29166722297668457\n",
      "29  train loss:  0.2889336943626404\n",
      "30  train loss:  0.2856193780899048\n",
      "31  train loss:  0.28337883949279785\n",
      "32  train loss:  0.28165388107299805\n",
      "33  train loss:  0.2804868519306183\n",
      "34  train loss:  0.27868974208831787\n",
      "35  train loss:  0.2766590118408203\n",
      "36  train loss:  0.27470651268959045\n",
      "37  train loss:  0.27111732959747314\n",
      "38  train loss:  0.2727404534816742\n",
      "39  train loss:  0.26844778656959534\n",
      "40  train loss:  0.26813411712646484\n",
      "41  train loss:  0.2639071047306061\n",
      "42  train loss:  0.265841007232666\n",
      "43  train loss:  0.26143375039100647\n",
      "44  train loss:  0.2616613209247589\n",
      "45  train loss:  0.2568671405315399\n",
      "46  train loss:  0.2561506927013397\n",
      "47  train loss:  0.2538091838359833\n",
      "48  train loss:  0.2521284520626068\n",
      "49  train loss:  0.2514472007751465\n",
      "50  train loss:  0.2487027645111084\n",
      "51  train loss:  0.2490418255329132\n",
      "52  train loss:  0.24617698788642883\n",
      "53  train loss:  0.24443793296813965\n",
      "54  train loss:  0.24572023749351501\n",
      "55  train loss:  0.24227991700172424\n",
      "56  train loss:  0.24016854166984558\n",
      "57  train loss:  0.24112240970134735\n",
      "58  train loss:  0.2414740025997162\n",
      "59  train loss:  0.23857998847961426\n",
      "60  train loss:  0.23769938945770264\n",
      "61  train loss:  0.23729290068149567\n",
      "62  train loss:  0.23534740507602692\n",
      "63  train loss:  0.23382695019245148\n",
      "64  train loss:  0.23276381194591522\n",
      "65  train loss:  0.23284228146076202\n",
      "66  train loss:  0.23128516972064972\n",
      "67  train loss:  0.23107729852199554\n",
      "68  train loss:  0.22940059006214142\n",
      "69  train loss:  0.22871237993240356\n",
      "70  train loss:  0.22786837816238403\n",
      "71  train loss:  0.22662964463233948\n",
      "72  train loss:  0.22548344731330872\n",
      "73  train loss:  0.22481508553028107\n",
      "74  train loss:  0.22426101565361023\n",
      "75  train loss:  0.22374898195266724\n",
      "76  train loss:  0.2228761613368988\n",
      "77  train loss:  0.22128883004188538\n",
      "78  train loss:  0.2211715131998062\n",
      "79  train loss:  0.22057849168777466\n",
      "80  train loss:  0.21945393085479736\n",
      "81  train loss:  0.2187901884317398\n",
      "82  train loss:  0.2183409482240677\n",
      "83  train loss:  0.21808463335037231\n",
      "84  train loss:  0.21665915846824646\n",
      "85  train loss:  0.21674476563930511\n",
      "86  train loss:  0.21529608964920044\n",
      "87  train loss:  0.2143065333366394\n",
      "88  train loss:  0.2137729972600937\n",
      "89  train loss:  0.2164100855588913\n",
      "90  train loss:  0.21272335946559906\n",
      "91  train loss:  0.2134946882724762\n",
      "92  train loss:  0.21222087740898132\n",
      "93  train loss:  0.21169880032539368\n",
      "94  train loss:  0.21118994057178497\n",
      "95  train loss:  0.20864610373973846\n",
      "96  train loss:  0.20734550058841705\n",
      "97  train loss:  0.20838338136672974\n",
      "98  train loss:  0.2054181694984436\n",
      "99  train loss:  0.20603619515895844\n",
      "test acc (%):  tensor(79.8027)\n",
      "0  train loss:  0.5251149535179138\n",
      "1  train loss:  0.4160231351852417\n",
      "2  train loss:  0.4038849472999573\n",
      "3  train loss:  0.3746381998062134\n",
      "4  train loss:  0.3710888624191284\n",
      "5  train loss:  0.3691904544830322\n",
      "6  train loss:  0.3471009135246277\n",
      "7  train loss:  0.33572134375572205\n",
      "8  train loss:  0.33550411462783813\n",
      "9  train loss:  0.32212698459625244\n",
      "10  train loss:  0.3165484368801117\n",
      "11  train loss:  0.3164050281047821\n",
      "12  train loss:  0.3077126741409302\n",
      "13  train loss:  0.2979154586791992\n",
      "14  train loss:  0.29250386357307434\n",
      "15  train loss:  0.28991255164146423\n",
      "16  train loss:  0.28555935621261597\n",
      "17  train loss:  0.2786591351032257\n",
      "18  train loss:  0.27575770020484924\n",
      "19  train loss:  0.2675536274909973\n",
      "20  train loss:  0.2600347101688385\n",
      "21  train loss:  0.25699421763420105\n",
      "22  train loss:  0.2582131624221802\n",
      "23  train loss:  0.25467318296432495\n",
      "24  train loss:  0.24974100291728973\n",
      "25  train loss:  0.2470267117023468\n",
      "26  train loss:  0.2455173134803772\n",
      "27  train loss:  0.24017319083213806\n",
      "28  train loss:  0.23641256988048553\n",
      "29  train loss:  0.23615577816963196\n",
      "30  train loss:  0.23443740606307983\n",
      "31  train loss:  0.22853055596351624\n",
      "32  train loss:  0.22571450471878052\n",
      "33  train loss:  0.2251013070344925\n",
      "34  train loss:  0.22131147980690002\n",
      "35  train loss:  0.21824392676353455\n",
      "36  train loss:  0.21465830504894257\n",
      "37  train loss:  0.21274742484092712\n",
      "38  train loss:  0.21145065128803253\n",
      "39  train loss:  0.21044287085533142\n",
      "40  train loss:  0.20799429714679718\n",
      "41  train loss:  0.20675785839557648\n",
      "42  train loss:  0.20472058653831482\n",
      "43  train loss:  0.20331355929374695\n",
      "44  train loss:  0.20224431157112122\n",
      "45  train loss:  0.20149220526218414\n",
      "46  train loss:  0.20079608261585236\n",
      "47  train loss:  0.198338583111763\n",
      "48  train loss:  0.1965206116437912\n",
      "49  train loss:  0.1954900622367859\n",
      "50  train loss:  0.19487182796001434\n",
      "51  train loss:  0.19451506435871124\n",
      "52  train loss:  0.19356141984462738\n",
      "53  train loss:  0.19238513708114624\n",
      "54  train loss:  0.19167178869247437\n",
      "55  train loss:  0.1909416913986206\n",
      "56  train loss:  0.18992184102535248\n",
      "57  train loss:  0.18878892064094543\n",
      "58  train loss:  0.1875322312116623\n",
      "59  train loss:  0.18659773468971252\n",
      "60  train loss:  0.1847836971282959\n",
      "61  train loss:  0.18335998058319092\n",
      "62  train loss:  0.1829613894224167\n",
      "63  train loss:  0.1820981800556183\n",
      "64  train loss:  0.18011082708835602\n",
      "65  train loss:  0.17913773655891418\n",
      "66  train loss:  0.1788700670003891\n",
      "67  train loss:  0.17839160561561584\n",
      "68  train loss:  0.1772128790616989\n",
      "69  train loss:  0.17670677602291107\n",
      "70  train loss:  0.17636185884475708\n",
      "71  train loss:  0.17572827637195587\n",
      "72  train loss:  0.1743621528148651\n",
      "73  train loss:  0.17407234013080597\n",
      "74  train loss:  0.17404057085514069\n",
      "75  train loss:  0.17347662150859833\n",
      "76  train loss:  0.17285995185375214\n",
      "77  train loss:  0.1719610095024109\n",
      "78  train loss:  0.1716797947883606\n",
      "79  train loss:  0.17121902108192444\n",
      "80  train loss:  0.1705721914768219\n",
      "81  train loss:  0.1699400395154953\n",
      "82  train loss:  0.16947536170482635\n",
      "83  train loss:  0.1691446751356125\n",
      "84  train loss:  0.16817553341388702\n",
      "85  train loss:  0.1679394692182541\n",
      "86  train loss:  0.16732385754585266\n",
      "87  train loss:  0.16664110124111176\n",
      "88  train loss:  0.16673535108566284\n",
      "89  train loss:  0.1658286601305008\n",
      "90  train loss:  0.1651659607887268\n",
      "91  train loss:  0.1644197553396225\n",
      "92  train loss:  0.1640443354845047\n",
      "93  train loss:  0.16307777166366577\n",
      "94  train loss:  0.1627928465604782\n",
      "95  train loss:  0.16239596903324127\n",
      "96  train loss:  0.16206255555152893\n",
      "97  train loss:  0.16164006292819977\n",
      "98  train loss:  0.1601921021938324\n",
      "99  train loss:  0.16017016768455505\n",
      "test acc (%):  tensor(78.3502)\n",
      "0  train loss:  0.5202327966690063\n",
      "1  train loss:  0.46398282051086426\n",
      "2  train loss:  0.4181289076805115\n",
      "3  train loss:  0.4195062220096588\n",
      "4  train loss:  0.3863317370414734\n",
      "5  train loss:  0.3715074062347412\n",
      "6  train loss:  0.3529791831970215\n",
      "7  train loss:  0.3317939341068268\n",
      "8  train loss:  0.3252486288547516\n",
      "9  train loss:  0.3204556405544281\n",
      "10  train loss:  0.3091552257537842\n",
      "11  train loss:  0.2999962568283081\n",
      "12  train loss:  0.29334768652915955\n",
      "13  train loss:  0.2900646924972534\n",
      "14  train loss:  0.28186723589897156\n",
      "15  train loss:  0.28467294573783875\n",
      "16  train loss:  0.28006649017333984\n",
      "17  train loss:  0.2693063020706177\n",
      "18  train loss:  0.262320876121521\n",
      "19  train loss:  0.262887179851532\n",
      "20  train loss:  0.263159841299057\n",
      "21  train loss:  0.2574334442615509\n",
      "22  train loss:  0.25266173481941223\n",
      "23  train loss:  0.24923890829086304\n",
      "24  train loss:  0.24405185878276825\n",
      "25  train loss:  0.23954465985298157\n",
      "26  train loss:  0.24937984347343445\n",
      "27  train loss:  0.23682935535907745\n",
      "28  train loss:  0.2452785074710846\n",
      "29  train loss:  0.24167941510677338\n",
      "30  train loss:  0.22955888509750366\n",
      "31  train loss:  0.22917668521404266\n",
      "32  train loss:  0.22569826245307922\n",
      "33  train loss:  0.21633483469486237\n",
      "34  train loss:  0.21520626544952393\n",
      "35  train loss:  0.2117512822151184\n",
      "36  train loss:  0.20663303136825562\n",
      "37  train loss:  0.20328651368618011\n",
      "38  train loss:  0.20259444415569305\n",
      "39  train loss:  0.20022958517074585\n",
      "40  train loss:  0.19554567337036133\n",
      "41  train loss:  0.19377005100250244\n",
      "42  train loss:  0.19347962737083435\n",
      "43  train loss:  0.19312572479248047\n",
      "44  train loss:  0.18841716647148132\n",
      "45  train loss:  0.18634448945522308\n",
      "46  train loss:  0.1845988929271698\n",
      "47  train loss:  0.18102650344371796\n",
      "48  train loss:  0.1800457388162613\n",
      "49  train loss:  0.17755858600139618\n",
      "50  train loss:  0.17534469068050385\n",
      "51  train loss:  0.17198029160499573\n",
      "52  train loss:  0.1705855280160904\n",
      "53  train loss:  0.16817669570446014\n",
      "54  train loss:  0.16803359985351562\n",
      "55  train loss:  0.1622716635465622\n",
      "56  train loss:  0.16195712983608246\n",
      "57  train loss:  0.17016488313674927\n",
      "58  train loss:  0.18950439989566803\n",
      "59  train loss:  0.17023597657680511\n",
      "60  train loss:  0.1534235030412674\n",
      "61  train loss:  0.15646977722644806\n",
      "62  train loss:  0.1536971479654312\n",
      "63  train loss:  0.15075719356536865\n",
      "64  train loss:  0.14806745946407318\n",
      "65  train loss:  0.1441275179386139\n",
      "66  train loss:  0.14220565557479858\n",
      "67  train loss:  0.14124177396297455\n",
      "68  train loss:  0.13825014233589172\n",
      "69  train loss:  0.13716772198677063\n",
      "70  train loss:  0.13710439205169678\n",
      "71  train loss:  0.13324132561683655\n",
      "72  train loss:  0.13468123972415924\n",
      "73  train loss:  0.1302298903465271\n",
      "74  train loss:  0.12963064014911652\n",
      "75  train loss:  0.12716345489025116\n",
      "76  train loss:  0.12550126016139984\n",
      "77  train loss:  0.12448248267173767\n",
      "78  train loss:  0.12235528230667114\n",
      "79  train loss:  0.12167780846357346\n",
      "80  train loss:  0.11997020244598389\n",
      "81  train loss:  0.11906276643276215\n",
      "82  train loss:  0.11825878173112869\n",
      "83  train loss:  0.11715829372406006\n",
      "84  train loss:  0.11606740206480026\n",
      "85  train loss:  0.11517525464296341\n",
      "86  train loss:  0.11430289596319199\n",
      "87  train loss:  0.11353687196969986\n",
      "88  train loss:  0.1126728430390358\n",
      "89  train loss:  0.11190143972635269\n",
      "90  train loss:  0.11101093143224716\n",
      "91  train loss:  0.11032110452651978\n",
      "92  train loss:  0.10947225242853165\n",
      "93  train loss:  0.10883480310440063\n",
      "94  train loss:  0.1078510731458664\n",
      "95  train loss:  0.1077064722776413\n",
      "96  train loss:  0.10657676309347153\n",
      "97  train loss:  0.10598870366811752\n",
      "98  train loss:  0.10556218773126602\n",
      "99  train loss:  0.10466237366199493\n",
      "test acc (%):  tensor(77.9118)\n",
      "0  train loss:  0.6841557025909424\n",
      "1  train loss:  0.553023099899292\n",
      "2  train loss:  0.5162405371665955\n",
      "3  train loss:  0.45602384209632874\n",
      "4  train loss:  0.406716912984848\n",
      "5  train loss:  0.40910467505455017\n",
      "6  train loss:  0.37134602665901184\n",
      "7  train loss:  0.38987985253334045\n",
      "8  train loss:  0.38463422656059265\n",
      "9  train loss:  0.3393288254737854\n",
      "10  train loss:  0.33288848400115967\n",
      "11  train loss:  0.32389184832572937\n",
      "12  train loss:  0.3161846697330475\n",
      "13  train loss:  0.30435091257095337\n",
      "14  train loss:  0.2983759343624115\n",
      "15  train loss:  0.2922232747077942\n",
      "16  train loss:  0.28817856311798096\n",
      "17  train loss:  0.28478705883026123\n",
      "18  train loss:  0.28012531995773315\n",
      "19  train loss:  0.27417004108428955\n",
      "20  train loss:  0.27181437611579895\n",
      "21  train loss:  0.2687414586544037\n",
      "22  train loss:  0.2784019410610199\n",
      "23  train loss:  0.2759305536746979\n",
      "24  train loss:  0.27149853110313416\n",
      "25  train loss:  0.26107487082481384\n",
      "26  train loss:  0.2657875120639801\n",
      "27  train loss:  0.25676825642585754\n",
      "28  train loss:  0.25225159525871277\n",
      "29  train loss:  0.2507016360759735\n",
      "30  train loss:  0.24576127529144287\n",
      "31  train loss:  0.24420464038848877\n",
      "32  train loss:  0.23660506308078766\n",
      "33  train loss:  0.23624326288700104\n",
      "34  train loss:  0.23131883144378662\n",
      "35  train loss:  0.2313930094242096\n",
      "36  train loss:  0.22668999433517456\n",
      "37  train loss:  0.2229921519756317\n",
      "38  train loss:  0.21726274490356445\n",
      "39  train loss:  0.2144087851047516\n",
      "40  train loss:  0.21212700009346008\n",
      "41  train loss:  0.20907782018184662\n",
      "42  train loss:  0.2049432247877121\n",
      "43  train loss:  0.20242464542388916\n",
      "44  train loss:  0.19979998469352722\n",
      "45  train loss:  0.1957150101661682\n",
      "46  train loss:  0.19355590641498566\n",
      "47  train loss:  0.19001320004463196\n",
      "48  train loss:  0.18789950013160706\n",
      "49  train loss:  0.18473364412784576\n",
      "50  train loss:  0.18240846693515778\n",
      "51  train loss:  0.17968446016311646\n",
      "52  train loss:  0.1774752140045166\n",
      "53  train loss:  0.17477509379386902\n",
      "54  train loss:  0.17271025478839874\n",
      "55  train loss:  0.17052125930786133\n",
      "56  train loss:  0.16905605792999268\n",
      "57  train loss:  0.16563951969146729\n",
      "58  train loss:  0.16376005113124847\n",
      "59  train loss:  0.1620393991470337\n",
      "60  train loss:  0.16182638704776764\n",
      "61  train loss:  0.16009782254695892\n",
      "62  train loss:  0.15743547677993774\n",
      "63  train loss:  0.1567094475030899\n",
      "64  train loss:  0.15556761622428894\n",
      "65  train loss:  0.15327998995780945\n",
      "66  train loss:  0.15254008769989014\n",
      "67  train loss:  0.1503879278898239\n",
      "68  train loss:  0.14884346723556519\n",
      "69  train loss:  0.14759567379951477\n",
      "70  train loss:  0.14600418508052826\n",
      "71  train loss:  0.14421747624874115\n",
      "72  train loss:  0.14397136867046356\n",
      "73  train loss:  0.14618277549743652\n",
      "74  train loss:  0.1562119424343109\n",
      "75  train loss:  0.17201735079288483\n",
      "76  train loss:  0.14352630078792572\n",
      "77  train loss:  0.15930210053920746\n",
      "78  train loss:  0.19825494289398193\n",
      "79  train loss:  0.14210589230060577\n",
      "80  train loss:  0.21225033700466156\n",
      "81  train loss:  0.17396827042102814\n",
      "82  train loss:  0.2054775059223175\n",
      "83  train loss:  0.15973468124866486\n",
      "84  train loss:  0.2175426334142685\n",
      "85  train loss:  0.15676040947437286\n",
      "86  train loss:  0.1983158141374588\n",
      "87  train loss:  0.1598680168390274\n",
      "88  train loss:  0.16262328624725342\n",
      "89  train loss:  0.16013103723526\n",
      "90  train loss:  0.14791081845760345\n",
      "91  train loss:  0.16877949237823486\n",
      "92  train loss:  0.14111068844795227\n",
      "93  train loss:  0.18183964490890503\n",
      "94  train loss:  0.14142727851867676\n",
      "95  train loss:  0.16980098187923431\n",
      "96  train loss:  0.16126373410224915\n",
      "97  train loss:  0.1573885828256607\n",
      "98  train loss:  0.13808497786521912\n",
      "99  train loss:  0.14454787969589233\n",
      "test acc (%):  tensor(78.8709)\n",
      "0  train loss:  0.7063934206962585\n",
      "1  train loss:  0.5540148019790649\n",
      "2  train loss:  0.4548705220222473\n",
      "3  train loss:  0.36558663845062256\n",
      "4  train loss:  0.34335020184516907\n",
      "5  train loss:  0.32890447974205017\n",
      "6  train loss:  0.3199370205402374\n",
      "7  train loss:  0.3155739903450012\n",
      "8  train loss:  0.3118560314178467\n",
      "9  train loss:  0.29564523696899414\n",
      "10  train loss:  0.2935689687728882\n",
      "11  train loss:  0.29210129380226135\n",
      "12  train loss:  0.28600746393203735\n",
      "13  train loss:  0.28104573488235474\n",
      "14  train loss:  0.27939513325691223\n",
      "15  train loss:  0.27767279744148254\n",
      "16  train loss:  0.2733900845050812\n",
      "17  train loss:  0.2704123854637146\n",
      "18  train loss:  0.26523640751838684\n",
      "19  train loss:  0.2613876461982727\n",
      "20  train loss:  0.25847986340522766\n",
      "21  train loss:  0.25544944405555725\n",
      "22  train loss:  0.25251299142837524\n",
      "23  train loss:  0.2501312792301178\n",
      "24  train loss:  0.24604326486587524\n",
      "25  train loss:  0.24350617825984955\n",
      "26  train loss:  0.24445444345474243\n",
      "27  train loss:  0.24157890677452087\n",
      "28  train loss:  0.23543071746826172\n",
      "29  train loss:  0.23721739649772644\n",
      "30  train loss:  0.23208989202976227\n",
      "31  train loss:  0.2299235761165619\n",
      "32  train loss:  0.2276197075843811\n",
      "33  train loss:  0.22535565495491028\n",
      "34  train loss:  0.22172699868679047\n",
      "35  train loss:  0.21948114037513733\n",
      "36  train loss:  0.2151988297700882\n",
      "37  train loss:  0.21400249004364014\n",
      "38  train loss:  0.21260902285575867\n",
      "39  train loss:  0.21517127752304077\n",
      "40  train loss:  0.2085631638765335\n",
      "41  train loss:  0.20509175956249237\n",
      "42  train loss:  0.20669493079185486\n",
      "43  train loss:  0.2023586630821228\n",
      "44  train loss:  0.20319271087646484\n",
      "45  train loss:  0.19843372702598572\n",
      "46  train loss:  0.19881704449653625\n",
      "47  train loss:  0.19469720125198364\n",
      "48  train loss:  0.19375523924827576\n",
      "49  train loss:  0.19154998660087585\n",
      "50  train loss:  0.18884426355361938\n",
      "51  train loss:  0.18755094707012177\n",
      "52  train loss:  0.18501192331314087\n",
      "53  train loss:  0.184458389878273\n",
      "54  train loss:  0.1826275885105133\n",
      "55  train loss:  0.18168166279792786\n",
      "56  train loss:  0.17990827560424805\n",
      "57  train loss:  0.17929114401340485\n",
      "58  train loss:  0.17730732262134552\n",
      "59  train loss:  0.17617358267307281\n",
      "60  train loss:  0.17508487403392792\n",
      "61  train loss:  0.17381256818771362\n",
      "62  train loss:  0.17206570506095886\n",
      "63  train loss:  0.17017324268817902\n",
      "64  train loss:  0.1690429449081421\n",
      "65  train loss:  0.16787438094615936\n",
      "66  train loss:  0.16680964827537537\n",
      "67  train loss:  0.16615821421146393\n",
      "68  train loss:  0.16523432731628418\n",
      "69  train loss:  0.16427874565124512\n",
      "70  train loss:  0.16326114535331726\n",
      "71  train loss:  0.16235661506652832\n",
      "72  train loss:  0.16120965778827667\n",
      "73  train loss:  0.16037051379680634\n",
      "74  train loss:  0.15964926779270172\n",
      "75  train loss:  0.1586700677871704\n",
      "76  train loss:  0.15793807804584503\n",
      "77  train loss:  0.15720421075820923\n",
      "78  train loss:  0.1564229279756546\n",
      "79  train loss:  0.15571363270282745\n",
      "80  train loss:  0.15502944588661194\n",
      "81  train loss:  0.15427863597869873\n",
      "82  train loss:  0.15367810428142548\n",
      "83  train loss:  0.15302182734012604\n",
      "84  train loss:  0.15239188075065613\n",
      "85  train loss:  0.1517454981803894\n",
      "86  train loss:  0.1510816365480423\n",
      "87  train loss:  0.15018470585346222\n",
      "88  train loss:  0.1496647298336029\n",
      "89  train loss:  0.14920006692409515\n",
      "90  train loss:  0.1485036164522171\n",
      "91  train loss:  0.14737005531787872\n",
      "92  train loss:  0.14673712849617004\n",
      "93  train loss:  0.14620788395404816\n",
      "94  train loss:  0.14521105587482452\n",
      "95  train loss:  0.14443738758563995\n",
      "96  train loss:  0.14363902807235718\n",
      "97  train loss:  0.14300277829170227\n",
      "98  train loss:  0.14237581193447113\n",
      "99  train loss:  0.14185912907123566\n",
      "test acc (%):  tensor(78.7065)\n",
      "0  train loss:  0.6371516585350037\n",
      "1  train loss:  0.5825444459915161\n",
      "2  train loss:  0.5413233637809753\n",
      "3  train loss:  0.47340789437294006\n",
      "4  train loss:  0.4256959557533264\n",
      "5  train loss:  0.39970144629478455\n",
      "6  train loss:  0.36783209443092346\n",
      "7  train loss:  0.3522229492664337\n",
      "8  train loss:  0.35110393166542053\n",
      "9  train loss:  0.3494546711444855\n",
      "10  train loss:  0.33536234498023987\n",
      "11  train loss:  0.33095449209213257\n",
      "12  train loss:  0.33672896027565\n",
      "13  train loss:  0.32614463567733765\n",
      "14  train loss:  0.32325226068496704\n",
      "15  train loss:  0.3152787983417511\n",
      "16  train loss:  0.31221121549606323\n",
      "17  train loss:  0.30457574129104614\n",
      "18  train loss:  0.2990896701812744\n",
      "19  train loss:  0.28694599866867065\n",
      "20  train loss:  0.27913400530815125\n",
      "21  train loss:  0.2757922112941742\n",
      "22  train loss:  0.26927492022514343\n",
      "23  train loss:  0.26753371953964233\n",
      "24  train loss:  0.2624626159667969\n",
      "25  train loss:  0.25875625014305115\n",
      "26  train loss:  0.2547749876976013\n",
      "27  train loss:  0.2513229548931122\n",
      "28  train loss:  0.25227785110473633\n",
      "29  train loss:  0.24879130721092224\n",
      "30  train loss:  0.24480047821998596\n",
      "31  train loss:  0.24147740006446838\n",
      "32  train loss:  0.24143652617931366\n",
      "33  train loss:  0.23768211901187897\n",
      "34  train loss:  0.2335081249475479\n",
      "35  train loss:  0.2304983139038086\n",
      "36  train loss:  0.2289763242006302\n",
      "37  train loss:  0.22498595714569092\n",
      "38  train loss:  0.22203537821769714\n",
      "39  train loss:  0.22001491487026215\n",
      "40  train loss:  0.2180943489074707\n",
      "41  train loss:  0.21548454463481903\n",
      "42  train loss:  0.2131468504667282\n",
      "43  train loss:  0.2119937688112259\n",
      "44  train loss:  0.20896543562412262\n",
      "45  train loss:  0.20722945034503937\n",
      "46  train loss:  0.20471161603927612\n",
      "47  train loss:  0.20308850705623627\n",
      "48  train loss:  0.20145456492900848\n",
      "49  train loss:  0.1989341676235199\n",
      "50  train loss:  0.19706271588802338\n",
      "51  train loss:  0.19514091312885284\n",
      "52  train loss:  0.193895623087883\n",
      "53  train loss:  0.19189240038394928\n",
      "54  train loss:  0.18993377685546875\n",
      "55  train loss:  0.1882367581129074\n",
      "56  train loss:  0.18630348145961761\n",
      "57  train loss:  0.18503610789775848\n",
      "58  train loss:  0.18313118815422058\n",
      "59  train loss:  0.1821078062057495\n",
      "60  train loss:  0.17995433509349823\n",
      "61  train loss:  0.17821088433265686\n",
      "62  train loss:  0.1774022877216339\n",
      "63  train loss:  0.175236776471138\n",
      "64  train loss:  0.17278151214122772\n",
      "65  train loss:  0.17447791993618011\n",
      "66  train loss:  0.16979533433914185\n",
      "67  train loss:  0.1685551404953003\n",
      "68  train loss:  0.166920006275177\n",
      "69  train loss:  0.16570837795734406\n",
      "70  train loss:  0.16375653445720673\n",
      "71  train loss:  0.16176673769950867\n",
      "72  train loss:  0.1618042141199112\n",
      "73  train loss:  0.16210584342479706\n",
      "74  train loss:  0.1576615422964096\n",
      "75  train loss:  0.15899527072906494\n",
      "76  train loss:  0.15459096431732178\n",
      "77  train loss:  0.15286342799663544\n",
      "78  train loss:  0.15203264355659485\n",
      "79  train loss:  0.15065445005893707\n",
      "80  train loss:  0.14799685776233673\n",
      "81  train loss:  0.1465214490890503\n",
      "82  train loss:  0.14573054015636444\n",
      "83  train loss:  0.14337530732154846\n",
      "84  train loss:  0.14245525002479553\n",
      "85  train loss:  0.14105528593063354\n",
      "86  train loss:  0.13957573473453522\n",
      "87  train loss:  0.13858871161937714\n",
      "88  train loss:  0.13659420609474182\n",
      "89  train loss:  0.1354588270187378\n",
      "90  train loss:  0.13328580558300018\n",
      "91  train loss:  0.13179835677146912\n",
      "92  train loss:  0.1300259679555893\n",
      "93  train loss:  0.12977053225040436\n",
      "94  train loss:  0.12880170345306396\n",
      "95  train loss:  0.12779149413108826\n",
      "96  train loss:  0.12707993388175964\n",
      "97  train loss:  0.12628717720508575\n",
      "98  train loss:  0.125627338886261\n",
      "99  train loss:  0.12509050965309143\n",
      "test acc (%):  tensor(79.3094)\n",
      "0  train loss:  0.7709457874298096\n",
      "1  train loss:  0.680379331111908\n",
      "2  train loss:  0.566445529460907\n",
      "3  train loss:  0.4976397752761841\n",
      "4  train loss:  0.48833897709846497\n",
      "5  train loss:  0.44842860102653503\n",
      "6  train loss:  0.41493603587150574\n",
      "7  train loss:  0.39423081278800964\n",
      "8  train loss:  0.384653240442276\n",
      "9  train loss:  0.3778233528137207\n",
      "10  train loss:  0.3794441223144531\n",
      "11  train loss:  0.37152889370918274\n",
      "12  train loss:  0.3643154501914978\n",
      "13  train loss:  0.35436901450157166\n",
      "14  train loss:  0.3445751368999481\n",
      "15  train loss:  0.3387492597103119\n",
      "16  train loss:  0.3313452899456024\n",
      "17  train loss:  0.3257494270801544\n",
      "18  train loss:  0.31984710693359375\n",
      "19  train loss:  0.3162112534046173\n",
      "20  train loss:  0.312566876411438\n",
      "21  train loss:  0.30640751123428345\n",
      "22  train loss:  0.3020613491535187\n",
      "23  train loss:  0.29843050241470337\n",
      "24  train loss:  0.29387322068214417\n",
      "25  train loss:  0.2879067063331604\n",
      "26  train loss:  0.28441908955574036\n",
      "27  train loss:  0.2818082273006439\n",
      "28  train loss:  0.2780490219593048\n",
      "29  train loss:  0.2749558687210083\n",
      "30  train loss:  0.27418115735054016\n",
      "31  train loss:  0.2697928249835968\n",
      "32  train loss:  0.26731306314468384\n",
      "33  train loss:  0.2640959918498993\n",
      "34  train loss:  0.2590636610984802\n",
      "35  train loss:  0.25645333528518677\n",
      "36  train loss:  0.25435346364974976\n",
      "37  train loss:  0.24956873059272766\n",
      "38  train loss:  0.24992305040359497\n",
      "39  train loss:  0.24584229290485382\n",
      "40  train loss:  0.2452894002199173\n",
      "41  train loss:  0.2459641993045807\n",
      "42  train loss:  0.24313808977603912\n",
      "43  train loss:  0.24194170534610748\n",
      "44  train loss:  0.23740386962890625\n",
      "45  train loss:  0.234142005443573\n",
      "46  train loss:  0.23315009474754333\n",
      "47  train loss:  0.23197583854198456\n",
      "48  train loss:  0.2308891862630844\n",
      "49  train loss:  0.2282124012708664\n",
      "50  train loss:  0.2289377599954605\n",
      "51  train loss:  0.2255256474018097\n",
      "52  train loss:  0.22092977166175842\n",
      "53  train loss:  0.21842974424362183\n",
      "54  train loss:  0.21734312176704407\n",
      "55  train loss:  0.21410779654979706\n",
      "56  train loss:  0.21480415761470795\n",
      "57  train loss:  0.2120354324579239\n",
      "58  train loss:  0.21093329787254333\n",
      "59  train loss:  0.2072596400976181\n",
      "60  train loss:  0.205500066280365\n",
      "61  train loss:  0.20282591879367828\n",
      "62  train loss:  0.2016509473323822\n",
      "63  train loss:  0.20006991922855377\n",
      "64  train loss:  0.1993807703256607\n",
      "65  train loss:  0.1975458711385727\n",
      "66  train loss:  0.19531477987766266\n",
      "67  train loss:  0.19458694756031036\n",
      "68  train loss:  0.19228143990039825\n",
      "69  train loss:  0.190121129155159\n",
      "70  train loss:  0.18768274784088135\n",
      "71  train loss:  0.18648108839988708\n",
      "72  train loss:  0.18348829448223114\n",
      "73  train loss:  0.18087852001190186\n",
      "74  train loss:  0.1793484091758728\n",
      "75  train loss:  0.1799815446138382\n",
      "76  train loss:  0.2005603164434433\n",
      "77  train loss:  0.21575234830379486\n",
      "78  train loss:  0.24998968839645386\n",
      "79  train loss:  0.19641560316085815\n",
      "80  train loss:  0.2568800449371338\n",
      "81  train loss:  0.2770633399486542\n",
      "82  train loss:  0.2694145441055298\n",
      "83  train loss:  0.21714143455028534\n",
      "84  train loss:  0.21258418262004852\n",
      "85  train loss:  0.23058339953422546\n",
      "86  train loss:  0.22574014961719513\n",
      "87  train loss:  0.227148175239563\n",
      "88  train loss:  0.2293175756931305\n",
      "89  train loss:  0.21353766322135925\n",
      "90  train loss:  0.21970252692699432\n",
      "91  train loss:  0.21826466917991638\n",
      "92  train loss:  0.22970449924468994\n",
      "93  train loss:  0.227502703666687\n",
      "94  train loss:  0.21471425890922546\n",
      "95  train loss:  0.2113640308380127\n",
      "96  train loss:  0.20451407134532928\n",
      "97  train loss:  0.2023221105337143\n",
      "98  train loss:  0.19689324498176575\n",
      "99  train loss:  0.19337646663188934\n",
      "test acc (%):  tensor(77.8021)\n",
      "0  train loss:  0.5167626142501831\n",
      "1  train loss:  0.44724181294441223\n",
      "2  train loss:  0.4063095450401306\n",
      "3  train loss:  0.4002903401851654\n",
      "4  train loss:  0.3867650628089905\n",
      "5  train loss:  0.37010157108306885\n",
      "6  train loss:  0.3477318584918976\n",
      "7  train loss:  0.33234795928001404\n",
      "8  train loss:  0.3234553039073944\n",
      "9  train loss:  0.3126946687698364\n",
      "10  train loss:  0.3045501410961151\n",
      "11  train loss:  0.30315354466438293\n",
      "12  train loss:  0.29254722595214844\n",
      "13  train loss:  0.2873331606388092\n",
      "14  train loss:  0.28360989689826965\n",
      "15  train loss:  0.28109216690063477\n",
      "16  train loss:  0.27818235754966736\n",
      "17  train loss:  0.2727818191051483\n",
      "18  train loss:  0.2710120677947998\n",
      "19  train loss:  0.26369473338127136\n",
      "20  train loss:  0.2570970952510834\n",
      "21  train loss:  0.2554297149181366\n",
      "22  train loss:  0.2523350715637207\n",
      "23  train loss:  0.2488672435283661\n",
      "24  train loss:  0.24509499967098236\n",
      "25  train loss:  0.24191582202911377\n",
      "26  train loss:  0.23868170380592346\n",
      "27  train loss:  0.2366950362920761\n",
      "28  train loss:  0.23415057361125946\n",
      "29  train loss:  0.2327943742275238\n",
      "30  train loss:  0.2300485372543335\n",
      "31  train loss:  0.22841037809848785\n",
      "32  train loss:  0.2245386689901352\n",
      "33  train loss:  0.22165422141551971\n",
      "34  train loss:  0.2218468338251114\n",
      "35  train loss:  0.21690386533737183\n",
      "36  train loss:  0.21562041342258453\n",
      "37  train loss:  0.21691253781318665\n",
      "38  train loss:  0.21412286162376404\n",
      "39  train loss:  0.21007892489433289\n",
      "40  train loss:  0.2074822038412094\n",
      "41  train loss:  0.20825427770614624\n",
      "42  train loss:  0.2058093100786209\n",
      "43  train loss:  0.20329785346984863\n",
      "44  train loss:  0.2024390995502472\n",
      "45  train loss:  0.20174747705459595\n",
      "46  train loss:  0.20033954083919525\n",
      "47  train loss:  0.1980401575565338\n",
      "48  train loss:  0.19698673486709595\n",
      "49  train loss:  0.19730380177497864\n",
      "50  train loss:  0.1958250105381012\n",
      "51  train loss:  0.1930793672800064\n",
      "52  train loss:  0.19162024557590485\n",
      "53  train loss:  0.19032056629657745\n",
      "54  train loss:  0.1890813559293747\n",
      "55  train loss:  0.18793641030788422\n",
      "56  train loss:  0.1868905872106552\n",
      "57  train loss:  0.1860489398241043\n",
      "58  train loss:  0.18417492508888245\n",
      "59  train loss:  0.183094322681427\n",
      "60  train loss:  0.1808534562587738\n",
      "61  train loss:  0.17941170930862427\n",
      "62  train loss:  0.17856785655021667\n",
      "63  train loss:  0.17742329835891724\n",
      "64  train loss:  0.17576394975185394\n",
      "65  train loss:  0.17670714855194092\n",
      "66  train loss:  0.1741057187318802\n",
      "67  train loss:  0.17298917472362518\n",
      "68  train loss:  0.17193730175495148\n",
      "69  train loss:  0.1707574427127838\n",
      "70  train loss:  0.17013271152973175\n",
      "71  train loss:  0.1685297042131424\n",
      "72  train loss:  0.1674991399049759\n",
      "73  train loss:  0.16639384627342224\n",
      "74  train loss:  0.16520890593528748\n",
      "75  train loss:  0.16406600177288055\n",
      "76  train loss:  0.16316869854927063\n",
      "77  train loss:  0.16259056329727173\n",
      "78  train loss:  0.16380295157432556\n",
      "79  train loss:  0.16421930491924286\n",
      "80  train loss:  0.17184925079345703\n",
      "81  train loss:  0.1745573878288269\n",
      "82  train loss:  0.16930341720581055\n",
      "83  train loss:  0.17040467262268066\n",
      "84  train loss:  0.16540516912937164\n",
      "85  train loss:  0.16229602694511414\n",
      "86  train loss:  0.16160348057746887\n",
      "87  train loss:  0.1599627137184143\n",
      "88  train loss:  0.15681342780590057\n",
      "89  train loss:  0.1577884405851364\n",
      "90  train loss:  0.15801352262496948\n",
      "91  train loss:  0.1580478549003601\n",
      "92  train loss:  0.15755189955234528\n",
      "93  train loss:  0.1554432213306427\n",
      "94  train loss:  0.15299642086029053\n",
      "95  train loss:  0.15128633379936218\n",
      "96  train loss:  0.15197283029556274\n",
      "97  train loss:  0.14910666644573212\n",
      "98  train loss:  0.14806599915027618\n",
      "99  train loss:  0.1502377986907959\n",
      "test acc (%):  tensor(79.3094)\n",
      "0  train loss:  0.5382158756256104\n",
      "1  train loss:  0.4914323091506958\n",
      "2  train loss:  0.44796329736709595\n",
      "3  train loss:  0.4116383492946625\n",
      "4  train loss:  0.37989065051078796\n",
      "5  train loss:  0.36871767044067383\n",
      "6  train loss:  0.35553112626075745\n",
      "7  train loss:  0.3402159810066223\n",
      "8  train loss:  0.33157357573509216\n",
      "9  train loss:  0.3219216465950012\n",
      "10  train loss:  0.3200405240058899\n",
      "11  train loss:  0.31426507234573364\n",
      "12  train loss:  0.30091196298599243\n",
      "13  train loss:  0.29761603474617004\n",
      "14  train loss:  0.28508493304252625\n",
      "15  train loss:  0.2868310213088989\n",
      "16  train loss:  0.2832575738430023\n",
      "17  train loss:  0.2762492597103119\n",
      "18  train loss:  0.2737516164779663\n",
      "19  train loss:  0.274014413356781\n",
      "20  train loss:  0.27082282304763794\n",
      "21  train loss:  0.26904332637786865\n",
      "22  train loss:  0.26255202293395996\n",
      "23  train loss:  0.26223647594451904\n",
      "24  train loss:  0.2584563195705414\n",
      "25  train loss:  0.2557674050331116\n",
      "26  train loss:  0.2518194019794464\n",
      "27  train loss:  0.24989478290081024\n",
      "28  train loss:  0.2471858412027359\n",
      "29  train loss:  0.24480624496936798\n",
      "30  train loss:  0.2432214468717575\n",
      "31  train loss:  0.24001534283161163\n",
      "32  train loss:  0.23901356756687164\n",
      "33  train loss:  0.23662914335727692\n",
      "34  train loss:  0.2336350381374359\n",
      "35  train loss:  0.23133978247642517\n",
      "36  train loss:  0.22942179441452026\n",
      "37  train loss:  0.2293165922164917\n",
      "38  train loss:  0.22734306752681732\n",
      "39  train loss:  0.22458383440971375\n",
      "40  train loss:  0.22499176859855652\n",
      "41  train loss:  0.22165246307849884\n",
      "42  train loss:  0.21942107379436493\n",
      "43  train loss:  0.2174621820449829\n",
      "44  train loss:  0.21814963221549988\n",
      "45  train loss:  0.21549512445926666\n",
      "46  train loss:  0.21391387283802032\n",
      "47  train loss:  0.21173007786273956\n",
      "48  train loss:  0.21151110529899597\n",
      "49  train loss:  0.2095014899969101\n",
      "50  train loss:  0.2084013968706131\n",
      "51  train loss:  0.20655007660388947\n",
      "52  train loss:  0.2062683254480362\n",
      "53  train loss:  0.2028476893901825\n",
      "54  train loss:  0.20136892795562744\n",
      "55  train loss:  0.19952894747257233\n",
      "56  train loss:  0.19907249510288239\n",
      "57  train loss:  0.1972101777791977\n",
      "58  train loss:  0.1971065104007721\n",
      "59  train loss:  0.19527161121368408\n",
      "60  train loss:  0.1937919557094574\n",
      "61  train loss:  0.19293716549873352\n",
      "62  train loss:  0.19221071898937225\n",
      "63  train loss:  0.19080282747745514\n",
      "64  train loss:  0.18943770229816437\n",
      "65  train loss:  0.18938817083835602\n",
      "66  train loss:  0.1882910430431366\n",
      "67  train loss:  0.1861676275730133\n",
      "68  train loss:  0.18565350770950317\n",
      "69  train loss:  0.18311549723148346\n",
      "70  train loss:  0.18435972929000854\n",
      "71  train loss:  0.18190856277942657\n",
      "72  train loss:  0.18052861094474792\n",
      "73  train loss:  0.18044447898864746\n",
      "74  train loss:  0.17946065962314606\n",
      "75  train loss:  0.1773737519979477\n",
      "76  train loss:  0.17708110809326172\n",
      "77  train loss:  0.17576099932193756\n",
      "78  train loss:  0.17498162388801575\n",
      "79  train loss:  0.1736331284046173\n",
      "80  train loss:  0.17356574535369873\n",
      "81  train loss:  0.17600789666175842\n",
      "82  train loss:  0.1720464527606964\n",
      "83  train loss:  0.1728537529706955\n",
      "84  train loss:  0.17178745567798615\n",
      "85  train loss:  0.1701180636882782\n",
      "86  train loss:  0.1696660816669464\n",
      "87  train loss:  0.16816633939743042\n",
      "88  train loss:  0.16987764835357666\n",
      "89  train loss:  0.1672837883234024\n",
      "90  train loss:  0.16675743460655212\n",
      "91  train loss:  0.16642192006111145\n",
      "92  train loss:  0.16634120047092438\n",
      "93  train loss:  0.1658354103565216\n",
      "94  train loss:  0.16383793950080872\n",
      "95  train loss:  0.16417567431926727\n",
      "96  train loss:  0.16569961607456207\n",
      "97  train loss:  0.16345129907131195\n",
      "98  train loss:  0.1639701873064041\n",
      "99  train loss:  0.16103006899356842\n",
      "test acc (%):  tensor(77.4185)\n",
      "0  train loss:  0.49010175466537476\n",
      "1  train loss:  0.4242294132709503\n",
      "2  train loss:  0.3867684602737427\n",
      "3  train loss:  0.3629301190376282\n",
      "4  train loss:  0.34893670678138733\n",
      "5  train loss:  0.3484891355037689\n",
      "6  train loss:  0.33779311180114746\n",
      "7  train loss:  0.3233455419540405\n",
      "8  train loss:  0.3135721981525421\n",
      "9  train loss:  0.3323131501674652\n",
      "10  train loss:  0.2962920367717743\n",
      "11  train loss:  0.2892927825450897\n",
      "12  train loss:  0.29182857275009155\n",
      "13  train loss:  0.2864178717136383\n",
      "14  train loss:  0.27715423703193665\n",
      "15  train loss:  0.2708192467689514\n",
      "16  train loss:  0.2650771141052246\n",
      "17  train loss:  0.25893720984458923\n",
      "18  train loss:  0.25415563583374023\n",
      "19  train loss:  0.25155109167099\n",
      "20  train loss:  0.25178804993629456\n",
      "21  train loss:  0.2492910623550415\n",
      "22  train loss:  0.2451038658618927\n",
      "23  train loss:  0.23942822217941284\n",
      "24  train loss:  0.2351599633693695\n",
      "25  train loss:  0.23362061381340027\n",
      "26  train loss:  0.22623692452907562\n",
      "27  train loss:  0.2273455113172531\n",
      "28  train loss:  0.22112281620502472\n",
      "29  train loss:  0.2179221361875534\n",
      "30  train loss:  0.21495310962200165\n",
      "31  train loss:  0.21649882197380066\n",
      "32  train loss:  0.21679668128490448\n",
      "33  train loss:  0.2102983146905899\n",
      "34  train loss:  0.20894858241081238\n",
      "35  train loss:  0.20962004363536835\n",
      "36  train loss:  0.20883682370185852\n",
      "37  train loss:  0.20679697394371033\n",
      "38  train loss:  0.20201648771762848\n",
      "39  train loss:  0.19767235219478607\n",
      "40  train loss:  0.19569317996501923\n",
      "41  train loss:  0.19493526220321655\n",
      "42  train loss:  0.19271643459796906\n",
      "43  train loss:  0.19029855728149414\n",
      "44  train loss:  0.18825341761112213\n",
      "45  train loss:  0.18648186326026917\n",
      "46  train loss:  0.18474654853343964\n",
      "47  train loss:  0.18308216333389282\n",
      "48  train loss:  0.18123529851436615\n",
      "49  train loss:  0.17935283482074738\n",
      "50  train loss:  0.179036483168602\n",
      "51  train loss:  0.1771756410598755\n",
      "52  train loss:  0.17526564002037048\n",
      "53  train loss:  0.17311736941337585\n",
      "54  train loss:  0.17161676287651062\n",
      "55  train loss:  0.16997133195400238\n",
      "56  train loss:  0.16913394629955292\n",
      "57  train loss:  0.16853486001491547\n",
      "58  train loss:  0.1670909821987152\n",
      "59  train loss:  0.16598203778266907\n",
      "60  train loss:  0.1655176728963852\n",
      "61  train loss:  0.1658717393875122\n",
      "62  train loss:  0.1650404930114746\n",
      "63  train loss:  0.16272996366024017\n",
      "64  train loss:  0.16303013265132904\n",
      "65  train loss:  0.16200926899909973\n",
      "66  train loss:  0.16132085025310516\n",
      "67  train loss:  0.16086134314537048\n",
      "68  train loss:  0.1601603776216507\n",
      "69  train loss:  0.16128048300743103\n",
      "70  train loss:  0.1590593159198761\n",
      "71  train loss:  0.1600279062986374\n",
      "72  train loss:  0.15609674155712128\n",
      "73  train loss:  0.15849265456199646\n",
      "74  train loss:  0.15661585330963135\n",
      "75  train loss:  0.1584821194410324\n",
      "76  train loss:  0.15554459393024445\n",
      "77  train loss:  0.1645195484161377\n",
      "78  train loss:  0.15431448817253113\n",
      "79  train loss:  0.16405345499515533\n",
      "80  train loss:  0.15343721210956573\n",
      "81  train loss:  0.15817461907863617\n",
      "82  train loss:  0.158799409866333\n",
      "83  train loss:  0.15311071276664734\n",
      "84  train loss:  0.1528356969356537\n",
      "85  train loss:  0.1505511850118637\n",
      "86  train loss:  0.15425774455070496\n",
      "87  train loss:  0.15210235118865967\n",
      "88  train loss:  0.1502772718667984\n",
      "89  train loss:  0.15956982970237732\n",
      "90  train loss:  0.1521015465259552\n",
      "91  train loss:  0.1663031280040741\n",
      "92  train loss:  0.1546780914068222\n",
      "93  train loss:  0.15926297008991241\n",
      "94  train loss:  0.14798356592655182\n",
      "95  train loss:  0.15331663191318512\n",
      "96  train loss:  0.16442090272903442\n",
      "97  train loss:  0.15431393682956696\n",
      "98  train loss:  0.14814624190330505\n",
      "99  train loss:  0.16254471242427826\n",
      "test acc (%):  tensor(78.7065)\n",
      "0  train loss:  0.47873345017433167\n",
      "1  train loss:  0.43942785263061523\n",
      "2  train loss:  0.39906689524650574\n",
      "3  train loss:  0.3812221884727478\n",
      "4  train loss:  0.3614707887172699\n",
      "5  train loss:  0.3468765318393707\n",
      "6  train loss:  0.3386400640010834\n",
      "7  train loss:  0.32696518301963806\n",
      "8  train loss:  0.31082987785339355\n",
      "9  train loss:  0.30827999114990234\n",
      "10  train loss:  0.29975953698158264\n",
      "11  train loss:  0.28966832160949707\n",
      "12  train loss:  0.28298187255859375\n",
      "13  train loss:  0.28109338879585266\n",
      "14  train loss:  0.2752423584461212\n",
      "15  train loss:  0.26746654510498047\n",
      "16  train loss:  0.26367366313934326\n",
      "17  train loss:  0.2646980583667755\n",
      "18  train loss:  0.2559308409690857\n",
      "19  train loss:  0.24891018867492676\n",
      "20  train loss:  0.24474312365055084\n",
      "21  train loss:  0.24710699915885925\n",
      "22  train loss:  0.24611306190490723\n",
      "23  train loss:  0.24659191071987152\n",
      "24  train loss:  0.24438311159610748\n",
      "25  train loss:  0.23986095190048218\n",
      "26  train loss:  0.23377278447151184\n",
      "27  train loss:  0.24540726840496063\n",
      "28  train loss:  0.2368883341550827\n",
      "29  train loss:  0.24322086572647095\n",
      "30  train loss:  0.24499990046024323\n",
      "31  train loss:  0.2453433871269226\n",
      "32  train loss:  0.2395508885383606\n",
      "33  train loss:  0.23686598241329193\n",
      "34  train loss:  0.2322835624217987\n",
      "35  train loss:  0.22921688854694366\n",
      "36  train loss:  0.23048169910907745\n",
      "37  train loss:  0.2195773720741272\n",
      "38  train loss:  0.21734048426151276\n",
      "39  train loss:  0.21521241962909698\n",
      "40  train loss:  0.20955443382263184\n",
      "41  train loss:  0.21450653672218323\n",
      "42  train loss:  0.20789583027362823\n",
      "43  train loss:  0.20722827315330505\n",
      "44  train loss:  0.20471443235874176\n",
      "45  train loss:  0.2008649855852127\n",
      "46  train loss:  0.19867810606956482\n",
      "47  train loss:  0.19672240316867828\n",
      "48  train loss:  0.1933775693178177\n",
      "49  train loss:  0.19393350183963776\n",
      "50  train loss:  0.1926945298910141\n",
      "51  train loss:  0.1935228705406189\n",
      "52  train loss:  0.18814925849437714\n",
      "53  train loss:  0.18785350024700165\n",
      "54  train loss:  0.18576565384864807\n",
      "55  train loss:  0.18643885850906372\n",
      "56  train loss:  0.1848512440919876\n",
      "57  train loss:  0.18343542516231537\n",
      "58  train loss:  0.18172882497310638\n",
      "59  train loss:  0.1831361949443817\n",
      "60  train loss:  0.1804819405078888\n",
      "61  train loss:  0.18100330233573914\n",
      "62  train loss:  0.1787349134683609\n",
      "63  train loss:  0.17895495891571045\n",
      "64  train loss:  0.17613838613033295\n",
      "65  train loss:  0.17515112459659576\n",
      "66  train loss:  0.1745220273733139\n",
      "67  train loss:  0.17306223511695862\n",
      "68  train loss:  0.1738595813512802\n",
      "69  train loss:  0.17315271496772766\n",
      "70  train loss:  0.17201142013072968\n",
      "71  train loss:  0.17141813039779663\n",
      "72  train loss:  0.16842439770698547\n",
      "73  train loss:  0.16837024688720703\n",
      "74  train loss:  0.16784629225730896\n",
      "75  train loss:  0.16673852503299713\n",
      "76  train loss:  0.1673867553472519\n",
      "77  train loss:  0.166864275932312\n",
      "78  train loss:  0.16438277065753937\n",
      "79  train loss:  0.16356925666332245\n",
      "80  train loss:  0.16300912201404572\n",
      "81  train loss:  0.16191528737545013\n",
      "82  train loss:  0.1608942300081253\n",
      "83  train loss:  0.16069673001766205\n",
      "84  train loss:  0.15985369682312012\n",
      "85  train loss:  0.15896008908748627\n",
      "86  train loss:  0.15813098847866058\n",
      "87  train loss:  0.15733587741851807\n",
      "88  train loss:  0.15665531158447266\n",
      "89  train loss:  0.15579381585121155\n",
      "90  train loss:  0.15520809590816498\n",
      "91  train loss:  0.15418139100074768\n",
      "92  train loss:  0.15359161794185638\n",
      "93  train loss:  0.15250012278556824\n",
      "94  train loss:  0.15187740325927734\n",
      "95  train loss:  0.1511063575744629\n",
      "96  train loss:  0.15033045411109924\n",
      "97  train loss:  0.14952649176120758\n",
      "98  train loss:  0.14911000430583954\n",
      "99  train loss:  0.14836518466472626\n",
      "test acc (%):  tensor(78.3228)\n",
      "0  train loss:  0.6492352485656738\n",
      "1  train loss:  0.5112026929855347\n",
      "2  train loss:  0.4252936840057373\n",
      "3  train loss:  0.4088808000087738\n",
      "4  train loss:  0.3982701003551483\n",
      "5  train loss:  0.3765893876552582\n",
      "6  train loss:  0.3667777180671692\n",
      "7  train loss:  0.35975182056427\n",
      "8  train loss:  0.3558046519756317\n",
      "9  train loss:  0.3508974015712738\n",
      "10  train loss:  0.3470253646373749\n",
      "11  train loss:  0.3353336453437805\n",
      "12  train loss:  0.32629114389419556\n",
      "13  train loss:  0.32132458686828613\n",
      "14  train loss:  0.31564775109291077\n",
      "15  train loss:  0.3128555417060852\n",
      "16  train loss:  0.3081415593624115\n",
      "17  train loss:  0.3063987195491791\n",
      "18  train loss:  0.3036520183086395\n",
      "19  train loss:  0.2991652190685272\n",
      "20  train loss:  0.2937909662723541\n",
      "21  train loss:  0.2911864221096039\n",
      "22  train loss:  0.28694799542427063\n",
      "23  train loss:  0.28409814834594727\n",
      "24  train loss:  0.2811868190765381\n",
      "25  train loss:  0.2754916548728943\n",
      "26  train loss:  0.2747173607349396\n",
      "27  train loss:  0.2723434865474701\n",
      "28  train loss:  0.27026328444480896\n",
      "29  train loss:  0.26892992854118347\n",
      "30  train loss:  0.26299750804901123\n",
      "31  train loss:  0.2624935507774353\n",
      "32  train loss:  0.25944292545318604\n",
      "33  train loss:  0.2542289197444916\n",
      "34  train loss:  0.2515355944633484\n",
      "35  train loss:  0.2491087019443512\n",
      "36  train loss:  0.24621674418449402\n",
      "37  train loss:  0.2423686534166336\n",
      "38  train loss:  0.24194422364234924\n",
      "39  train loss:  0.2414991706609726\n",
      "40  train loss:  0.23803113400936127\n",
      "41  train loss:  0.23605233430862427\n",
      "42  train loss:  0.23418660461902618\n",
      "43  train loss:  0.23262211680412292\n",
      "44  train loss:  0.22965547442436218\n",
      "45  train loss:  0.2283879667520523\n",
      "46  train loss:  0.22757385671138763\n",
      "47  train loss:  0.2258473038673401\n",
      "48  train loss:  0.22397981584072113\n",
      "49  train loss:  0.22274565696716309\n",
      "50  train loss:  0.22130423784255981\n",
      "51  train loss:  0.21987436711788177\n",
      "52  train loss:  0.22019647061824799\n",
      "53  train loss:  0.21960297226905823\n",
      "54  train loss:  0.21922771632671356\n",
      "55  train loss:  0.21634463965892792\n",
      "56  train loss:  0.2169201523065567\n",
      "57  train loss:  0.2150409072637558\n",
      "58  train loss:  0.21362844109535217\n",
      "59  train loss:  0.21364663541316986\n",
      "60  train loss:  0.2112923264503479\n",
      "61  train loss:  0.21204745769500732\n",
      "62  train loss:  0.2094937264919281\n",
      "63  train loss:  0.205942302942276\n",
      "64  train loss:  0.20675791800022125\n",
      "65  train loss:  0.20517472922801971\n",
      "66  train loss:  0.20398004353046417\n",
      "67  train loss:  0.20570528507232666\n",
      "68  train loss:  0.20445963740348816\n",
      "69  train loss:  0.20099380612373352\n",
      "70  train loss:  0.20091529190540314\n",
      "71  train loss:  0.198663130402565\n",
      "72  train loss:  0.19705572724342346\n",
      "73  train loss:  0.19983024895191193\n",
      "74  train loss:  0.19620393216609955\n",
      "75  train loss:  0.19432100653648376\n",
      "76  train loss:  0.1955660581588745\n",
      "77  train loss:  0.19282546639442444\n",
      "78  train loss:  0.19226934015750885\n",
      "79  train loss:  0.19244921207427979\n",
      "80  train loss:  0.18998286128044128\n",
      "81  train loss:  0.18894803524017334\n",
      "82  train loss:  0.1889706403017044\n",
      "83  train loss:  0.18903133273124695\n",
      "84  train loss:  0.18750183284282684\n",
      "85  train loss:  0.18743209540843964\n",
      "86  train loss:  0.1865728795528412\n",
      "87  train loss:  0.1851324439048767\n",
      "88  train loss:  0.18517179787158966\n",
      "89  train loss:  0.18337132036685944\n",
      "90  train loss:  0.18374954164028168\n",
      "91  train loss:  0.18255740404129028\n",
      "92  train loss:  0.18383991718292236\n",
      "93  train loss:  0.1821320503950119\n",
      "94  train loss:  0.18186549842357635\n",
      "95  train loss:  0.18090908229351044\n",
      "96  train loss:  0.18038083612918854\n",
      "97  train loss:  0.1804674118757248\n",
      "98  train loss:  0.17917799949645996\n",
      "99  train loss:  0.17840544879436493\n",
      "test acc (%):  tensor(78.1584)\n",
      "0  train loss:  0.4849011301994324\n",
      "1  train loss:  0.4425598382949829\n",
      "2  train loss:  0.39077362418174744\n",
      "3  train loss:  0.3595622777938843\n",
      "4  train loss:  0.34726059436798096\n",
      "5  train loss:  0.33519214391708374\n",
      "6  train loss:  0.3296492397785187\n",
      "7  train loss:  0.32508695125579834\n",
      "8  train loss:  0.31806865334510803\n",
      "9  train loss:  0.30667921900749207\n",
      "10  train loss:  0.30097395181655884\n",
      "11  train loss:  0.3052316904067993\n",
      "12  train loss:  0.3047727048397064\n",
      "13  train loss:  0.3016207218170166\n",
      "14  train loss:  0.2939881980419159\n",
      "15  train loss:  0.2896340489387512\n",
      "16  train loss:  0.2903931736946106\n",
      "17  train loss:  0.2872585356235504\n",
      "18  train loss:  0.2826368510723114\n",
      "19  train loss:  0.28060656785964966\n",
      "20  train loss:  0.2767818570137024\n",
      "21  train loss:  0.27584338188171387\n",
      "22  train loss:  0.2722201645374298\n",
      "23  train loss:  0.2693682312965393\n",
      "24  train loss:  0.2668868899345398\n",
      "25  train loss:  0.2631714642047882\n",
      "26  train loss:  0.2616433799266815\n",
      "27  train loss:  0.2591652274131775\n",
      "28  train loss:  0.2579498887062073\n",
      "29  train loss:  0.2555597424507141\n",
      "30  train loss:  0.2538810074329376\n",
      "31  train loss:  0.25140446424484253\n",
      "32  train loss:  0.24957695603370667\n",
      "33  train loss:  0.24875904619693756\n",
      "34  train loss:  0.24691139161586761\n",
      "35  train loss:  0.24431806802749634\n",
      "36  train loss:  0.2421092689037323\n",
      "37  train loss:  0.2410248965024948\n",
      "38  train loss:  0.2391832321882248\n",
      "39  train loss:  0.24298863112926483\n",
      "40  train loss:  0.23933111131191254\n",
      "41  train loss:  0.2385721653699875\n",
      "42  train loss:  0.2427835762500763\n",
      "43  train loss:  0.2357121855020523\n",
      "44  train loss:  0.2347930520772934\n",
      "45  train loss:  0.2377987653017044\n",
      "46  train loss:  0.23380304872989655\n",
      "47  train loss:  0.23230797052383423\n",
      "48  train loss:  0.228254497051239\n",
      "49  train loss:  0.22902433574199677\n",
      "50  train loss:  0.2242359071969986\n",
      "51  train loss:  0.22496318817138672\n",
      "52  train loss:  0.22544971108436584\n",
      "53  train loss:  0.22198179364204407\n",
      "54  train loss:  0.2196626216173172\n",
      "55  train loss:  0.21962353587150574\n",
      "56  train loss:  0.21930982172489166\n",
      "57  train loss:  0.21829870343208313\n",
      "58  train loss:  0.2162279188632965\n",
      "59  train loss:  0.21415221691131592\n",
      "60  train loss:  0.21356698870658875\n",
      "61  train loss:  0.21364633738994598\n",
      "62  train loss:  0.21142078936100006\n",
      "63  train loss:  0.20939646661281586\n",
      "64  train loss:  0.20885197818279266\n",
      "65  train loss:  0.2085082232952118\n",
      "66  train loss:  0.20784595608711243\n",
      "67  train loss:  0.20680031180381775\n",
      "68  train loss:  0.20651106536388397\n",
      "69  train loss:  0.20525965094566345\n",
      "70  train loss:  0.2051711231470108\n",
      "71  train loss:  0.20428380370140076\n",
      "72  train loss:  0.20198960602283478\n",
      "73  train loss:  0.2032628059387207\n",
      "74  train loss:  0.20191997289657593\n",
      "75  train loss:  0.1997969001531601\n",
      "76  train loss:  0.20037764310836792\n",
      "77  train loss:  0.19901196658611298\n",
      "78  train loss:  0.19823004305362701\n",
      "79  train loss:  0.19797223806381226\n",
      "80  train loss:  0.1960323601961136\n",
      "81  train loss:  0.19472403824329376\n",
      "82  train loss:  0.1952197551727295\n",
      "83  train loss:  0.19387634098529816\n",
      "84  train loss:  0.19298383593559265\n",
      "85  train loss:  0.19165317714214325\n",
      "86  train loss:  0.19157344102859497\n",
      "87  train loss:  0.19092437624931335\n",
      "88  train loss:  0.19094334542751312\n",
      "89  train loss:  0.19399665296077728\n",
      "90  train loss:  0.1885906606912613\n",
      "91  train loss:  0.18971990048885345\n",
      "92  train loss:  0.19123277068138123\n",
      "93  train loss:  0.18838715553283691\n",
      "94  train loss:  0.18928688764572144\n",
      "95  train loss:  0.18524952232837677\n",
      "96  train loss:  0.18466174602508545\n",
      "97  train loss:  0.1846170723438263\n",
      "98  train loss:  0.18228575587272644\n",
      "99  train loss:  0.1838960200548172\n",
      "test acc (%):  tensor(77.3911)\n",
      "0  train loss:  0.5166152119636536\n",
      "1  train loss:  0.4757368266582489\n",
      "2  train loss:  0.44347670674324036\n",
      "3  train loss:  0.42841970920562744\n",
      "4  train loss:  0.41200733184814453\n",
      "5  train loss:  0.3946855366230011\n",
      "6  train loss:  0.38158705830574036\n",
      "7  train loss:  0.37194278836250305\n",
      "8  train loss:  0.3637710511684418\n",
      "9  train loss:  0.34862056374549866\n",
      "10  train loss:  0.340096652507782\n",
      "11  train loss:  0.3290714919567108\n",
      "12  train loss:  0.3291669189929962\n",
      "13  train loss:  0.3177403211593628\n",
      "14  train loss:  0.31819674372673035\n",
      "15  train loss:  0.3075808882713318\n",
      "16  train loss:  0.3117374777793884\n",
      "17  train loss:  0.3001682460308075\n",
      "18  train loss:  0.29575955867767334\n",
      "19  train loss:  0.28730693459510803\n",
      "20  train loss:  0.2853780686855316\n",
      "21  train loss:  0.2812439799308777\n",
      "22  train loss:  0.2822226285934448\n",
      "23  train loss:  0.2766565978527069\n",
      "24  train loss:  0.27461937069892883\n",
      "25  train loss:  0.27271130681037903\n",
      "26  train loss:  0.2703884541988373\n",
      "27  train loss:  0.2685447931289673\n",
      "28  train loss:  0.2648133635520935\n",
      "29  train loss:  0.26149842143058777\n",
      "30  train loss:  0.25695499777793884\n",
      "31  train loss:  0.25356176495552063\n",
      "32  train loss:  0.2514638602733612\n",
      "33  train loss:  0.24939073622226715\n",
      "34  train loss:  0.24688999354839325\n",
      "35  train loss:  0.24446821212768555\n",
      "36  train loss:  0.2429393082857132\n",
      "37  train loss:  0.24035963416099548\n",
      "38  train loss:  0.23862965404987335\n",
      "39  train loss:  0.23808720707893372\n",
      "40  train loss:  0.23508396744728088\n",
      "41  train loss:  0.2341170758008957\n",
      "42  train loss:  0.23391121625900269\n",
      "43  train loss:  0.2306927740573883\n",
      "44  train loss:  0.22904250025749207\n",
      "45  train loss:  0.22971822321414948\n",
      "46  train loss:  0.2265041023492813\n",
      "47  train loss:  0.22818315029144287\n",
      "48  train loss:  0.2267850637435913\n",
      "49  train loss:  0.22380898892879486\n",
      "50  train loss:  0.2241026610136032\n",
      "51  train loss:  0.22262327373027802\n",
      "52  train loss:  0.22161619365215302\n",
      "53  train loss:  0.22297751903533936\n",
      "54  train loss:  0.22248388826847076\n",
      "55  train loss:  0.22498780488967896\n",
      "56  train loss:  0.22269386053085327\n",
      "57  train loss:  0.2198495715856552\n",
      "58  train loss:  0.22686725854873657\n",
      "59  train loss:  0.21616625785827637\n",
      "60  train loss:  0.2276262789964676\n",
      "61  train loss:  0.21336236596107483\n",
      "62  train loss:  0.21258512139320374\n",
      "63  train loss:  0.22035159170627594\n",
      "64  train loss:  0.21322309970855713\n",
      "65  train loss:  0.21016280353069305\n",
      "66  train loss:  0.21162265539169312\n",
      "67  train loss:  0.2114710658788681\n",
      "68  train loss:  0.20601043105125427\n",
      "69  train loss:  0.2092140018939972\n",
      "70  train loss:  0.2068481594324112\n",
      "71  train loss:  0.2054232656955719\n",
      "72  train loss:  0.20345529913902283\n",
      "73  train loss:  0.20958314836025238\n",
      "74  train loss:  0.20587751269340515\n",
      "75  train loss:  0.20224547386169434\n",
      "76  train loss:  0.19847002625465393\n",
      "77  train loss:  0.20434565842151642\n",
      "78  train loss:  0.1969342827796936\n",
      "79  train loss:  0.1986013501882553\n",
      "80  train loss:  0.1949024349451065\n",
      "81  train loss:  0.194710835814476\n",
      "82  train loss:  0.19352591037750244\n",
      "83  train loss:  0.19352933764457703\n",
      "84  train loss:  0.1910076141357422\n",
      "85  train loss:  0.19159355759620667\n",
      "86  train loss:  0.18842290341854095\n",
      "87  train loss:  0.18991918861865997\n",
      "88  train loss:  0.18909142911434174\n",
      "89  train loss:  0.1867998093366623\n",
      "90  train loss:  0.18824872374534607\n",
      "91  train loss:  0.19106411933898926\n",
      "92  train loss:  0.18955278396606445\n",
      "93  train loss:  0.1868431270122528\n",
      "94  train loss:  0.19119620323181152\n",
      "95  train loss:  0.18985484540462494\n",
      "96  train loss:  0.18629421293735504\n",
      "97  train loss:  0.19138593971729279\n",
      "98  train loss:  0.18576014041900635\n",
      "99  train loss:  0.19033309817314148\n",
      "test acc (%):  tensor(77.1992)\n",
      "0  train loss:  0.6110591292381287\n",
      "1  train loss:  0.547713577747345\n",
      "2  train loss:  0.49347198009490967\n",
      "3  train loss:  0.4605344235897064\n",
      "4  train loss:  0.5000701546669006\n",
      "5  train loss:  0.4172792136669159\n",
      "6  train loss:  0.4119921922683716\n",
      "7  train loss:  0.40413713455200195\n",
      "8  train loss:  0.3844398260116577\n",
      "9  train loss:  0.38185080885887146\n",
      "10  train loss:  0.37453433871269226\n",
      "11  train loss:  0.3619057238101959\n",
      "12  train loss:  0.3546804189682007\n",
      "13  train loss:  0.3509545624256134\n",
      "14  train loss:  0.3452126085758209\n",
      "15  train loss:  0.33894291520118713\n",
      "16  train loss:  0.3300398588180542\n",
      "17  train loss:  0.31892308592796326\n",
      "18  train loss:  0.3117031157016754\n",
      "19  train loss:  0.30840003490448\n",
      "20  train loss:  0.3129477798938751\n",
      "21  train loss:  0.3126662075519562\n",
      "22  train loss:  0.3129541873931885\n",
      "23  train loss:  0.2994842529296875\n",
      "24  train loss:  0.3057834506034851\n",
      "25  train loss:  0.30057552456855774\n",
      "26  train loss:  0.29660654067993164\n",
      "27  train loss:  0.2936195731163025\n",
      "28  train loss:  0.2894301116466522\n",
      "29  train loss:  0.2858365774154663\n",
      "30  train loss:  0.28038984537124634\n",
      "31  train loss:  0.27891862392425537\n",
      "32  train loss:  0.2741073966026306\n",
      "33  train loss:  0.27382978796958923\n",
      "34  train loss:  0.271079421043396\n",
      "35  train loss:  0.2694198787212372\n",
      "36  train loss:  0.2659843862056732\n",
      "37  train loss:  0.2674727141857147\n",
      "38  train loss:  0.26075997948646545\n",
      "39  train loss:  0.25972098112106323\n",
      "40  train loss:  0.25613197684288025\n",
      "41  train loss:  0.25541144609451294\n",
      "42  train loss:  0.25163304805755615\n",
      "43  train loss:  0.24994587898254395\n",
      "44  train loss:  0.25094109773635864\n",
      "45  train loss:  0.24688436090946198\n",
      "46  train loss:  0.24719330668449402\n",
      "47  train loss:  0.2455519437789917\n",
      "48  train loss:  0.24350719153881073\n",
      "49  train loss:  0.24155379831790924\n",
      "50  train loss:  0.24101637303829193\n",
      "51  train loss:  0.23949018120765686\n",
      "52  train loss:  0.23882126808166504\n",
      "53  train loss:  0.23779748380184174\n",
      "54  train loss:  0.23593619465827942\n",
      "55  train loss:  0.23838795721530914\n",
      "56  train loss:  0.240681454539299\n",
      "57  train loss:  0.23317310214042664\n",
      "58  train loss:  0.2443448156118393\n",
      "59  train loss:  0.23115336894989014\n",
      "60  train loss:  0.23524507880210876\n",
      "61  train loss:  0.2310847043991089\n",
      "62  train loss:  0.2285459041595459\n",
      "63  train loss:  0.22948786616325378\n",
      "64  train loss:  0.2285543978214264\n",
      "65  train loss:  0.23102153837680817\n",
      "66  train loss:  0.22373275458812714\n",
      "67  train loss:  0.22574706375598907\n",
      "68  train loss:  0.2203952521085739\n",
      "69  train loss:  0.21955470740795135\n",
      "70  train loss:  0.21913129091262817\n",
      "71  train loss:  0.21658380329608917\n",
      "72  train loss:  0.2203892469406128\n",
      "73  train loss:  0.22215795516967773\n",
      "74  train loss:  0.22130584716796875\n",
      "75  train loss:  0.2230861932039261\n",
      "76  train loss:  0.21324504911899567\n",
      "77  train loss:  0.2209705412387848\n",
      "78  train loss:  0.2118872106075287\n",
      "79  train loss:  0.2093338668346405\n",
      "80  train loss:  0.2111174613237381\n",
      "81  train loss:  0.20740827918052673\n",
      "82  train loss:  0.21162910759449005\n",
      "83  train loss:  0.20572277903556824\n",
      "84  train loss:  0.20535826683044434\n",
      "85  train loss:  0.21006855368614197\n",
      "86  train loss:  0.20335188508033752\n",
      "87  train loss:  0.2034866064786911\n",
      "88  train loss:  0.2032662183046341\n",
      "89  train loss:  0.19963295757770538\n",
      "90  train loss:  0.19991084933280945\n",
      "91  train loss:  0.1985120177268982\n",
      "92  train loss:  0.2011544555425644\n",
      "93  train loss:  0.2058662325143814\n",
      "94  train loss:  0.19821318984031677\n",
      "95  train loss:  0.21199928224086761\n",
      "96  train loss:  0.1988936960697174\n",
      "97  train loss:  0.21223458647727966\n",
      "98  train loss:  0.19976754486560822\n",
      "99  train loss:  0.20232807099819183\n",
      "test acc (%):  tensor(77.5007)\n",
      "0  train loss:  0.4397011697292328\n",
      "1  train loss:  0.4238611161708832\n",
      "2  train loss:  0.3925372064113617\n",
      "3  train loss:  0.3852439522743225\n",
      "4  train loss:  0.3548601567745209\n",
      "5  train loss:  0.34798672795295715\n",
      "6  train loss:  0.3382188081741333\n",
      "7  train loss:  0.33144456148147583\n",
      "8  train loss:  0.3279241919517517\n",
      "9  train loss:  0.32799312472343445\n",
      "10  train loss:  0.3236880302429199\n",
      "11  train loss:  0.32063600420951843\n",
      "12  train loss:  0.32091230154037476\n",
      "13  train loss:  0.30439406633377075\n",
      "14  train loss:  0.3089253604412079\n",
      "15  train loss:  0.3167416751384735\n",
      "16  train loss:  0.3224642276763916\n",
      "17  train loss:  0.3200533390045166\n",
      "18  train loss:  0.30205339193344116\n",
      "19  train loss:  0.30259090662002563\n",
      "20  train loss:  0.2887008786201477\n",
      "21  train loss:  0.28791555762290955\n",
      "22  train loss:  0.29805245995521545\n",
      "23  train loss:  0.28140103816986084\n",
      "24  train loss:  0.2740561068058014\n",
      "25  train loss:  0.27654212713241577\n",
      "26  train loss:  0.2696749269962311\n",
      "27  train loss:  0.2628920078277588\n",
      "28  train loss:  0.26392650604248047\n",
      "29  train loss:  0.26310810446739197\n",
      "30  train loss:  0.255794882774353\n",
      "31  train loss:  0.2620113790035248\n",
      "32  train loss:  0.2512953579425812\n",
      "33  train loss:  0.24861328303813934\n",
      "34  train loss:  0.24482785165309906\n",
      "35  train loss:  0.24757343530654907\n",
      "36  train loss:  0.24117393791675568\n",
      "37  train loss:  0.24022117257118225\n",
      "38  train loss:  0.23962995409965515\n",
      "39  train loss:  0.23489582538604736\n",
      "40  train loss:  0.23331986367702484\n",
      "41  train loss:  0.22978432476520538\n",
      "42  train loss:  0.22667694091796875\n",
      "43  train loss:  0.22568202018737793\n",
      "44  train loss:  0.22306764125823975\n",
      "45  train loss:  0.2225588858127594\n",
      "46  train loss:  0.22052833437919617\n",
      "47  train loss:  0.2205100655555725\n",
      "48  train loss:  0.2206992357969284\n",
      "49  train loss:  0.21717311441898346\n",
      "50  train loss:  0.21735450625419617\n",
      "51  train loss:  0.21507732570171356\n",
      "52  train loss:  0.21320252120494843\n",
      "53  train loss:  0.2113557606935501\n",
      "54  train loss:  0.21206112205982208\n",
      "55  train loss:  0.21001730859279633\n",
      "56  train loss:  0.2070709466934204\n",
      "57  train loss:  0.20720361173152924\n",
      "58  train loss:  0.2051038146018982\n",
      "59  train loss:  0.20517735183238983\n",
      "60  train loss:  0.20458479225635529\n",
      "61  train loss:  0.20221863687038422\n",
      "62  train loss:  0.20387543737888336\n",
      "63  train loss:  0.20529179275035858\n",
      "64  train loss:  0.2044752687215805\n",
      "65  train loss:  0.20614027976989746\n",
      "66  train loss:  0.21011841297149658\n",
      "67  train loss:  0.20856663584709167\n",
      "68  train loss:  0.2029326856136322\n",
      "69  train loss:  0.21551060676574707\n",
      "70  train loss:  0.20006847381591797\n",
      "71  train loss:  0.21216022968292236\n",
      "72  train loss:  0.21072402596473694\n",
      "73  train loss:  0.2165793478488922\n",
      "74  train loss:  0.20402568578720093\n",
      "75  train loss:  0.20003937184810638\n",
      "76  train loss:  0.20275992155075073\n",
      "77  train loss:  0.20254360139369965\n",
      "78  train loss:  0.19720225036144257\n",
      "79  train loss:  0.20074430108070374\n",
      "80  train loss:  0.19969074428081512\n",
      "81  train loss:  0.19855281710624695\n",
      "82  train loss:  0.19399338960647583\n",
      "83  train loss:  0.1996946781873703\n",
      "84  train loss:  0.19487203657627106\n",
      "85  train loss:  0.19493862986564636\n",
      "86  train loss:  0.19365361332893372\n",
      "87  train loss:  0.19132061302661896\n",
      "88  train loss:  0.19086292386054993\n",
      "89  train loss:  0.19175061583518982\n",
      "90  train loss:  0.18917429447174072\n",
      "91  train loss:  0.18785278499126434\n",
      "92  train loss:  0.18686163425445557\n",
      "93  train loss:  0.18656249344348907\n",
      "94  train loss:  0.1858440786600113\n",
      "95  train loss:  0.1853773593902588\n",
      "96  train loss:  0.18432605266571045\n",
      "97  train loss:  0.18314361572265625\n",
      "98  train loss:  0.1828659027814865\n",
      "99  train loss:  0.18439435958862305\n",
      "test acc (%):  tensor(77.2266)\n",
      "0  train loss:  0.48123791813850403\n",
      "1  train loss:  0.43979984521865845\n",
      "2  train loss:  0.4180186092853546\n",
      "3  train loss:  0.4099618196487427\n",
      "4  train loss:  0.41052019596099854\n",
      "5  train loss:  0.3840923607349396\n",
      "6  train loss:  0.37612518668174744\n",
      "7  train loss:  0.36850714683532715\n",
      "8  train loss:  0.3565589487552643\n",
      "9  train loss:  0.34546199440956116\n",
      "10  train loss:  0.34140312671661377\n",
      "11  train loss:  0.3256871998310089\n",
      "12  train loss:  0.3223322331905365\n",
      "13  train loss:  0.3069027364253998\n",
      "14  train loss:  0.30455276370048523\n",
      "15  train loss:  0.2964686155319214\n",
      "16  train loss:  0.29648521542549133\n",
      "17  train loss:  0.29102155566215515\n",
      "18  train loss:  0.2877964675426483\n",
      "19  train loss:  0.2821415066719055\n",
      "20  train loss:  0.27634191513061523\n",
      "21  train loss:  0.27384328842163086\n",
      "22  train loss:  0.2722867429256439\n",
      "23  train loss:  0.2678975462913513\n",
      "24  train loss:  0.26475632190704346\n",
      "25  train loss:  0.2624760568141937\n",
      "26  train loss:  0.26178380846977234\n",
      "27  train loss:  0.2571789026260376\n",
      "28  train loss:  0.25402557849884033\n",
      "29  train loss:  0.253160297870636\n",
      "30  train loss:  0.25040796399116516\n",
      "31  train loss:  0.2493424117565155\n",
      "32  train loss:  0.24767851829528809\n",
      "33  train loss:  0.2460181564092636\n",
      "34  train loss:  0.24498441815376282\n",
      "35  train loss:  0.2427470088005066\n",
      "36  train loss:  0.24098826944828033\n",
      "37  train loss:  0.23917631804943085\n",
      "38  train loss:  0.23873324692249298\n",
      "39  train loss:  0.23736798763275146\n",
      "40  train loss:  0.23366065323352814\n",
      "41  train loss:  0.2326093167066574\n",
      "42  train loss:  0.23307614028453827\n",
      "43  train loss:  0.2312178909778595\n",
      "44  train loss:  0.23462121188640594\n",
      "45  train loss:  0.2326444536447525\n",
      "46  train loss:  0.22759273648262024\n",
      "47  train loss:  0.22799719870090485\n",
      "48  train loss:  0.22591464221477509\n",
      "49  train loss:  0.22369562089443207\n",
      "50  train loss:  0.22224028408527374\n",
      "51  train loss:  0.22204183042049408\n",
      "52  train loss:  0.22640064358711243\n",
      "53  train loss:  0.2261582911014557\n",
      "54  train loss:  0.22206056118011475\n",
      "55  train loss:  0.2221565693616867\n",
      "56  train loss:  0.21601812541484833\n",
      "57  train loss:  0.21651366353034973\n",
      "58  train loss:  0.21825960278511047\n",
      "59  train loss:  0.2157556712627411\n",
      "60  train loss:  0.21632805466651917\n",
      "61  train loss:  0.2138267308473587\n",
      "62  train loss:  0.21217960119247437\n",
      "63  train loss:  0.2162659913301468\n",
      "64  train loss:  0.21172015368938446\n",
      "65  train loss:  0.21257048845291138\n",
      "66  train loss:  0.21331942081451416\n",
      "67  train loss:  0.20742616057395935\n",
      "68  train loss:  0.2101951539516449\n",
      "69  train loss:  0.20587122440338135\n",
      "70  train loss:  0.20641343295574188\n",
      "71  train loss:  0.20509843528270721\n",
      "72  train loss:  0.2049083411693573\n",
      "73  train loss:  0.20641106367111206\n",
      "74  train loss:  0.20255596935749054\n",
      "75  train loss:  0.2029622197151184\n",
      "76  train loss:  0.2008707970380783\n",
      "77  train loss:  0.20248804986476898\n",
      "78  train loss:  0.20288234949111938\n",
      "79  train loss:  0.19862431287765503\n",
      "80  train loss:  0.19968964159488678\n",
      "81  train loss:  0.19753222167491913\n",
      "82  train loss:  0.19516558945178986\n",
      "83  train loss:  0.19481275975704193\n",
      "84  train loss:  0.1929684430360794\n",
      "85  train loss:  0.1942777782678604\n",
      "86  train loss:  0.19146305322647095\n",
      "87  train loss:  0.19209954142570496\n",
      "88  train loss:  0.19387520849704742\n",
      "89  train loss:  0.192169651389122\n",
      "90  train loss:  0.18871189653873444\n",
      "91  train loss:  0.18900372087955475\n",
      "92  train loss:  0.19076165556907654\n",
      "93  train loss:  0.1914975345134735\n",
      "94  train loss:  0.19106227159500122\n",
      "95  train loss:  0.19321733713150024\n",
      "96  train loss:  0.198515847325325\n",
      "97  train loss:  0.19006408751010895\n",
      "98  train loss:  0.19122862815856934\n",
      "99  train loss:  0.19175979495048523\n",
      "test acc (%):  tensor(77.8569)\n",
      "0  train loss:  0.5208513736724854\n",
      "1  train loss:  0.4412713050842285\n",
      "2  train loss:  0.38919687271118164\n",
      "3  train loss:  0.35748177766799927\n",
      "4  train loss:  0.34745317697525024\n",
      "5  train loss:  0.35071924328804016\n",
      "6  train loss:  0.3293097913265228\n",
      "7  train loss:  0.3240073025226593\n",
      "8  train loss:  0.31857040524482727\n",
      "9  train loss:  0.30409565567970276\n",
      "10  train loss:  0.29566702246665955\n",
      "11  train loss:  0.2879345715045929\n",
      "12  train loss:  0.29392746090888977\n",
      "13  train loss:  0.2803538739681244\n",
      "14  train loss:  0.28866899013519287\n",
      "15  train loss:  0.2814396917819977\n",
      "16  train loss:  0.277386337518692\n",
      "17  train loss:  0.26743441820144653\n",
      "18  train loss:  0.2772047221660614\n",
      "19  train loss:  0.26822713017463684\n",
      "20  train loss:  0.2611466944217682\n",
      "21  train loss:  0.2551957964897156\n",
      "22  train loss:  0.266488641500473\n",
      "23  train loss:  0.24788233637809753\n",
      "24  train loss:  0.24344530701637268\n",
      "25  train loss:  0.2398388832807541\n",
      "26  train loss:  0.23909048736095428\n",
      "27  train loss:  0.2319309115409851\n",
      "28  train loss:  0.23103067278862\n",
      "29  train loss:  0.22744311392307281\n",
      "30  train loss:  0.22905533015727997\n",
      "31  train loss:  0.22219893336296082\n",
      "32  train loss:  0.22324563562870026\n",
      "33  train loss:  0.22291983664035797\n",
      "34  train loss:  0.214192196726799\n",
      "35  train loss:  0.20936235785484314\n",
      "36  train loss:  0.208624005317688\n",
      "37  train loss:  0.2073364406824112\n",
      "38  train loss:  0.20840908586978912\n",
      "39  train loss:  0.21140965819358826\n",
      "40  train loss:  0.2043064534664154\n",
      "41  train loss:  0.2144794762134552\n",
      "42  train loss:  0.21263201534748077\n",
      "43  train loss:  0.20492388308048248\n",
      "44  train loss:  0.20537129044532776\n",
      "45  train loss:  0.20704969763755798\n",
      "46  train loss:  0.20340196788311005\n",
      "47  train loss:  0.20072045922279358\n",
      "48  train loss:  0.19936524331569672\n",
      "49  train loss:  0.19493180513381958\n",
      "50  train loss:  0.19683338701725006\n",
      "51  train loss:  0.19746200740337372\n",
      "52  train loss:  0.1912432760000229\n",
      "53  train loss:  0.19643749296665192\n",
      "54  train loss:  0.19292211532592773\n",
      "55  train loss:  0.18978682160377502\n",
      "56  train loss:  0.18929517269134521\n",
      "57  train loss:  0.18499819934368134\n",
      "58  train loss:  0.18502143025398254\n",
      "59  train loss:  0.18449713289737701\n",
      "60  train loss:  0.18263554573059082\n",
      "61  train loss:  0.18305055797100067\n",
      "62  train loss:  0.18075942993164062\n",
      "63  train loss:  0.18121761083602905\n",
      "64  train loss:  0.17763251066207886\n",
      "65  train loss:  0.17798563838005066\n",
      "66  train loss:  0.17453795671463013\n",
      "67  train loss:  0.1759747862815857\n",
      "68  train loss:  0.17730656266212463\n",
      "69  train loss:  0.17670665681362152\n",
      "70  train loss:  0.17417557537555695\n",
      "71  train loss:  0.17301225662231445\n",
      "72  train loss:  0.17152421176433563\n",
      "73  train loss:  0.17176420986652374\n",
      "74  train loss:  0.1692110151052475\n",
      "75  train loss:  0.16937698423862457\n",
      "76  train loss:  0.16980919241905212\n",
      "77  train loss:  0.1698608547449112\n",
      "78  train loss:  0.17085060477256775\n",
      "79  train loss:  0.16973769664764404\n",
      "80  train loss:  0.16711735725402832\n",
      "81  train loss:  0.166152685880661\n",
      "82  train loss:  0.16591759026050568\n",
      "83  train loss:  0.16416996717453003\n",
      "84  train loss:  0.16534733772277832\n",
      "85  train loss:  0.168330579996109\n",
      "86  train loss:  0.1656983494758606\n",
      "87  train loss:  0.16047227382659912\n",
      "88  train loss:  0.16876575350761414\n",
      "89  train loss:  0.1616469770669937\n",
      "90  train loss:  0.17302842438220978\n",
      "91  train loss:  0.16425397992134094\n",
      "92  train loss:  0.16673627495765686\n",
      "93  train loss:  0.17113205790519714\n",
      "94  train loss:  0.16573019325733185\n",
      "95  train loss:  0.1674693077802658\n",
      "96  train loss:  0.1646651178598404\n",
      "97  train loss:  0.15915805101394653\n",
      "98  train loss:  0.15804579854011536\n",
      "99  train loss:  0.15644370019435883\n",
      "test acc (%):  tensor(77.2540)\n",
      "0  train loss:  0.6056464314460754\n",
      "1  train loss:  0.5275279879570007\n",
      "2  train loss:  0.49662888050079346\n",
      "3  train loss:  0.4513078033924103\n",
      "4  train loss:  0.41283485293388367\n",
      "5  train loss:  0.40646693110466003\n",
      "6  train loss:  0.3932856619358063\n",
      "7  train loss:  0.3831518590450287\n",
      "8  train loss:  0.3694848120212555\n",
      "9  train loss:  0.3672904372215271\n",
      "10  train loss:  0.36067333817481995\n",
      "11  train loss:  0.3622591197490692\n",
      "12  train loss:  0.3518488109111786\n",
      "13  train loss:  0.35165244340896606\n",
      "14  train loss:  0.35836806893348694\n",
      "15  train loss:  0.35653793811798096\n",
      "16  train loss:  0.33096951246261597\n",
      "17  train loss:  0.32197895646095276\n",
      "18  train loss:  0.31770601868629456\n",
      "19  train loss:  0.31193122267723083\n",
      "20  train loss:  0.3147198557853699\n",
      "21  train loss:  0.3149910271167755\n",
      "22  train loss:  0.32528921961784363\n",
      "23  train loss:  0.30692407488822937\n",
      "24  train loss:  0.3066350221633911\n",
      "25  train loss:  0.3014873266220093\n",
      "26  train loss:  0.2999478876590729\n",
      "27  train loss:  0.29850995540618896\n",
      "28  train loss:  0.2891998887062073\n",
      "29  train loss:  0.29197075963020325\n",
      "30  train loss:  0.28211718797683716\n",
      "31  train loss:  0.27981165051460266\n",
      "32  train loss:  0.2779957056045532\n",
      "33  train loss:  0.2682543396949768\n",
      "34  train loss:  0.26323431730270386\n",
      "35  train loss:  0.2637217938899994\n",
      "36  train loss:  0.2632521390914917\n",
      "37  train loss:  0.2600265443325043\n",
      "38  train loss:  0.25548890233039856\n",
      "39  train loss:  0.25430047512054443\n",
      "40  train loss:  0.2496633231639862\n",
      "41  train loss:  0.24547752737998962\n",
      "42  train loss:  0.2452610284090042\n",
      "43  train loss:  0.2393759936094284\n",
      "44  train loss:  0.24047663807868958\n",
      "45  train loss:  0.23550574481487274\n",
      "46  train loss:  0.23525011539459229\n",
      "47  train loss:  0.23256464302539825\n",
      "48  train loss:  0.22950325906276703\n",
      "49  train loss:  0.22745850682258606\n",
      "50  train loss:  0.22601917386054993\n",
      "51  train loss:  0.22430670261383057\n",
      "52  train loss:  0.22162382304668427\n",
      "53  train loss:  0.2196984887123108\n",
      "54  train loss:  0.21842674911022186\n",
      "55  train loss:  0.2166229635477066\n",
      "56  train loss:  0.21559378504753113\n",
      "57  train loss:  0.21395911276340485\n",
      "58  train loss:  0.21230435371398926\n",
      "59  train loss:  0.21123813092708588\n",
      "60  train loss:  0.2101469337940216\n",
      "61  train loss:  0.20890723168849945\n",
      "62  train loss:  0.20797741413116455\n",
      "63  train loss:  0.2067127525806427\n",
      "64  train loss:  0.20563054084777832\n",
      "65  train loss:  0.20430205762386322\n",
      "66  train loss:  0.2028885781764984\n",
      "67  train loss:  0.20285248756408691\n",
      "68  train loss:  0.20231080055236816\n",
      "69  train loss:  0.20232287049293518\n",
      "70  train loss:  0.20136378705501556\n",
      "71  train loss:  0.19927041232585907\n",
      "72  train loss:  0.1985972374677658\n",
      "73  train loss:  0.19827666878700256\n",
      "74  train loss:  0.19749680161476135\n",
      "75  train loss:  0.1986403614282608\n",
      "76  train loss:  0.19602647423744202\n",
      "77  train loss:  0.19799602031707764\n",
      "78  train loss:  0.19540143013000488\n",
      "79  train loss:  0.20024631917476654\n",
      "80  train loss:  0.19732558727264404\n",
      "81  train loss:  0.19261173903942108\n",
      "82  train loss:  0.20032796263694763\n",
      "83  train loss:  0.19344960153102875\n",
      "84  train loss:  0.19810311496257782\n",
      "85  train loss:  0.19534099102020264\n",
      "86  train loss:  0.19529037177562714\n",
      "87  train loss:  0.19145885109901428\n",
      "88  train loss:  0.19735336303710938\n",
      "89  train loss:  0.19083407521247864\n",
      "90  train loss:  0.19593550264835358\n",
      "91  train loss:  0.19116052985191345\n",
      "92  train loss:  0.19042019546031952\n",
      "93  train loss:  0.18931356072425842\n",
      "94  train loss:  0.1928119659423828\n",
      "95  train loss:  0.1883641928434372\n",
      "96  train loss:  0.18766967952251434\n",
      "97  train loss:  0.1882755011320114\n",
      "98  train loss:  0.18779203295707703\n",
      "99  train loss:  0.18677252531051636\n",
      "test acc (%):  tensor(77.6651)\n",
      "0  train loss:  0.6689680218696594\n",
      "1  train loss:  0.5530670285224915\n",
      "2  train loss:  0.4633828401565552\n",
      "3  train loss:  0.4192030131816864\n",
      "4  train loss:  0.3958819508552551\n",
      "5  train loss:  0.3721821904182434\n",
      "6  train loss:  0.3685239553451538\n",
      "7  train loss:  0.36060991883277893\n",
      "8  train loss:  0.3527977764606476\n",
      "9  train loss:  0.35653531551361084\n",
      "10  train loss:  0.34382882714271545\n",
      "11  train loss:  0.3442668318748474\n",
      "12  train loss:  0.3452727496623993\n",
      "13  train loss:  0.34005144238471985\n",
      "14  train loss:  0.33305031061172485\n",
      "15  train loss:  0.32562851905822754\n",
      "16  train loss:  0.32514822483062744\n",
      "17  train loss:  0.32002681493759155\n",
      "18  train loss:  0.3117343485355377\n",
      "19  train loss:  0.30875372886657715\n",
      "20  train loss:  0.30790361762046814\n",
      "21  train loss:  0.306261271238327\n",
      "22  train loss:  0.3009796142578125\n",
      "23  train loss:  0.2977234423160553\n",
      "24  train loss:  0.2938724160194397\n",
      "25  train loss:  0.2885592579841614\n",
      "26  train loss:  0.28775039315223694\n",
      "27  train loss:  0.2815244197845459\n",
      "28  train loss:  0.28230273723602295\n",
      "29  train loss:  0.28001153469085693\n",
      "30  train loss:  0.2763524055480957\n",
      "31  train loss:  0.27375078201293945\n",
      "32  train loss:  0.27159637212753296\n",
      "33  train loss:  0.26947057247161865\n",
      "34  train loss:  0.2663753926753998\n",
      "35  train loss:  0.264856219291687\n",
      "36  train loss:  0.262436181306839\n",
      "37  train loss:  0.2601563632488251\n",
      "38  train loss:  0.25835976004600525\n",
      "39  train loss:  0.2570272982120514\n",
      "40  train loss:  0.2550106346607208\n",
      "41  train loss:  0.2543826103210449\n",
      "42  train loss:  0.25342705845832825\n",
      "43  train loss:  0.2507627308368683\n",
      "44  train loss:  0.25069180130958557\n",
      "45  train loss:  0.25188639760017395\n",
      "46  train loss:  0.24849078059196472\n",
      "47  train loss:  0.2504459023475647\n",
      "48  train loss:  0.24658723175525665\n",
      "49  train loss:  0.2469535917043686\n",
      "50  train loss:  0.24496038258075714\n",
      "51  train loss:  0.2459496408700943\n",
      "52  train loss:  0.243583545088768\n",
      "53  train loss:  0.24503065645694733\n",
      "54  train loss:  0.24109035730361938\n",
      "55  train loss:  0.24254265427589417\n",
      "56  train loss:  0.24434058368206024\n",
      "57  train loss:  0.2429439127445221\n",
      "58  train loss:  0.24637022614479065\n",
      "59  train loss:  0.24139945209026337\n",
      "60  train loss:  0.23944324254989624\n",
      "61  train loss:  0.2387879192829132\n",
      "62  train loss:  0.2378346025943756\n",
      "63  train loss:  0.23588746786117554\n",
      "64  train loss:  0.23525886237621307\n",
      "65  train loss:  0.23603589832782745\n",
      "66  train loss:  0.23494958877563477\n",
      "67  train loss:  0.23403288424015045\n",
      "68  train loss:  0.23638232052326202\n",
      "69  train loss:  0.23848342895507812\n",
      "70  train loss:  0.23155340552330017\n",
      "71  train loss:  0.23192721605300903\n",
      "72  train loss:  0.22883450984954834\n",
      "73  train loss:  0.23111800849437714\n",
      "74  train loss:  0.22956837713718414\n",
      "75  train loss:  0.2309073656797409\n",
      "76  train loss:  0.2358999401330948\n",
      "77  train loss:  0.22931040823459625\n",
      "78  train loss:  0.25186705589294434\n",
      "79  train loss:  0.23375314474105835\n",
      "80  train loss:  0.23904524743556976\n",
      "81  train loss:  0.24199698865413666\n",
      "82  train loss:  0.23300819098949432\n",
      "83  train loss:  0.2283787578344345\n",
      "84  train loss:  0.2320346087217331\n",
      "85  train loss:  0.2324366718530655\n",
      "86  train loss:  0.22847598791122437\n",
      "87  train loss:  0.22921627759933472\n",
      "88  train loss:  0.22683154046535492\n",
      "89  train loss:  0.23891817033290863\n",
      "90  train loss:  0.23782064020633698\n",
      "91  train loss:  0.25705385208129883\n",
      "92  train loss:  0.23005709052085876\n",
      "93  train loss:  0.26275116205215454\n",
      "94  train loss:  0.22925132513046265\n",
      "95  train loss:  0.24070625007152557\n",
      "96  train loss:  0.24159766733646393\n",
      "97  train loss:  0.22557510435581207\n",
      "98  train loss:  0.24726493656635284\n",
      "99  train loss:  0.22609783709049225\n",
      "test acc (%):  tensor(77.5829)\n",
      "0  train loss:  0.47852933406829834\n",
      "1  train loss:  0.44373568892478943\n",
      "2  train loss:  0.41872718930244446\n",
      "3  train loss:  0.3984000086784363\n",
      "4  train loss:  0.37769317626953125\n",
      "5  train loss:  0.37509509921073914\n",
      "6  train loss:  0.36744728684425354\n",
      "7  train loss:  0.3525597155094147\n",
      "8  train loss:  0.3400046229362488\n",
      "9  train loss:  0.3316805064678192\n",
      "10  train loss:  0.32093381881713867\n",
      "11  train loss:  0.31096944212913513\n",
      "12  train loss:  0.3077322542667389\n",
      "13  train loss:  0.3103761076927185\n",
      "14  train loss:  0.2968161106109619\n",
      "15  train loss:  0.3103315532207489\n",
      "16  train loss:  0.29030609130859375\n",
      "17  train loss:  0.28707391023635864\n",
      "18  train loss:  0.282841295003891\n",
      "19  train loss:  0.2788606584072113\n",
      "20  train loss:  0.27013540267944336\n",
      "21  train loss:  0.2713572382926941\n",
      "22  train loss:  0.2686702609062195\n",
      "23  train loss:  0.2647522985935211\n",
      "24  train loss:  0.2639022469520569\n",
      "25  train loss:  0.26060062646865845\n",
      "26  train loss:  0.2577439546585083\n",
      "27  train loss:  0.2543078064918518\n",
      "28  train loss:  0.25359800457954407\n",
      "29  train loss:  0.24907515943050385\n",
      "30  train loss:  0.2493731677532196\n",
      "31  train loss:  0.24694888293743134\n",
      "32  train loss:  0.24339808523654938\n",
      "33  train loss:  0.24084177613258362\n",
      "34  train loss:  0.23898044228553772\n",
      "35  train loss:  0.23653651773929596\n",
      "36  train loss:  0.23406971991062164\n",
      "37  train loss:  0.23198990523815155\n",
      "38  train loss:  0.23093262314796448\n",
      "39  train loss:  0.23121382296085358\n",
      "40  train loss:  0.22816474735736847\n",
      "41  train loss:  0.22681672871112823\n",
      "42  train loss:  0.22600041329860687\n",
      "43  train loss:  0.22294244170188904\n",
      "44  train loss:  0.22156685590744019\n",
      "45  train loss:  0.2199065238237381\n",
      "46  train loss:  0.2184886336326599\n",
      "47  train loss:  0.2182692140340805\n",
      "48  train loss:  0.21627172827720642\n",
      "49  train loss:  0.2150704711675644\n",
      "50  train loss:  0.21398137509822845\n",
      "51  train loss:  0.2131529003381729\n",
      "52  train loss:  0.21238669753074646\n",
      "53  train loss:  0.2115386724472046\n",
      "54  train loss:  0.21047113835811615\n",
      "55  train loss:  0.20914198458194733\n",
      "56  train loss:  0.20809561014175415\n",
      "57  train loss:  0.20719857513904572\n",
      "58  train loss:  0.20679546892642975\n",
      "59  train loss:  0.20607125759124756\n",
      "60  train loss:  0.20520617067813873\n",
      "61  train loss:  0.2044409066438675\n",
      "62  train loss:  0.20377077162265778\n",
      "63  train loss:  0.2032475769519806\n",
      "64  train loss:  0.2026088386774063\n",
      "65  train loss:  0.2017415314912796\n",
      "66  train loss:  0.201063334941864\n",
      "67  train loss:  0.20052501559257507\n",
      "68  train loss:  0.20008021593093872\n",
      "69  train loss:  0.19900287687778473\n",
      "70  train loss:  0.19893573224544525\n",
      "71  train loss:  0.19785098731517792\n",
      "72  train loss:  0.1971084028482437\n",
      "73  train loss:  0.19694551825523376\n",
      "74  train loss:  0.19676998257637024\n",
      "75  train loss:  0.19543685019016266\n",
      "76  train loss:  0.19526392221450806\n",
      "77  train loss:  0.19430863857269287\n",
      "78  train loss:  0.19384776055812836\n",
      "79  train loss:  0.19339688122272491\n",
      "80  train loss:  0.1922982633113861\n",
      "81  train loss:  0.19201478362083435\n",
      "82  train loss:  0.1921410858631134\n",
      "83  train loss:  0.19113712012767792\n",
      "84  train loss:  0.19076018035411835\n",
      "85  train loss:  0.18999947607517242\n",
      "86  train loss:  0.18993844091892242\n",
      "87  train loss:  0.1893509477376938\n",
      "88  train loss:  0.18966063857078552\n",
      "89  train loss:  0.188088059425354\n",
      "90  train loss:  0.1885116696357727\n",
      "91  train loss:  0.18789711594581604\n",
      "92  train loss:  0.18780399858951569\n",
      "93  train loss:  0.18691033124923706\n",
      "94  train loss:  0.18577340245246887\n",
      "95  train loss:  0.18659867346286774\n",
      "96  train loss:  0.18565845489501953\n",
      "97  train loss:  0.18605881929397583\n",
      "98  train loss:  0.18565736711025238\n",
      "99  train loss:  0.18543972074985504\n",
      "test acc (%):  tensor(77.8569)\n",
      "0  train loss:  0.4352472722530365\n",
      "1  train loss:  0.4155983328819275\n",
      "2  train loss:  0.3878236711025238\n",
      "3  train loss:  0.36293306946754456\n",
      "4  train loss:  0.36831599473953247\n",
      "5  train loss:  0.35734251141548157\n",
      "6  train loss:  0.3418332636356354\n",
      "7  train loss:  0.32658177614212036\n",
      "8  train loss:  0.32634225487709045\n",
      "9  train loss:  0.3169918954372406\n",
      "10  train loss:  0.3253675103187561\n",
      "11  train loss:  0.30544140934944153\n",
      "12  train loss:  0.31513461470603943\n",
      "13  train loss:  0.31041431427001953\n",
      "14  train loss:  0.3083139657974243\n",
      "15  train loss:  0.3124687969684601\n",
      "16  train loss:  0.30996429920196533\n",
      "17  train loss:  0.31578636169433594\n",
      "18  train loss:  0.29927611351013184\n",
      "19  train loss:  0.29512691497802734\n",
      "20  train loss:  0.28574442863464355\n",
      "21  train loss:  0.2994484007358551\n",
      "22  train loss:  0.3266521990299225\n",
      "23  train loss:  0.28410106897354126\n",
      "24  train loss:  0.2792140543460846\n",
      "25  train loss:  0.2756926715373993\n",
      "26  train loss:  0.26888349652290344\n",
      "27  train loss:  0.26675131916999817\n",
      "28  train loss:  0.2727753221988678\n",
      "29  train loss:  0.26514732837677\n",
      "30  train loss:  0.254957914352417\n",
      "31  train loss:  0.2521226704120636\n",
      "32  train loss:  0.2530253529548645\n",
      "33  train loss:  0.2509862184524536\n",
      "34  train loss:  0.2496458739042282\n",
      "35  train loss:  0.24587805569171906\n",
      "36  train loss:  0.24388407170772552\n",
      "37  train loss:  0.24049030244350433\n",
      "38  train loss:  0.23817433416843414\n",
      "39  train loss:  0.23613697290420532\n",
      "40  train loss:  0.2361324578523636\n",
      "41  train loss:  0.23356838524341583\n",
      "42  train loss:  0.2313697636127472\n",
      "43  train loss:  0.23050658404827118\n",
      "44  train loss:  0.22934256494045258\n",
      "45  train loss:  0.22770251333713531\n",
      "46  train loss:  0.22588689625263214\n",
      "47  train loss:  0.22404402494430542\n",
      "48  train loss:  0.22262924909591675\n",
      "49  train loss:  0.2217111587524414\n",
      "50  train loss:  0.22276471555233002\n",
      "51  train loss:  0.22004760801792145\n",
      "52  train loss:  0.2195785492658615\n",
      "53  train loss:  0.21891452372074127\n",
      "54  train loss:  0.21744291484355927\n",
      "55  train loss:  0.2162005454301834\n",
      "56  train loss:  0.2176452875137329\n",
      "57  train loss:  0.2147551029920578\n",
      "58  train loss:  0.21390756964683533\n",
      "59  train loss:  0.21483486890792847\n",
      "60  train loss:  0.2139822244644165\n",
      "61  train loss:  0.21278198063373566\n",
      "62  train loss:  0.21166925132274628\n",
      "63  train loss:  0.20944741368293762\n",
      "64  train loss:  0.20879405736923218\n",
      "65  train loss:  0.20829901099205017\n",
      "66  train loss:  0.2072531133890152\n",
      "67  train loss:  0.2062995284795761\n",
      "68  train loss:  0.2056201845407486\n",
      "69  train loss:  0.20344878733158112\n",
      "70  train loss:  0.20292265713214874\n",
      "71  train loss:  0.20151983201503754\n",
      "72  train loss:  0.2021544873714447\n",
      "73  train loss:  0.20052790641784668\n",
      "74  train loss:  0.20099394023418427\n",
      "75  train loss:  0.19940431416034698\n",
      "76  train loss:  0.19982318580150604\n",
      "77  train loss:  0.19901110231876373\n",
      "78  train loss:  0.19824029505252838\n",
      "79  train loss:  0.19814351201057434\n",
      "80  train loss:  0.19695612788200378\n",
      "81  train loss:  0.19670216739177704\n",
      "82  train loss:  0.19562259316444397\n",
      "83  train loss:  0.19549761712551117\n",
      "84  train loss:  0.19480037689208984\n",
      "85  train loss:  0.19423341751098633\n",
      "86  train loss:  0.19342154264450073\n",
      "87  train loss:  0.193141371011734\n",
      "88  train loss:  0.19206708669662476\n",
      "89  train loss:  0.19089743494987488\n",
      "90  train loss:  0.1900084763765335\n",
      "91  train loss:  0.18922263383865356\n",
      "92  train loss:  0.1888212114572525\n",
      "93  train loss:  0.18865658342838287\n",
      "94  train loss:  0.1880115419626236\n",
      "95  train loss:  0.1884038746356964\n",
      "96  train loss:  0.18904989957809448\n",
      "97  train loss:  0.1866140514612198\n",
      "98  train loss:  0.18799015879631042\n",
      "99  train loss:  0.18817315995693207\n",
      "test acc (%):  tensor(77.7747)\n",
      "0  train loss:  0.496487557888031\n",
      "1  train loss:  0.46376627683639526\n",
      "2  train loss:  0.4318382143974304\n",
      "3  train loss:  0.41372814774513245\n",
      "4  train loss:  0.387179970741272\n",
      "5  train loss:  0.3735344111919403\n",
      "6  train loss:  0.3662114143371582\n",
      "7  train loss:  0.3559683561325073\n",
      "8  train loss:  0.35854023694992065\n",
      "9  train loss:  0.33569955825805664\n",
      "10  train loss:  0.3319517970085144\n",
      "11  train loss:  0.3226366341114044\n",
      "12  train loss:  0.3170984089374542\n",
      "13  train loss:  0.3160571753978729\n",
      "14  train loss:  0.3056461811065674\n",
      "15  train loss:  0.3045598864555359\n",
      "16  train loss:  0.31913140416145325\n",
      "17  train loss:  0.30117419362068176\n",
      "18  train loss:  0.32237708568573\n",
      "19  train loss:  0.2940565347671509\n",
      "20  train loss:  0.3138272762298584\n",
      "21  train loss:  0.29560840129852295\n",
      "22  train loss:  0.3003312647342682\n",
      "23  train loss:  0.29614371061325073\n",
      "24  train loss:  0.2879880964756012\n",
      "25  train loss:  0.300931841135025\n",
      "26  train loss:  0.2775494456291199\n",
      "27  train loss:  0.286285936832428\n",
      "28  train loss:  0.2816552221775055\n",
      "29  train loss:  0.2865610718727112\n",
      "30  train loss:  0.27652937173843384\n",
      "31  train loss:  0.2672496438026428\n",
      "32  train loss:  0.2727013826370239\n",
      "33  train loss:  0.26788967847824097\n",
      "34  train loss:  0.2719113230705261\n",
      "35  train loss:  0.2645181715488434\n",
      "36  train loss:  0.29211685061454773\n",
      "37  train loss:  0.26881006360054016\n",
      "38  train loss:  0.27795007824897766\n",
      "39  train loss:  0.28247973322868347\n",
      "40  train loss:  0.2997053563594818\n",
      "41  train loss:  0.27928149700164795\n",
      "42  train loss:  0.2710115313529968\n",
      "43  train loss:  0.27187579870224\n",
      "44  train loss:  0.2671895921230316\n",
      "45  train loss:  0.26209285855293274\n",
      "46  train loss:  0.2658320367336273\n",
      "47  train loss:  0.25857365131378174\n",
      "48  train loss:  0.25869420170783997\n",
      "49  train loss:  0.2559080421924591\n",
      "50  train loss:  0.25391295552253723\n",
      "51  train loss:  0.2508949935436249\n",
      "52  train loss:  0.24847736954689026\n",
      "53  train loss:  0.24444322288036346\n",
      "54  train loss:  0.24198691546916962\n",
      "55  train loss:  0.23978030681610107\n",
      "56  train loss:  0.23893381655216217\n",
      "57  train loss:  0.2354363203048706\n",
      "58  train loss:  0.23502451181411743\n",
      "59  train loss:  0.23643873631954193\n",
      "60  train loss:  0.2318933755159378\n",
      "61  train loss:  0.233506977558136\n",
      "62  train loss:  0.2304123491048813\n",
      "63  train loss:  0.2303917407989502\n",
      "64  train loss:  0.22857774794101715\n",
      "65  train loss:  0.22683106362819672\n",
      "66  train loss:  0.22752197086811066\n",
      "67  train loss:  0.2254994958639145\n",
      "68  train loss:  0.22526168823242188\n",
      "69  train loss:  0.2229539304971695\n",
      "70  train loss:  0.2244974970817566\n",
      "71  train loss:  0.22170577943325043\n",
      "72  train loss:  0.2207343578338623\n",
      "73  train loss:  0.22099529206752777\n",
      "74  train loss:  0.21919241547584534\n",
      "75  train loss:  0.2184293419122696\n",
      "76  train loss:  0.21715539693832397\n",
      "77  train loss:  0.21653440594673157\n",
      "78  train loss:  0.21493524312973022\n",
      "79  train loss:  0.21547526121139526\n",
      "80  train loss:  0.21715131402015686\n",
      "81  train loss:  0.2147306352853775\n",
      "82  train loss:  0.21769385039806366\n",
      "83  train loss:  0.21762004494667053\n",
      "84  train loss:  0.2299979031085968\n",
      "85  train loss:  0.21894556283950806\n",
      "86  train loss:  0.22146262228488922\n",
      "87  train loss:  0.22139374911785126\n",
      "88  train loss:  0.23385949432849884\n",
      "89  train loss:  0.21928146481513977\n",
      "90  train loss:  0.2126747965812683\n",
      "91  train loss:  0.22305473685264587\n",
      "92  train loss:  0.21109539270401\n",
      "93  train loss:  0.21401138603687286\n",
      "94  train loss:  0.21736480295658112\n",
      "95  train loss:  0.20894837379455566\n",
      "96  train loss:  0.21442794799804688\n",
      "97  train loss:  0.20662984251976013\n",
      "98  train loss:  0.20669518411159515\n",
      "99  train loss:  0.2054278552532196\n",
      "test acc (%):  tensor(76.6785)\n",
      "0  train loss:  0.5618070960044861\n",
      "1  train loss:  0.48083698749542236\n",
      "2  train loss:  0.4850342869758606\n",
      "3  train loss:  0.4409301280975342\n",
      "4  train loss:  0.40654024481773376\n",
      "5  train loss:  0.38910454511642456\n",
      "6  train loss:  0.36894476413726807\n",
      "7  train loss:  0.3718833923339844\n",
      "8  train loss:  0.36251363158226013\n",
      "9  train loss:  0.3503212034702301\n",
      "10  train loss:  0.35073933005332947\n",
      "11  train loss:  0.33916082978248596\n",
      "12  train loss:  0.32978272438049316\n",
      "13  train loss:  0.3182515799999237\n",
      "14  train loss:  0.30996111035346985\n",
      "15  train loss:  0.3046080768108368\n",
      "16  train loss:  0.30037158727645874\n",
      "17  train loss:  0.29351910948753357\n",
      "18  train loss:  0.29052186012268066\n",
      "19  train loss:  0.2903538644313812\n",
      "20  train loss:  0.2865218222141266\n",
      "21  train loss:  0.2829083800315857\n",
      "22  train loss:  0.2782568633556366\n",
      "23  train loss:  0.27309510111808777\n",
      "24  train loss:  0.27298876643180847\n",
      "25  train loss:  0.2697362005710602\n",
      "26  train loss:  0.2657550573348999\n",
      "27  train loss:  0.2620171010494232\n",
      "28  train loss:  0.2621137499809265\n",
      "29  train loss:  0.2570161819458008\n",
      "30  train loss:  0.25477588176727295\n",
      "31  train loss:  0.2542670965194702\n",
      "32  train loss:  0.2495747208595276\n",
      "33  train loss:  0.24742770195007324\n",
      "34  train loss:  0.24507026374340057\n",
      "35  train loss:  0.24243462085723877\n",
      "36  train loss:  0.24257993698120117\n",
      "37  train loss:  0.24158522486686707\n",
      "38  train loss:  0.23948092758655548\n",
      "39  train loss:  0.23879696428775787\n",
      "40  train loss:  0.23501704633235931\n",
      "41  train loss:  0.23359663784503937\n",
      "42  train loss:  0.23209013044834137\n",
      "43  train loss:  0.22905127704143524\n",
      "44  train loss:  0.22790294885635376\n",
      "45  train loss:  0.22590892016887665\n",
      "46  train loss:  0.2243361622095108\n",
      "47  train loss:  0.2228071242570877\n",
      "48  train loss:  0.22182892262935638\n",
      "49  train loss:  0.22074253857135773\n",
      "50  train loss:  0.22184909880161285\n",
      "51  train loss:  0.21847662329673767\n",
      "52  train loss:  0.21703723073005676\n",
      "53  train loss:  0.21560698747634888\n",
      "54  train loss:  0.21507525444030762\n",
      "55  train loss:  0.2139444351196289\n",
      "56  train loss:  0.21266305446624756\n",
      "57  train loss:  0.21145962178707123\n",
      "58  train loss:  0.2113800346851349\n",
      "59  train loss:  0.20973283052444458\n",
      "60  train loss:  0.20930270850658417\n",
      "61  train loss:  0.2084484100341797\n",
      "62  train loss:  0.20724883675575256\n",
      "63  train loss:  0.2066873013973236\n",
      "64  train loss:  0.20595747232437134\n",
      "65  train loss:  0.20482273399829865\n",
      "66  train loss:  0.20475701987743378\n",
      "67  train loss:  0.20315036177635193\n",
      "68  train loss:  0.20261934399604797\n",
      "69  train loss:  0.20159129798412323\n",
      "70  train loss:  0.2028733491897583\n",
      "71  train loss:  0.20340624451637268\n",
      "72  train loss:  0.1994377225637436\n",
      "73  train loss:  0.19977279007434845\n",
      "74  train loss:  0.20195263624191284\n",
      "75  train loss:  0.19785936176776886\n",
      "76  train loss:  0.19674518704414368\n",
      "77  train loss:  0.1981036514043808\n",
      "78  train loss:  0.19743254780769348\n",
      "79  train loss:  0.1957457959651947\n",
      "80  train loss:  0.19536668062210083\n",
      "81  train loss:  0.19410036504268646\n",
      "82  train loss:  0.19427736103534698\n",
      "83  train loss:  0.1927519589662552\n",
      "84  train loss:  0.1925196498632431\n",
      "85  train loss:  0.19214074313640594\n",
      "86  train loss:  0.19262699782848358\n",
      "87  train loss:  0.19176480174064636\n",
      "88  train loss:  0.19181588292121887\n",
      "89  train loss:  0.19097553193569183\n",
      "90  train loss:  0.18908679485321045\n",
      "91  train loss:  0.18853522837162018\n",
      "92  train loss:  0.18899090588092804\n",
      "93  train loss:  0.18731281161308289\n",
      "94  train loss:  0.1863502860069275\n",
      "95  train loss:  0.18603792786598206\n",
      "96  train loss:  0.18564334511756897\n",
      "97  train loss:  0.18493008613586426\n",
      "98  train loss:  0.18478161096572876\n",
      "99  train loss:  0.18380220234394073\n",
      "test acc (%):  tensor(78.6243)\n",
      "0  train loss:  0.4629921019077301\n",
      "1  train loss:  0.427592009305954\n",
      "2  train loss:  0.3906458914279938\n",
      "3  train loss:  0.3697272837162018\n",
      "4  train loss:  0.3571237623691559\n",
      "5  train loss:  0.34712734818458557\n",
      "6  train loss:  0.33343130350112915\n",
      "7  train loss:  0.31850120425224304\n",
      "8  train loss:  0.31631192564964294\n",
      "9  train loss:  0.32040780782699585\n",
      "10  train loss:  0.3069399893283844\n",
      "11  train loss:  0.30584731698036194\n",
      "12  train loss:  0.3013668954372406\n",
      "13  train loss:  0.29442864656448364\n",
      "14  train loss:  0.28902339935302734\n",
      "15  train loss:  0.2879985570907593\n",
      "16  train loss:  0.28897619247436523\n",
      "17  train loss:  0.2857269048690796\n",
      "18  train loss:  0.28516310453414917\n",
      "19  train loss:  0.2814209461212158\n",
      "20  train loss:  0.2823874056339264\n",
      "21  train loss:  0.277436226606369\n",
      "22  train loss:  0.2726939022541046\n",
      "23  train loss:  0.26945456862449646\n",
      "24  train loss:  0.2690480649471283\n",
      "25  train loss:  0.26373863220214844\n",
      "26  train loss:  0.25994235277175903\n",
      "27  train loss:  0.25572681427001953\n",
      "28  train loss:  0.2540637254714966\n",
      "29  train loss:  0.2535325288772583\n",
      "30  train loss:  0.24965469539165497\n",
      "31  train loss:  0.2459072321653366\n",
      "32  train loss:  0.2477501481771469\n",
      "33  train loss:  0.24653786420822144\n",
      "34  train loss:  0.24485906958580017\n",
      "35  train loss:  0.24881871044635773\n",
      "36  train loss:  0.24275542795658112\n",
      "37  train loss:  0.2507726550102234\n",
      "38  train loss:  0.24368977546691895\n",
      "39  train loss:  0.2483404576778412\n",
      "40  train loss:  0.2397194653749466\n",
      "41  train loss:  0.24423418939113617\n",
      "42  train loss:  0.23494493961334229\n",
      "43  train loss:  0.23511937260627747\n",
      "44  train loss:  0.2343074083328247\n",
      "45  train loss:  0.2307058870792389\n",
      "46  train loss:  0.23544809222221375\n",
      "47  train loss:  0.232319176197052\n",
      "48  train loss:  0.2304002195596695\n",
      "49  train loss:  0.2286996841430664\n",
      "50  train loss:  0.22476698458194733\n",
      "51  train loss:  0.22285790741443634\n",
      "52  train loss:  0.22233840823173523\n",
      "53  train loss:  0.21826954185962677\n",
      "54  train loss:  0.21947695314884186\n",
      "55  train loss:  0.21658627688884735\n",
      "56  train loss:  0.21611353754997253\n",
      "57  train loss:  0.21374402940273285\n",
      "58  train loss:  0.21085116267204285\n",
      "59  train loss:  0.20930343866348267\n",
      "60  train loss:  0.2091493457555771\n",
      "61  train loss:  0.20596925914287567\n",
      "62  train loss:  0.20441102981567383\n",
      "63  train loss:  0.20387184619903564\n",
      "64  train loss:  0.20234261453151703\n",
      "65  train loss:  0.20041418075561523\n",
      "66  train loss:  0.19945548474788666\n",
      "67  train loss:  0.19777563214302063\n",
      "68  train loss:  0.19607385993003845\n",
      "69  train loss:  0.19432908296585083\n",
      "70  train loss:  0.19371896982192993\n",
      "71  train loss:  0.19184565544128418\n",
      "72  train loss:  0.19079801440238953\n",
      "73  train loss:  0.1901467740535736\n",
      "74  train loss:  0.1891573667526245\n",
      "75  train loss:  0.18762218952178955\n",
      "76  train loss:  0.18663130700588226\n",
      "77  train loss:  0.18605905771255493\n",
      "78  train loss:  0.18464280664920807\n",
      "79  train loss:  0.18448087573051453\n",
      "80  train loss:  0.18369482457637787\n",
      "81  train loss:  0.18277348577976227\n",
      "82  train loss:  0.18182417750358582\n",
      "83  train loss:  0.18141062557697296\n",
      "84  train loss:  0.18026722967624664\n",
      "85  train loss:  0.17942355573177338\n",
      "86  train loss:  0.1789092868566513\n",
      "87  train loss:  0.178117573261261\n",
      "88  train loss:  0.17723596096038818\n",
      "89  train loss:  0.1794515997171402\n",
      "90  train loss:  0.17711664736270905\n",
      "91  train loss:  0.17720834910869598\n",
      "92  train loss:  0.1755039393901825\n",
      "93  train loss:  0.1754639744758606\n",
      "94  train loss:  0.17511098086833954\n",
      "95  train loss:  0.1732880026102066\n",
      "96  train loss:  0.17347334325313568\n",
      "97  train loss:  0.17378252744674683\n",
      "98  train loss:  0.1721409559249878\n",
      "99  train loss:  0.1710992455482483\n",
      "test acc (%):  tensor(78.5421)\n",
      "0  train loss:  0.5142166018486023\n",
      "1  train loss:  0.48778843879699707\n",
      "2  train loss:  0.4658674895763397\n",
      "3  train loss:  0.4218352735042572\n",
      "4  train loss:  0.39725440740585327\n",
      "5  train loss:  0.3794812560081482\n",
      "6  train loss:  0.36155185103416443\n",
      "7  train loss:  0.3586941659450531\n",
      "8  train loss:  0.3384465277194977\n",
      "9  train loss:  0.328201025724411\n",
      "10  train loss:  0.3214813768863678\n",
      "11  train loss:  0.3335493505001068\n",
      "12  train loss:  0.31992557644844055\n",
      "13  train loss:  0.30435875058174133\n",
      "14  train loss:  0.31435659527778625\n",
      "15  train loss:  0.32841742038726807\n",
      "16  train loss:  0.3026333451271057\n",
      "17  train loss:  0.3040902018547058\n",
      "18  train loss:  0.2971595525741577\n",
      "19  train loss:  0.301160603761673\n",
      "20  train loss:  0.2964138984680176\n",
      "21  train loss:  0.28431716561317444\n",
      "22  train loss:  0.2832140028476715\n",
      "23  train loss:  0.2816546857357025\n",
      "24  train loss:  0.2776797115802765\n",
      "25  train loss:  0.27756425738334656\n",
      "26  train loss:  0.27337902784347534\n",
      "27  train loss:  0.2665866017341614\n",
      "28  train loss:  0.2644156813621521\n",
      "29  train loss:  0.27071914076805115\n",
      "30  train loss:  0.25737282633781433\n",
      "31  train loss:  0.2553832530975342\n",
      "32  train loss:  0.25951510667800903\n",
      "33  train loss:  0.26794737577438354\n",
      "34  train loss:  0.2632688879966736\n",
      "35  train loss:  0.2541927397251129\n",
      "36  train loss:  0.25366002321243286\n",
      "37  train loss:  0.26491886377334595\n",
      "38  train loss:  0.24242331087589264\n",
      "39  train loss:  0.258329302072525\n",
      "40  train loss:  0.24635376036167145\n",
      "41  train loss:  0.25522756576538086\n",
      "42  train loss:  0.24705396592617035\n",
      "43  train loss:  0.2415369302034378\n",
      "44  train loss:  0.23703418672084808\n",
      "45  train loss:  0.2447086125612259\n",
      "46  train loss:  0.23493434488773346\n",
      "47  train loss:  0.22970296442508698\n",
      "48  train loss:  0.23183709383010864\n",
      "49  train loss:  0.2321896255016327\n",
      "50  train loss:  0.2292395532131195\n",
      "51  train loss:  0.22660104930400848\n",
      "52  train loss:  0.22296924889087677\n",
      "53  train loss:  0.22666707634925842\n",
      "54  train loss:  0.2281360626220703\n",
      "55  train loss:  0.22147414088249207\n",
      "56  train loss:  0.22720485925674438\n",
      "57  train loss:  0.21782749891281128\n",
      "58  train loss:  0.22336821258068085\n",
      "59  train loss:  0.21696646511554718\n",
      "60  train loss:  0.21873903274536133\n",
      "61  train loss:  0.21500764787197113\n",
      "62  train loss:  0.21445131301879883\n",
      "63  train loss:  0.21188776195049286\n",
      "64  train loss:  0.21181941032409668\n",
      "65  train loss:  0.20954036712646484\n",
      "66  train loss:  0.20791801810264587\n",
      "67  train loss:  0.2081122249364853\n",
      "68  train loss:  0.20621903240680695\n",
      "69  train loss:  0.20384715497493744\n",
      "70  train loss:  0.20344360172748566\n",
      "71  train loss:  0.2038770467042923\n",
      "72  train loss:  0.2019236981868744\n",
      "73  train loss:  0.20022118091583252\n",
      "74  train loss:  0.1985311508178711\n",
      "75  train loss:  0.1982276439666748\n",
      "76  train loss:  0.1962982565164566\n",
      "77  train loss:  0.1960117220878601\n",
      "78  train loss:  0.1949634701013565\n",
      "79  train loss:  0.19391736388206482\n",
      "80  train loss:  0.19393792748451233\n",
      "81  train loss:  0.19157512485980988\n",
      "82  train loss:  0.19298827648162842\n",
      "83  train loss:  0.1964939832687378\n",
      "84  train loss:  0.19801439344882965\n",
      "85  train loss:  0.18927544355392456\n",
      "86  train loss:  0.19065073132514954\n",
      "87  train loss:  0.18976937234401703\n",
      "88  train loss:  0.18951548635959625\n",
      "89  train loss:  0.1888115555047989\n",
      "90  train loss:  0.18890275061130524\n",
      "91  train loss:  0.18755470216274261\n",
      "92  train loss:  0.1867474913597107\n",
      "93  train loss:  0.1854371279478073\n",
      "94  train loss:  0.1846364438533783\n",
      "95  train loss:  0.18432895839214325\n",
      "96  train loss:  0.18254734575748444\n",
      "97  train loss:  0.18308931589126587\n",
      "98  train loss:  0.182745561003685\n",
      "99  train loss:  0.18176691234111786\n",
      "test acc (%):  tensor(78.7339)\n",
      "0  train loss:  0.453386515378952\n",
      "1  train loss:  0.4198743402957916\n",
      "2  train loss:  0.39140456914901733\n",
      "3  train loss:  0.373196005821228\n",
      "4  train loss:  0.38407978415489197\n",
      "5  train loss:  0.35797297954559326\n",
      "6  train loss:  0.3535751700401306\n",
      "7  train loss:  0.3306591808795929\n",
      "8  train loss:  0.32000434398651123\n",
      "9  train loss:  0.3257525861263275\n",
      "10  train loss:  0.30510982871055603\n",
      "11  train loss:  0.3018095791339874\n",
      "12  train loss:  0.29710817337036133\n",
      "13  train loss:  0.2898250222206116\n",
      "14  train loss:  0.2875368297100067\n",
      "15  train loss:  0.27918559312820435\n",
      "16  train loss:  0.2745577394962311\n",
      "17  train loss:  0.2732531726360321\n",
      "18  train loss:  0.2679894268512726\n",
      "19  train loss:  0.26806047558784485\n",
      "20  train loss:  0.2662316560745239\n",
      "21  train loss:  0.2589516341686249\n",
      "22  train loss:  0.2571132183074951\n",
      "23  train loss:  0.2582746148109436\n",
      "24  train loss:  0.2628081440925598\n",
      "25  train loss:  0.2543732821941376\n",
      "26  train loss:  0.2588929235935211\n",
      "27  train loss:  0.24922606348991394\n",
      "28  train loss:  0.24945490062236786\n",
      "29  train loss:  0.2451707124710083\n",
      "30  train loss:  0.24773290753364563\n",
      "31  train loss:  0.2422870397567749\n",
      "32  train loss:  0.252265602350235\n",
      "33  train loss:  0.24159224331378937\n",
      "34  train loss:  0.2594324052333832\n",
      "35  train loss:  0.23938843607902527\n",
      "36  train loss:  0.23842592537403107\n",
      "37  train loss:  0.2412022054195404\n",
      "38  train loss:  0.2355186939239502\n",
      "39  train loss:  0.22925201058387756\n",
      "40  train loss:  0.2286950647830963\n",
      "41  train loss:  0.2309243530035019\n",
      "42  train loss:  0.2268069088459015\n",
      "43  train loss:  0.23153731226921082\n",
      "44  train loss:  0.2222447395324707\n",
      "45  train loss:  0.2317836433649063\n",
      "46  train loss:  0.22787940502166748\n",
      "47  train loss:  0.22665826976299286\n",
      "48  train loss:  0.2195267379283905\n",
      "49  train loss:  0.22142992913722992\n",
      "50  train loss:  0.21833018958568573\n",
      "51  train loss:  0.2173723578453064\n",
      "52  train loss:  0.21267393231391907\n",
      "53  train loss:  0.21123071014881134\n",
      "54  train loss:  0.20950312912464142\n",
      "55  train loss:  0.21030162274837494\n",
      "56  train loss:  0.2087334841489792\n",
      "57  train loss:  0.20832300186157227\n",
      "58  train loss:  0.20961838960647583\n",
      "59  train loss:  0.2038063406944275\n",
      "60  train loss:  0.20496349036693573\n",
      "61  train loss:  0.2027888000011444\n",
      "62  train loss:  0.2020653933286667\n",
      "63  train loss:  0.2014128714799881\n",
      "64  train loss:  0.19952932000160217\n",
      "65  train loss:  0.1968853771686554\n",
      "66  train loss:  0.19773878157138824\n",
      "67  train loss:  0.1966511756181717\n",
      "68  train loss:  0.1940106302499771\n",
      "69  train loss:  0.19207626581192017\n",
      "70  train loss:  0.19214901328086853\n",
      "71  train loss:  0.19179165363311768\n",
      "72  train loss:  0.18901191651821136\n",
      "73  train loss:  0.18849577009677887\n",
      "74  train loss:  0.18762320280075073\n",
      "75  train loss:  0.1873815804719925\n",
      "76  train loss:  0.18575476109981537\n",
      "77  train loss:  0.1855129599571228\n",
      "78  train loss:  0.18476928770542145\n",
      "79  train loss:  0.18433944880962372\n",
      "80  train loss:  0.18391405045986176\n",
      "81  train loss:  0.1824144572019577\n",
      "82  train loss:  0.18178200721740723\n",
      "83  train loss:  0.1805616170167923\n",
      "84  train loss:  0.18028928339481354\n",
      "85  train loss:  0.17990221083164215\n",
      "86  train loss:  0.17919118702411652\n",
      "87  train loss:  0.18078866600990295\n",
      "88  train loss:  0.18959634006023407\n",
      "89  train loss:  0.1901707649230957\n",
      "90  train loss:  0.18126165866851807\n",
      "91  train loss:  0.1893024742603302\n",
      "92  train loss:  0.17995581030845642\n",
      "93  train loss:  0.1981803923845291\n",
      "94  train loss:  0.19576109945774078\n",
      "95  train loss:  0.18101748824119568\n",
      "96  train loss:  0.20305228233337402\n",
      "97  train loss:  0.1976262927055359\n",
      "98  train loss:  0.20658794045448303\n",
      "99  train loss:  0.19562144577503204\n",
      "test acc (%):  tensor(78.5969)\n",
      "0  train loss:  0.49913665652275085\n",
      "1  train loss:  0.48061612248420715\n",
      "2  train loss:  0.4296666085720062\n",
      "3  train loss:  0.4493009150028229\n",
      "4  train loss:  0.4388132393360138\n",
      "5  train loss:  0.4147602319717407\n",
      "6  train loss:  0.3940754234790802\n",
      "7  train loss:  0.36629125475883484\n",
      "8  train loss:  0.35019779205322266\n",
      "9  train loss:  0.34927064180374146\n",
      "10  train loss:  0.37909820675849915\n",
      "11  train loss:  0.3885757625102997\n",
      "12  train loss:  0.3671090006828308\n",
      "13  train loss:  0.36593684554100037\n",
      "14  train loss:  0.34977394342422485\n",
      "15  train loss:  0.34345051646232605\n",
      "16  train loss:  0.3353312015533447\n",
      "17  train loss:  0.33154821395874023\n",
      "18  train loss:  0.3205549418926239\n",
      "19  train loss:  0.3182051479816437\n",
      "20  train loss:  0.31671151518821716\n",
      "21  train loss:  0.31231415271759033\n",
      "22  train loss:  0.312327116727829\n",
      "23  train loss:  0.3046807646751404\n",
      "24  train loss:  0.29748016595840454\n",
      "25  train loss:  0.2978081703186035\n",
      "26  train loss:  0.30118027329444885\n",
      "27  train loss:  0.3071116805076599\n",
      "28  train loss:  0.29312363266944885\n",
      "29  train loss:  0.2918228507041931\n",
      "30  train loss:  0.29163071513175964\n",
      "31  train loss:  0.2885729670524597\n",
      "32  train loss:  0.27835601568222046\n",
      "33  train loss:  0.2791067361831665\n",
      "34  train loss:  0.291443407535553\n",
      "35  train loss:  0.2859850823879242\n",
      "36  train loss:  0.28659293055534363\n",
      "37  train loss:  0.27673983573913574\n",
      "38  train loss:  0.26965656876564026\n",
      "39  train loss:  0.2763402760028839\n",
      "40  train loss:  0.2632318139076233\n",
      "41  train loss:  0.26836109161376953\n",
      "42  train loss:  0.25620532035827637\n",
      "43  train loss:  0.25948700308799744\n",
      "44  train loss:  0.25172415375709534\n",
      "45  train loss:  0.24710659682750702\n",
      "46  train loss:  0.24906207621097565\n",
      "47  train loss:  0.2408107966184616\n",
      "48  train loss:  0.2417972981929779\n",
      "49  train loss:  0.23656532168388367\n",
      "50  train loss:  0.237950399518013\n",
      "51  train loss:  0.23506514728069305\n",
      "52  train loss:  0.23709270358085632\n",
      "53  train loss:  0.2348509281873703\n",
      "54  train loss:  0.22967371344566345\n",
      "55  train loss:  0.22661203145980835\n",
      "56  train loss:  0.22886373102664948\n",
      "57  train loss:  0.2257792353630066\n",
      "58  train loss:  0.22292587161064148\n",
      "59  train loss:  0.22542837262153625\n",
      "60  train loss:  0.22032611072063446\n",
      "61  train loss:  0.22417666018009186\n",
      "62  train loss:  0.2215462327003479\n",
      "63  train loss:  0.22164495289325714\n",
      "64  train loss:  0.21873506903648376\n",
      "65  train loss:  0.2195035219192505\n",
      "66  train loss:  0.216130331158638\n",
      "67  train loss:  0.21778029203414917\n",
      "68  train loss:  0.21429318189620972\n",
      "69  train loss:  0.21328264474868774\n",
      "70  train loss:  0.21187695860862732\n",
      "71  train loss:  0.21095839142799377\n",
      "72  train loss:  0.21030455827713013\n",
      "73  train loss:  0.20963217318058014\n",
      "74  train loss:  0.2102201133966446\n",
      "75  train loss:  0.20776380598545074\n",
      "76  train loss:  0.20700807869434357\n",
      "77  train loss:  0.20500344038009644\n",
      "78  train loss:  0.2066068947315216\n",
      "79  train loss:  0.20400133728981018\n",
      "80  train loss:  0.20280392467975616\n",
      "81  train loss:  0.20332825183868408\n",
      "82  train loss:  0.20215661823749542\n",
      "83  train loss:  0.20029056072235107\n",
      "84  train loss:  0.2007340043783188\n",
      "85  train loss:  0.1999424695968628\n",
      "86  train loss:  0.19920788705348969\n",
      "87  train loss:  0.20035140216350555\n",
      "88  train loss:  0.21102802455425262\n",
      "89  train loss:  0.24200350046157837\n",
      "90  train loss:  0.24631576240062714\n",
      "91  train loss:  0.23250791430473328\n",
      "92  train loss:  0.223093181848526\n",
      "93  train loss:  0.21269619464874268\n",
      "94  train loss:  0.2102031707763672\n",
      "95  train loss:  0.20635201036930084\n",
      "96  train loss:  0.20618858933448792\n",
      "97  train loss:  0.2060568481683731\n",
      "98  train loss:  0.20644395053386688\n",
      "99  train loss:  0.20151731371879578\n",
      "test acc (%):  tensor(78.2680)\n",
      "0  train loss:  0.5886736512184143\n",
      "1  train loss:  0.4648156762123108\n",
      "2  train loss:  0.45472684502601624\n",
      "3  train loss:  0.42487314343452454\n",
      "4  train loss:  0.4106188416481018\n",
      "5  train loss:  0.38508525490760803\n",
      "6  train loss:  0.36469700932502747\n",
      "7  train loss:  0.35698843002319336\n",
      "8  train loss:  0.34831392765045166\n",
      "9  train loss:  0.3249046504497528\n",
      "10  train loss:  0.3140123188495636\n",
      "11  train loss:  0.3054884076118469\n",
      "12  train loss:  0.2992238700389862\n",
      "13  train loss:  0.2971320152282715\n",
      "14  train loss:  0.287198007106781\n",
      "15  train loss:  0.2858790159225464\n",
      "16  train loss:  0.2808566987514496\n",
      "17  train loss:  0.2762852609157562\n",
      "18  train loss:  0.27506986260414124\n",
      "19  train loss:  0.27114811539649963\n",
      "20  train loss:  0.266401082277298\n",
      "21  train loss:  0.26767757534980774\n",
      "22  train loss:  0.2679215371608734\n",
      "23  train loss:  0.2637626528739929\n",
      "24  train loss:  0.25899121165275574\n",
      "25  train loss:  0.25926679372787476\n",
      "26  train loss:  0.25348836183547974\n",
      "27  train loss:  0.2513239085674286\n",
      "28  train loss:  0.25376278162002563\n",
      "29  train loss:  0.2505517899990082\n",
      "30  train loss:  0.2499435395002365\n",
      "31  train loss:  0.24914167821407318\n",
      "32  train loss:  0.2415907382965088\n",
      "33  train loss:  0.2403314709663391\n",
      "34  train loss:  0.2363186925649643\n",
      "35  train loss:  0.23420362174510956\n",
      "36  train loss:  0.2342216670513153\n",
      "37  train loss:  0.23496636748313904\n",
      "38  train loss:  0.23044413328170776\n",
      "39  train loss:  0.22935156524181366\n",
      "40  train loss:  0.23367664217948914\n",
      "41  train loss:  0.22914835810661316\n",
      "42  train loss:  0.22358711063861847\n",
      "43  train loss:  0.22822563350200653\n",
      "44  train loss:  0.227244034409523\n",
      "45  train loss:  0.22119586169719696\n",
      "46  train loss:  0.22395068407058716\n",
      "47  train loss:  0.2220546007156372\n",
      "48  train loss:  0.2170455902814865\n",
      "49  train loss:  0.21516114473342896\n",
      "50  train loss:  0.2191278636455536\n",
      "51  train loss:  0.21362778544425964\n",
      "52  train loss:  0.2094670981168747\n",
      "53  train loss:  0.2114943265914917\n",
      "54  train loss:  0.20793652534484863\n",
      "55  train loss:  0.20502722263336182\n",
      "56  train loss:  0.2051790952682495\n",
      "57  train loss:  0.20389831066131592\n",
      "58  train loss:  0.20117835700511932\n",
      "59  train loss:  0.19933445751667023\n",
      "60  train loss:  0.20038290321826935\n",
      "61  train loss:  0.19753652811050415\n",
      "62  train loss:  0.1960555613040924\n",
      "63  train loss:  0.19610179960727692\n",
      "64  train loss:  0.19420558214187622\n",
      "65  train loss:  0.1915273219347\n",
      "66  train loss:  0.19162175059318542\n",
      "67  train loss:  0.18956343829631805\n",
      "68  train loss:  0.1894693523645401\n",
      "69  train loss:  0.18824735283851624\n",
      "70  train loss:  0.18672692775726318\n",
      "71  train loss:  0.18541881442070007\n",
      "72  train loss:  0.1848510503768921\n",
      "73  train loss:  0.18383651971817017\n",
      "74  train loss:  0.18357022106647491\n",
      "75  train loss:  0.18222157657146454\n",
      "76  train loss:  0.1818140596151352\n",
      "77  train loss:  0.18052983283996582\n",
      "78  train loss:  0.17970658838748932\n",
      "79  train loss:  0.17939196527004242\n",
      "80  train loss:  0.17802166938781738\n",
      "81  train loss:  0.17845259606838226\n",
      "82  train loss:  0.17728057503700256\n",
      "83  train loss:  0.17620427906513214\n",
      "84  train loss:  0.17603382468223572\n",
      "85  train loss:  0.17535905539989471\n",
      "86  train loss:  0.17451047897338867\n",
      "87  train loss:  0.17446453869342804\n",
      "88  train loss:  0.17369647324085236\n",
      "89  train loss:  0.17264725267887115\n",
      "90  train loss:  0.17227840423583984\n",
      "91  train loss:  0.17165912687778473\n",
      "92  train loss:  0.17083631455898285\n",
      "93  train loss:  0.170549675822258\n",
      "94  train loss:  0.1705234795808792\n",
      "95  train loss:  0.16982151567935944\n",
      "96  train loss:  0.169053852558136\n",
      "97  train loss:  0.17111532390117645\n",
      "98  train loss:  0.1704915314912796\n",
      "99  train loss:  0.16771574318408966\n",
      "test acc (%):  tensor(79.0902)\n",
      "0  train loss:  0.41354188323020935\n",
      "1  train loss:  0.3924695551395416\n",
      "2  train loss:  0.3745133876800537\n",
      "3  train loss:  0.36701709032058716\n",
      "4  train loss:  0.3504144549369812\n",
      "5  train loss:  0.3414657413959503\n",
      "6  train loss:  0.3327767550945282\n",
      "7  train loss:  0.3208865225315094\n",
      "8  train loss:  0.31042754650115967\n",
      "9  train loss:  0.2995694577693939\n",
      "10  train loss:  0.2933030128479004\n",
      "11  train loss:  0.2831399738788605\n",
      "12  train loss:  0.2793498933315277\n",
      "13  train loss:  0.2719876766204834\n",
      "14  train loss:  0.27047502994537354\n",
      "15  train loss:  0.26622721552848816\n",
      "16  train loss:  0.25857827067375183\n",
      "17  train loss:  0.25513869524002075\n",
      "18  train loss:  0.25267720222473145\n",
      "19  train loss:  0.25670647621154785\n",
      "20  train loss:  0.24519509077072144\n",
      "21  train loss:  0.2467634379863739\n",
      "22  train loss:  0.2431299090385437\n",
      "23  train loss:  0.24417711794376373\n",
      "24  train loss:  0.23873178660869598\n",
      "25  train loss:  0.23793460428714752\n",
      "26  train loss:  0.22986942529678345\n",
      "27  train loss:  0.23362798988819122\n",
      "28  train loss:  0.2314898818731308\n",
      "29  train loss:  0.22655606269836426\n",
      "30  train loss:  0.22729121148586273\n",
      "31  train loss:  0.22282080352306366\n",
      "32  train loss:  0.22161583602428436\n",
      "33  train loss:  0.21851767599582672\n",
      "34  train loss:  0.21646654605865479\n",
      "35  train loss:  0.22205734252929688\n",
      "36  train loss:  0.2172263264656067\n",
      "37  train loss:  0.21148769557476044\n",
      "38  train loss:  0.21245077252388\n",
      "39  train loss:  0.2105524092912674\n",
      "40  train loss:  0.21036693453788757\n",
      "41  train loss:  0.206828773021698\n",
      "42  train loss:  0.20896922051906586\n",
      "43  train loss:  0.20519447326660156\n",
      "44  train loss:  0.20550088584423065\n",
      "45  train loss:  0.20111070573329926\n",
      "46  train loss:  0.2009488195180893\n",
      "47  train loss:  0.19926176965236664\n",
      "48  train loss:  0.19795750081539154\n",
      "49  train loss:  0.19616642594337463\n",
      "50  train loss:  0.1970689743757248\n",
      "51  train loss:  0.19346238672733307\n",
      "52  train loss:  0.19363005459308624\n",
      "53  train loss:  0.19261357188224792\n",
      "54  train loss:  0.19133879244327545\n",
      "55  train loss:  0.1898355782032013\n",
      "56  train loss:  0.18965624272823334\n",
      "57  train loss:  0.18999294936656952\n",
      "58  train loss:  0.18744419515132904\n",
      "59  train loss:  0.18665532767772675\n",
      "60  train loss:  0.18615449965000153\n",
      "61  train loss:  0.18499912321567535\n",
      "62  train loss:  0.1851681023836136\n",
      "63  train loss:  0.1842142939567566\n",
      "64  train loss:  0.1833600401878357\n",
      "65  train loss:  0.18289506435394287\n",
      "66  train loss:  0.18184418976306915\n",
      "67  train loss:  0.18088914453983307\n",
      "68  train loss:  0.18030840158462524\n",
      "69  train loss:  0.17923949658870697\n",
      "70  train loss:  0.17917117476463318\n",
      "71  train loss:  0.1789868324995041\n",
      "72  train loss:  0.17789188027381897\n",
      "73  train loss:  0.17734570801258087\n",
      "74  train loss:  0.17667295038700104\n",
      "75  train loss:  0.1760864406824112\n",
      "76  train loss:  0.17561055719852448\n",
      "77  train loss:  0.1753019094467163\n",
      "78  train loss:  0.17439593374729156\n",
      "79  train loss:  0.17398279905319214\n",
      "80  train loss:  0.17348235845565796\n",
      "81  train loss:  0.17296642065048218\n",
      "82  train loss:  0.17292606830596924\n",
      "83  train loss:  0.17285507917404175\n",
      "84  train loss:  0.17233268916606903\n",
      "85  train loss:  0.17166957259178162\n",
      "86  train loss:  0.17164862155914307\n",
      "87  train loss:  0.17120519280433655\n",
      "88  train loss:  0.17014934122562408\n",
      "89  train loss:  0.17036540806293488\n",
      "90  train loss:  0.1691233217716217\n",
      "91  train loss:  0.1699703484773636\n",
      "92  train loss:  0.17058175802230835\n",
      "93  train loss:  0.16830304265022278\n",
      "94  train loss:  0.16909180581569672\n",
      "95  train loss:  0.16692502796649933\n",
      "96  train loss:  0.1676032841205597\n",
      "97  train loss:  0.16698701679706573\n",
      "98  train loss:  0.1662614494562149\n",
      "99  train loss:  0.16824586689472198\n",
      "test acc (%):  tensor(77.6651)\n",
      "0  train loss:  0.4931502044200897\n",
      "1  train loss:  0.4699935019016266\n",
      "2  train loss:  0.4328186810016632\n",
      "3  train loss:  0.40357258915901184\n",
      "4  train loss:  0.40829887986183167\n",
      "5  train loss:  0.38987958431243896\n",
      "6  train loss:  0.3923625648021698\n",
      "7  train loss:  0.3713895082473755\n",
      "8  train loss:  0.35609209537506104\n",
      "9  train loss:  0.3417166769504547\n",
      "10  train loss:  0.336409330368042\n",
      "11  train loss:  0.32772722840309143\n",
      "12  train loss:  0.32606783509254456\n",
      "13  train loss:  0.31228935718536377\n",
      "14  train loss:  0.3057825267314911\n",
      "15  train loss:  0.3018248677253723\n",
      "16  train loss:  0.29727011919021606\n",
      "17  train loss:  0.29119378328323364\n",
      "18  train loss:  0.2888029217720032\n",
      "19  train loss:  0.28371739387512207\n",
      "20  train loss:  0.28326672315597534\n",
      "21  train loss:  0.28248608112335205\n",
      "22  train loss:  0.2776503264904022\n",
      "23  train loss:  0.2736748158931732\n",
      "24  train loss:  0.27255308628082275\n",
      "25  train loss:  0.26859042048454285\n",
      "26  train loss:  0.26456761360168457\n",
      "27  train loss:  0.26288360357284546\n",
      "28  train loss:  0.2617151439189911\n",
      "29  train loss:  0.26048657298088074\n",
      "30  train loss:  0.25855913758277893\n",
      "31  train loss:  0.25720447301864624\n",
      "32  train loss:  0.2591916024684906\n",
      "33  train loss:  0.2661343514919281\n",
      "34  train loss:  0.26696938276290894\n",
      "35  train loss:  0.25855737924575806\n",
      "36  train loss:  0.2655767798423767\n",
      "37  train loss:  0.26142701506614685\n",
      "38  train loss:  0.2539057433605194\n",
      "39  train loss:  0.24646875262260437\n",
      "40  train loss:  0.2463587075471878\n",
      "41  train loss:  0.2439466118812561\n",
      "42  train loss:  0.24461671710014343\n",
      "43  train loss:  0.2439683973789215\n",
      "44  train loss:  0.2503596842288971\n",
      "45  train loss:  0.2412199229001999\n",
      "46  train loss:  0.24181601405143738\n",
      "47  train loss:  0.2426445186138153\n",
      "48  train loss:  0.24430988729000092\n",
      "49  train loss:  0.23839472234249115\n",
      "50  train loss:  0.25245219469070435\n",
      "51  train loss:  0.2388938069343567\n",
      "52  train loss:  0.23586814105510712\n",
      "53  train loss:  0.24097932875156403\n",
      "54  train loss:  0.23563486337661743\n",
      "55  train loss:  0.23295925557613373\n",
      "56  train loss:  0.24035324156284332\n",
      "57  train loss:  0.23083743453025818\n",
      "58  train loss:  0.22948941588401794\n",
      "59  train loss:  0.2313646674156189\n",
      "60  train loss:  0.22913560271263123\n",
      "61  train loss:  0.22689040005207062\n",
      "62  train loss:  0.2331337183713913\n",
      "63  train loss:  0.22754453122615814\n",
      "64  train loss:  0.2296501249074936\n",
      "65  train loss:  0.23069560527801514\n",
      "66  train loss:  0.225791797041893\n",
      "67  train loss:  0.22450461983680725\n",
      "68  train loss:  0.22548861801624298\n",
      "69  train loss:  0.225694939494133\n",
      "70  train loss:  0.22189758718013763\n",
      "71  train loss:  0.22125841677188873\n",
      "72  train loss:  0.22206903994083405\n",
      "73  train loss:  0.22093002498149872\n",
      "74  train loss:  0.22000709176063538\n",
      "75  train loss:  0.219744473695755\n",
      "76  train loss:  0.2189529985189438\n",
      "77  train loss:  0.2202989161014557\n",
      "78  train loss:  0.2213733196258545\n",
      "79  train loss:  0.22149325907230377\n",
      "80  train loss:  0.21956227719783783\n",
      "81  train loss:  0.22049959003925323\n",
      "82  train loss:  0.21540358662605286\n",
      "83  train loss:  0.21753734350204468\n",
      "84  train loss:  0.2187715768814087\n",
      "85  train loss:  0.21875952184200287\n",
      "86  train loss:  0.22425882518291473\n",
      "87  train loss:  0.21459142863750458\n",
      "88  train loss:  0.220464825630188\n",
      "89  train loss:  0.2193930596113205\n",
      "90  train loss:  0.21473737061023712\n",
      "91  train loss:  0.21691511571407318\n",
      "92  train loss:  0.21360205113887787\n",
      "93  train loss:  0.2149571180343628\n",
      "94  train loss:  0.21342319250106812\n",
      "95  train loss:  0.2129346877336502\n",
      "96  train loss:  0.2099069356918335\n",
      "97  train loss:  0.2110585868358612\n",
      "98  train loss:  0.20956245064735413\n",
      "99  train loss:  0.20897354185581207\n",
      "test acc (%):  tensor(77.1718)\n",
      "0  train loss:  0.5193343162536621\n",
      "1  train loss:  0.45509886741638184\n",
      "2  train loss:  0.4305005669593811\n",
      "3  train loss:  0.40874359011650085\n",
      "4  train loss:  0.3968586325645447\n",
      "5  train loss:  0.3883795142173767\n",
      "6  train loss:  0.3845866918563843\n",
      "7  train loss:  0.39806023240089417\n",
      "8  train loss:  0.3974177837371826\n",
      "9  train loss:  0.37653401494026184\n",
      "10  train loss:  0.3690502345561981\n",
      "11  train loss:  0.36730265617370605\n",
      "12  train loss:  0.34643101692199707\n",
      "13  train loss:  0.3341462314128876\n",
      "14  train loss:  0.33475178480148315\n",
      "15  train loss:  0.3555268943309784\n",
      "16  train loss:  0.33886903524398804\n",
      "17  train loss:  0.32504037022590637\n",
      "18  train loss:  0.32478049397468567\n",
      "19  train loss:  0.3173445463180542\n",
      "20  train loss:  0.30294269323349\n",
      "21  train loss:  0.32422909140586853\n",
      "22  train loss:  0.32530179619789124\n",
      "23  train loss:  0.2996272146701813\n",
      "24  train loss:  0.2905018627643585\n",
      "25  train loss:  0.29185906052589417\n",
      "26  train loss:  0.28601300716400146\n",
      "27  train loss:  0.2833499610424042\n",
      "28  train loss:  0.2821923792362213\n",
      "29  train loss:  0.2828441560268402\n",
      "30  train loss:  0.28652939200401306\n",
      "31  train loss:  0.2847408652305603\n",
      "32  train loss:  0.2753095328807831\n",
      "33  train loss:  0.27236849069595337\n",
      "34  train loss:  0.2705398201942444\n",
      "35  train loss:  0.2735000252723694\n",
      "36  train loss:  0.2870718836784363\n",
      "37  train loss:  0.28750014305114746\n",
      "38  train loss:  0.27130287885665894\n",
      "39  train loss:  0.26409924030303955\n",
      "40  train loss:  0.2648722529411316\n",
      "41  train loss:  0.2637421190738678\n",
      "42  train loss:  0.26472362875938416\n",
      "43  train loss:  0.2649061977863312\n",
      "44  train loss:  0.259059339761734\n",
      "45  train loss:  0.2629237473011017\n",
      "46  train loss:  0.26856517791748047\n",
      "47  train loss:  0.26629942655563354\n",
      "48  train loss:  0.2571551501750946\n",
      "49  train loss:  0.26303237676620483\n",
      "50  train loss:  0.26249223947525024\n",
      "51  train loss:  0.2548792362213135\n",
      "52  train loss:  0.2543177306652069\n",
      "53  train loss:  0.26016154885292053\n",
      "54  train loss:  0.26136335730552673\n",
      "55  train loss:  0.2568545639514923\n",
      "56  train loss:  0.24604302644729614\n",
      "57  train loss:  0.2502617835998535\n",
      "58  train loss:  0.24635355174541473\n",
      "59  train loss:  0.24333181977272034\n",
      "60  train loss:  0.24443046748638153\n",
      "61  train loss:  0.24002385139465332\n",
      "62  train loss:  0.23708446323871613\n",
      "63  train loss:  0.23839205503463745\n",
      "64  train loss:  0.23545536398887634\n",
      "65  train loss:  0.23380549252033234\n",
      "66  train loss:  0.2308771014213562\n",
      "67  train loss:  0.22667096555233002\n",
      "68  train loss:  0.22648803889751434\n",
      "69  train loss:  0.22841452062129974\n",
      "70  train loss:  0.22706712782382965\n",
      "71  train loss:  0.22405938804149628\n",
      "72  train loss:  0.22478733956813812\n",
      "73  train loss:  0.22160139679908752\n",
      "74  train loss:  0.21923232078552246\n",
      "75  train loss:  0.22099138796329498\n",
      "76  train loss:  0.22221750020980835\n",
      "77  train loss:  0.2191963791847229\n",
      "78  train loss:  0.216720849275589\n",
      "79  train loss:  0.2161627858877182\n",
      "80  train loss:  0.2150239795446396\n",
      "81  train loss:  0.2136131078004837\n",
      "82  train loss:  0.21223017573356628\n",
      "83  train loss:  0.2112165093421936\n",
      "84  train loss:  0.21070539951324463\n",
      "85  train loss:  0.20978640019893646\n",
      "86  train loss:  0.207954540848732\n",
      "87  train loss:  0.20756378769874573\n",
      "88  train loss:  0.20615310966968536\n",
      "89  train loss:  0.2053941786289215\n",
      "90  train loss:  0.204387366771698\n",
      "91  train loss:  0.2036505788564682\n",
      "92  train loss:  0.20296309888362885\n",
      "93  train loss:  0.20236770808696747\n",
      "94  train loss:  0.20128051936626434\n",
      "95  train loss:  0.2001688927412033\n",
      "96  train loss:  0.1993817687034607\n",
      "97  train loss:  0.19877992570400238\n",
      "98  train loss:  0.19832777976989746\n",
      "99  train loss:  0.19787025451660156\n",
      "test acc (%):  tensor(78.4050)\n",
      "0  train loss:  0.5065205693244934\n",
      "1  train loss:  0.46368202567100525\n",
      "2  train loss:  0.4445749521255493\n",
      "3  train loss:  0.4227934181690216\n",
      "4  train loss:  0.4032430648803711\n",
      "5  train loss:  0.39614951610565186\n",
      "6  train loss:  0.4018504321575165\n",
      "7  train loss:  0.41473388671875\n",
      "8  train loss:  0.37889111042022705\n",
      "9  train loss:  0.37079954147338867\n",
      "10  train loss:  0.37150365114212036\n",
      "11  train loss:  0.37962207198143005\n",
      "12  train loss:  0.3836889863014221\n",
      "13  train loss:  0.3591865301132202\n",
      "14  train loss:  0.33958446979522705\n",
      "15  train loss:  0.32710492610931396\n",
      "16  train loss:  0.330607533454895\n",
      "17  train loss:  0.32391417026519775\n",
      "18  train loss:  0.3314742147922516\n",
      "19  train loss:  0.3293286859989166\n",
      "20  train loss:  0.33961349725723267\n",
      "21  train loss:  0.3463536202907562\n",
      "22  train loss:  0.3294420540332794\n",
      "23  train loss:  0.31965386867523193\n",
      "24  train loss:  0.3157004714012146\n",
      "25  train loss:  0.305074006319046\n",
      "26  train loss:  0.30475834012031555\n",
      "27  train loss:  0.30600109696388245\n",
      "28  train loss:  0.30373769998550415\n",
      "29  train loss:  0.3061109185218811\n",
      "30  train loss:  0.30825138092041016\n",
      "31  train loss:  0.2936945855617523\n",
      "32  train loss:  0.2898063063621521\n",
      "33  train loss:  0.2849971055984497\n",
      "34  train loss:  0.2766077220439911\n",
      "35  train loss:  0.2732485830783844\n",
      "36  train loss:  0.2714574933052063\n",
      "37  train loss:  0.2677132785320282\n",
      "38  train loss:  0.26531872153282166\n",
      "39  train loss:  0.2628784477710724\n",
      "40  train loss:  0.26204144954681396\n",
      "41  train loss:  0.2588508129119873\n",
      "42  train loss:  0.25515174865722656\n",
      "43  train loss:  0.25593316555023193\n",
      "44  train loss:  0.2513543963432312\n",
      "45  train loss:  0.25016340613365173\n",
      "46  train loss:  0.25091877579689026\n",
      "47  train loss:  0.2553221583366394\n",
      "48  train loss:  0.24841760098934174\n",
      "49  train loss:  0.24770361185073853\n",
      "50  train loss:  0.24288851022720337\n",
      "51  train loss:  0.2446785569190979\n",
      "52  train loss:  0.23696079850196838\n",
      "53  train loss:  0.2376386672258377\n",
      "54  train loss:  0.23534928262233734\n",
      "55  train loss:  0.23170796036720276\n",
      "56  train loss:  0.2307300716638565\n",
      "57  train loss:  0.23117166757583618\n",
      "58  train loss:  0.2293912172317505\n",
      "59  train loss:  0.22755886614322662\n",
      "60  train loss:  0.22737710177898407\n",
      "61  train loss:  0.224896639585495\n",
      "62  train loss:  0.22405888140201569\n",
      "63  train loss:  0.2233256846666336\n",
      "64  train loss:  0.22161515057086945\n",
      "65  train loss:  0.22085383534431458\n",
      "66  train loss:  0.21961240470409393\n",
      "67  train loss:  0.21857979893684387\n",
      "68  train loss:  0.21780315041542053\n",
      "69  train loss:  0.21788398921489716\n",
      "70  train loss:  0.21671590209007263\n",
      "71  train loss:  0.21596598625183105\n",
      "72  train loss:  0.21435123682022095\n",
      "73  train loss:  0.21425805985927582\n",
      "74  train loss:  0.2133914977312088\n",
      "75  train loss:  0.21243268251419067\n",
      "76  train loss:  0.21163412928581238\n",
      "77  train loss:  0.21160593628883362\n",
      "78  train loss:  0.21128658950328827\n",
      "79  train loss:  0.21028195321559906\n",
      "80  train loss:  0.20895366370677948\n",
      "81  train loss:  0.20905452966690063\n",
      "82  train loss:  0.20893152058124542\n",
      "83  train loss:  0.20784327387809753\n",
      "84  train loss:  0.20747162401676178\n",
      "85  train loss:  0.2070208191871643\n",
      "86  train loss:  0.20592328906059265\n",
      "87  train loss:  0.20509129762649536\n",
      "88  train loss:  0.20432430505752563\n",
      "89  train loss:  0.204522967338562\n",
      "90  train loss:  0.20337113738059998\n",
      "91  train loss:  0.20224791765213013\n",
      "92  train loss:  0.2017327845096588\n",
      "93  train loss:  0.20141147077083588\n",
      "94  train loss:  0.20074670016765594\n",
      "95  train loss:  0.20018719136714935\n",
      "96  train loss:  0.20025840401649475\n",
      "97  train loss:  0.1999209076166153\n",
      "98  train loss:  0.1991996169090271\n",
      "99  train loss:  0.19934071600437164\n",
      "test acc (%):  tensor(76.7882)\n",
      "0  train loss:  0.4068978428840637\n",
      "1  train loss:  0.3861131966114044\n",
      "2  train loss:  0.35938170552253723\n",
      "3  train loss:  0.35277214646339417\n",
      "4  train loss:  0.3461834788322449\n",
      "5  train loss:  0.3340311646461487\n",
      "6  train loss:  0.31723150610923767\n",
      "7  train loss:  0.30997949838638306\n",
      "8  train loss:  0.3027459681034088\n",
      "9  train loss:  0.2938503324985504\n",
      "10  train loss:  0.2907526195049286\n",
      "11  train loss:  0.28722140192985535\n",
      "12  train loss:  0.28077414631843567\n",
      "13  train loss:  0.27462807297706604\n",
      "14  train loss:  0.2698058784008026\n",
      "15  train loss:  0.2714046239852905\n",
      "16  train loss:  0.2696051597595215\n",
      "17  train loss:  0.2668125033378601\n",
      "18  train loss:  0.26607587933540344\n",
      "19  train loss:  0.25809651613235474\n",
      "20  train loss:  0.25786781311035156\n",
      "21  train loss:  0.25151100754737854\n",
      "22  train loss:  0.2515268623828888\n",
      "23  train loss:  0.24411867558956146\n",
      "24  train loss:  0.2450941652059555\n",
      "25  train loss:  0.24255070090293884\n",
      "26  train loss:  0.23822945356369019\n",
      "27  train loss:  0.2368757575750351\n",
      "28  train loss:  0.23293882608413696\n",
      "29  train loss:  0.2321196347475052\n",
      "30  train loss:  0.22987493872642517\n",
      "31  train loss:  0.2280326783657074\n",
      "32  train loss:  0.22556932270526886\n",
      "33  train loss:  0.2244209200143814\n",
      "34  train loss:  0.223890483379364\n",
      "35  train loss:  0.22073544561862946\n",
      "36  train loss:  0.22023503482341766\n",
      "37  train loss:  0.22160355746746063\n",
      "38  train loss:  0.21854202449321747\n",
      "39  train loss:  0.21925628185272217\n",
      "40  train loss:  0.21844469010829926\n",
      "41  train loss:  0.22099104523658752\n",
      "42  train loss:  0.21733488142490387\n",
      "43  train loss:  0.2153840810060501\n",
      "44  train loss:  0.21199768781661987\n",
      "45  train loss:  0.21314917504787445\n",
      "46  train loss:  0.21192650496959686\n",
      "47  train loss:  0.2110511213541031\n",
      "48  train loss:  0.210662379860878\n",
      "49  train loss:  0.20825675129890442\n",
      "50  train loss:  0.20934194326400757\n",
      "51  train loss:  0.20837830007076263\n",
      "52  train loss:  0.20793530344963074\n",
      "53  train loss:  0.20660361647605896\n",
      "54  train loss:  0.20561867952346802\n",
      "55  train loss:  0.20469070971012115\n",
      "56  train loss:  0.20347584784030914\n",
      "57  train loss:  0.203111469745636\n",
      "58  train loss:  0.20238591730594635\n",
      "59  train loss:  0.2000296413898468\n",
      "60  train loss:  0.19980455935001373\n",
      "61  train loss:  0.1993437558412552\n",
      "62  train loss:  0.1978440135717392\n",
      "63  train loss:  0.19718436896800995\n",
      "64  train loss:  0.19649666547775269\n",
      "65  train loss:  0.19575147330760956\n",
      "66  train loss:  0.1949780136346817\n",
      "67  train loss:  0.19399325549602509\n",
      "68  train loss:  0.19335293769836426\n",
      "69  train loss:  0.1925843060016632\n",
      "70  train loss:  0.19176819920539856\n",
      "71  train loss:  0.1911180168390274\n",
      "72  train loss:  0.19033001363277435\n",
      "73  train loss:  0.18961481750011444\n",
      "74  train loss:  0.19004428386688232\n",
      "75  train loss:  0.19076375663280487\n",
      "76  train loss:  0.19037725031375885\n",
      "77  train loss:  0.18932539224624634\n",
      "78  train loss:  0.18988361954689026\n",
      "79  train loss:  0.18861915171146393\n",
      "80  train loss:  0.1876068413257599\n",
      "81  train loss:  0.18776319921016693\n",
      "82  train loss:  0.18629521131515503\n",
      "83  train loss:  0.1854294091463089\n",
      "84  train loss:  0.18618285655975342\n",
      "85  train loss:  0.18494214117527008\n",
      "86  train loss:  0.1854914277791977\n",
      "87  train loss:  0.18374748528003693\n",
      "88  train loss:  0.18316714465618134\n",
      "89  train loss:  0.1824699342250824\n",
      "90  train loss:  0.18189136683940887\n",
      "91  train loss:  0.18106083571910858\n",
      "92  train loss:  0.18046055734157562\n",
      "93  train loss:  0.17944563925266266\n",
      "94  train loss:  0.17981277406215668\n",
      "95  train loss:  0.17971642315387726\n",
      "96  train loss:  0.17821349203586578\n",
      "97  train loss:  0.177778422832489\n",
      "98  train loss:  0.17755354940891266\n",
      "99  train loss:  0.17684169113636017\n",
      "test acc (%):  tensor(78.4050)\n",
      "0  train loss:  0.4007130563259125\n",
      "1  train loss:  0.3835459053516388\n",
      "2  train loss:  0.36237838864326477\n",
      "3  train loss:  0.3380492925643921\n",
      "4  train loss:  0.3319322466850281\n",
      "5  train loss:  0.3229224383831024\n",
      "6  train loss:  0.3105449378490448\n",
      "7  train loss:  0.29839301109313965\n",
      "8  train loss:  0.2975919246673584\n",
      "9  train loss:  0.27825161814689636\n",
      "10  train loss:  0.2676815986633301\n",
      "11  train loss:  0.26040735840797424\n",
      "12  train loss:  0.25377875566482544\n",
      "13  train loss:  0.2502426505088806\n",
      "14  train loss:  0.25022223591804504\n",
      "15  train loss:  0.25608065724372864\n",
      "16  train loss:  0.25290554761886597\n",
      "17  train loss:  0.25350332260131836\n",
      "18  train loss:  0.2582170367240906\n",
      "19  train loss:  0.24439232051372528\n",
      "20  train loss:  0.2408173531293869\n",
      "21  train loss:  0.2337506115436554\n",
      "22  train loss:  0.22722496092319489\n",
      "23  train loss:  0.22343553602695465\n",
      "24  train loss:  0.21829856932163239\n",
      "25  train loss:  0.21511992812156677\n",
      "26  train loss:  0.20994269847869873\n",
      "27  train loss:  0.20917345583438873\n",
      "28  train loss:  0.20942653715610504\n",
      "29  train loss:  0.20730608701705933\n",
      "30  train loss:  0.2063475400209427\n",
      "31  train loss:  0.20415623486042023\n",
      "32  train loss:  0.2015070617198944\n",
      "33  train loss:  0.19866812229156494\n",
      "34  train loss:  0.1964937001466751\n",
      "35  train loss:  0.19445958733558655\n",
      "36  train loss:  0.19307194650173187\n",
      "37  train loss:  0.19171863794326782\n",
      "38  train loss:  0.1905745267868042\n",
      "39  train loss:  0.1894690990447998\n",
      "40  train loss:  0.18787245452404022\n",
      "41  train loss:  0.1866692751646042\n",
      "42  train loss:  0.186130091547966\n",
      "43  train loss:  0.18533609807491302\n",
      "44  train loss:  0.18378964066505432\n",
      "45  train loss:  0.18332825601100922\n",
      "46  train loss:  0.18255282938480377\n",
      "47  train loss:  0.18166306614875793\n",
      "48  train loss:  0.18048183619976044\n",
      "49  train loss:  0.17998573184013367\n",
      "50  train loss:  0.17880941927433014\n",
      "51  train loss:  0.178036168217659\n",
      "52  train loss:  0.17874911427497864\n",
      "53  train loss:  0.1793632060289383\n",
      "54  train loss:  0.1765914410352707\n",
      "55  train loss:  0.1764901876449585\n",
      "56  train loss:  0.1760321855545044\n",
      "57  train loss:  0.17584548890590668\n",
      "58  train loss:  0.17508168518543243\n",
      "59  train loss:  0.17413976788520813\n",
      "60  train loss:  0.17528480291366577\n",
      "61  train loss:  0.17400582134723663\n",
      "62  train loss:  0.17250187695026398\n",
      "63  train loss:  0.17115050554275513\n",
      "64  train loss:  0.1710742861032486\n",
      "65  train loss:  0.17056666314601898\n",
      "66  train loss:  0.17009735107421875\n",
      "67  train loss:  0.16995084285736084\n",
      "68  train loss:  0.1690537929534912\n",
      "69  train loss:  0.16802851855754852\n",
      "70  train loss:  0.16757933795452118\n",
      "71  train loss:  0.16730622947216034\n",
      "72  train loss:  0.16688485443592072\n",
      "73  train loss:  0.16627587378025055\n",
      "74  train loss:  0.16621895134449005\n",
      "75  train loss:  0.165618896484375\n",
      "76  train loss:  0.16525273025035858\n",
      "77  train loss:  0.16485971212387085\n",
      "78  train loss:  0.16474226117134094\n",
      "79  train loss:  0.16393069922924042\n",
      "80  train loss:  0.16368982195854187\n",
      "81  train loss:  0.16338558495044708\n",
      "82  train loss:  0.16284063458442688\n",
      "83  train loss:  0.16246002912521362\n",
      "84  train loss:  0.16232769191265106\n",
      "85  train loss:  0.16202868521213531\n",
      "86  train loss:  0.16152353584766388\n",
      "87  train loss:  0.1612962782382965\n",
      "88  train loss:  0.16111183166503906\n",
      "89  train loss:  0.1606452763080597\n",
      "90  train loss:  0.16032062470912933\n",
      "91  train loss:  0.15972404181957245\n",
      "92  train loss:  0.15894834697246552\n",
      "93  train loss:  0.15880461037158966\n",
      "94  train loss:  0.15862052142620087\n",
      "95  train loss:  0.1581820696592331\n",
      "96  train loss:  0.1577935814857483\n",
      "97  train loss:  0.1578812301158905\n",
      "98  train loss:  0.15801021456718445\n",
      "99  train loss:  0.15695537626743317\n",
      "test acc (%):  tensor(78.7613)\n",
      "0  train loss:  0.46136346459388733\n",
      "1  train loss:  0.42655229568481445\n",
      "2  train loss:  0.3949466347694397\n",
      "3  train loss:  0.38560476899147034\n",
      "4  train loss:  0.3558138608932495\n",
      "5  train loss:  0.35703399777412415\n",
      "6  train loss:  0.3463763892650604\n",
      "7  train loss:  0.3329392075538635\n",
      "8  train loss:  0.3201679289340973\n",
      "9  train loss:  0.3168490529060364\n",
      "10  train loss:  0.30771636962890625\n",
      "11  train loss:  0.29912951588630676\n",
      "12  train loss:  0.28674817085266113\n",
      "13  train loss:  0.2818765938282013\n",
      "14  train loss:  0.2798187732696533\n",
      "15  train loss:  0.27507588267326355\n",
      "16  train loss:  0.2694656550884247\n",
      "17  train loss:  0.2656429708003998\n",
      "18  train loss:  0.261331707239151\n",
      "19  train loss:  0.25901931524276733\n",
      "20  train loss:  0.2533556818962097\n",
      "21  train loss:  0.2545337975025177\n",
      "22  train loss:  0.24996745586395264\n",
      "23  train loss:  0.24753223359584808\n",
      "24  train loss:  0.24202874302864075\n",
      "25  train loss:  0.2406333088874817\n",
      "26  train loss:  0.23634730279445648\n",
      "27  train loss:  0.23836073279380798\n",
      "28  train loss:  0.23604080080986023\n",
      "29  train loss:  0.2329973727464676\n",
      "30  train loss:  0.23238077759742737\n",
      "31  train loss:  0.2316577285528183\n",
      "32  train loss:  0.23145152628421783\n",
      "33  train loss:  0.23010526597499847\n",
      "34  train loss:  0.2276921421289444\n",
      "35  train loss:  0.22571241855621338\n",
      "36  train loss:  0.22424662113189697\n",
      "37  train loss:  0.22710150480270386\n",
      "38  train loss:  0.224761500954628\n",
      "39  train loss:  0.22269690036773682\n",
      "40  train loss:  0.2203407734632492\n",
      "41  train loss:  0.2188214212656021\n",
      "42  train loss:  0.21969446539878845\n",
      "43  train loss:  0.21737848222255707\n",
      "44  train loss:  0.21684733033180237\n",
      "45  train loss:  0.21439535915851593\n",
      "46  train loss:  0.2144317477941513\n",
      "47  train loss:  0.21347133815288544\n",
      "48  train loss:  0.21096749603748322\n",
      "49  train loss:  0.21205423772335052\n",
      "50  train loss:  0.20803922414779663\n",
      "51  train loss:  0.2081054151058197\n",
      "52  train loss:  0.20606118440628052\n",
      "53  train loss:  0.21061570942401886\n",
      "54  train loss:  0.2061759978532791\n",
      "55  train loss:  0.2035631537437439\n",
      "56  train loss:  0.20308548212051392\n",
      "57  train loss:  0.20154671370983124\n",
      "58  train loss:  0.20065513253211975\n",
      "59  train loss:  0.200148805975914\n",
      "60  train loss:  0.19988228380680084\n",
      "61  train loss:  0.20102480053901672\n",
      "62  train loss:  0.19868458807468414\n",
      "63  train loss:  0.19760805368423462\n",
      "64  train loss:  0.19904282689094543\n",
      "65  train loss:  0.19845576584339142\n",
      "66  train loss:  0.1974649876356125\n",
      "67  train loss:  0.19605442881584167\n",
      "68  train loss:  0.19433051347732544\n",
      "69  train loss:  0.19555237889289856\n",
      "70  train loss:  0.191693976521492\n",
      "71  train loss:  0.19291849434375763\n",
      "72  train loss:  0.19145552814006805\n",
      "73  train loss:  0.19066137075424194\n",
      "74  train loss:  0.19101585447788239\n",
      "75  train loss:  0.18884843587875366\n",
      "76  train loss:  0.18837092816829681\n",
      "77  train loss:  0.1881500631570816\n",
      "78  train loss:  0.1868618279695511\n",
      "79  train loss:  0.1866273730993271\n",
      "80  train loss:  0.18576925992965698\n",
      "81  train loss:  0.18482835590839386\n",
      "82  train loss:  0.18472887575626373\n",
      "83  train loss:  0.18376809358596802\n",
      "84  train loss:  0.18326206505298615\n",
      "85  train loss:  0.18290317058563232\n",
      "86  train loss:  0.1822144091129303\n",
      "87  train loss:  0.1817891001701355\n",
      "88  train loss:  0.18140944838523865\n",
      "89  train loss:  0.1808547079563141\n",
      "90  train loss:  0.18085546791553497\n",
      "91  train loss:  0.1800067126750946\n",
      "92  train loss:  0.179155170917511\n",
      "93  train loss:  0.1786731630563736\n",
      "94  train loss:  0.1780671775341034\n",
      "95  train loss:  0.17780190706253052\n",
      "96  train loss:  0.17716169357299805\n",
      "97  train loss:  0.17621086537837982\n",
      "98  train loss:  0.17613618075847626\n",
      "99  train loss:  0.17548921704292297\n",
      "test acc (%):  tensor(77.9118)\n",
      "0  train loss:  0.45787495374679565\n",
      "1  train loss:  0.4239650368690491\n",
      "2  train loss:  0.3848242461681366\n",
      "3  train loss:  0.35410305857658386\n",
      "4  train loss:  0.33863088488578796\n",
      "5  train loss:  0.3194536566734314\n",
      "6  train loss:  0.3123815357685089\n",
      "7  train loss:  0.29994580149650574\n",
      "8  train loss:  0.3088460862636566\n",
      "9  train loss:  0.3047061264514923\n",
      "10  train loss:  0.2941838204860687\n",
      "11  train loss:  0.29222074151039124\n",
      "12  train loss:  0.29840123653411865\n",
      "13  train loss:  0.3014536201953888\n",
      "14  train loss:  0.2942239046096802\n",
      "15  train loss:  0.299625426530838\n",
      "16  train loss:  0.29870152473449707\n",
      "17  train loss:  0.2733106017112732\n",
      "18  train loss:  0.2763729989528656\n",
      "19  train loss:  0.2663157284259796\n",
      "20  train loss:  0.26125502586364746\n",
      "21  train loss:  0.2624824345111847\n",
      "22  train loss:  0.2554962933063507\n",
      "23  train loss:  0.24692201614379883\n",
      "24  train loss:  0.2444985806941986\n",
      "25  train loss:  0.2401886135339737\n",
      "26  train loss:  0.23869551718235016\n",
      "27  train loss:  0.23661015927791595\n",
      "28  train loss:  0.23186257481575012\n",
      "29  train loss:  0.2295810431241989\n",
      "30  train loss:  0.22672265768051147\n",
      "31  train loss:  0.2244962453842163\n",
      "32  train loss:  0.22630609571933746\n",
      "33  train loss:  0.221905916929245\n",
      "34  train loss:  0.2180442363023758\n",
      "35  train loss:  0.21784169971942902\n",
      "36  train loss:  0.21588563919067383\n",
      "37  train loss:  0.21307969093322754\n",
      "38  train loss:  0.21002070605754852\n",
      "39  train loss:  0.2084028422832489\n",
      "40  train loss:  0.208216592669487\n",
      "41  train loss:  0.21503156423568726\n",
      "42  train loss:  0.21425923705101013\n",
      "43  train loss:  0.21293355524539948\n",
      "44  train loss:  0.21074175834655762\n",
      "45  train loss:  0.21010935306549072\n",
      "46  train loss:  0.20838233828544617\n",
      "47  train loss:  0.20448915660381317\n",
      "48  train loss:  0.20401781797409058\n",
      "49  train loss:  0.20503972470760345\n",
      "50  train loss:  0.20088551938533783\n",
      "51  train loss:  0.19765423238277435\n",
      "52  train loss:  0.1950995773077011\n",
      "53  train loss:  0.1942441314458847\n",
      "54  train loss:  0.19285547733306885\n",
      "55  train loss:  0.19159910082817078\n",
      "56  train loss:  0.1904776394367218\n",
      "57  train loss:  0.18931537866592407\n",
      "58  train loss:  0.18855120241641998\n",
      "59  train loss:  0.18693771958351135\n",
      "60  train loss:  0.18646055459976196\n",
      "61  train loss:  0.18498171865940094\n",
      "62  train loss:  0.18340347707271576\n",
      "63  train loss:  0.18269696831703186\n",
      "64  train loss:  0.1817011535167694\n",
      "65  train loss:  0.18119235336780548\n",
      "66  train loss:  0.1808260679244995\n",
      "67  train loss:  0.1798677295446396\n",
      "68  train loss:  0.17861208319664001\n",
      "69  train loss:  0.17750434577465057\n",
      "70  train loss:  0.17718255519866943\n",
      "71  train loss:  0.17619264125823975\n",
      "72  train loss:  0.1757819503545761\n",
      "73  train loss:  0.17504315078258514\n",
      "74  train loss:  0.17422786355018616\n",
      "75  train loss:  0.17363040149211884\n",
      "76  train loss:  0.17278391122817993\n",
      "77  train loss:  0.1722457855939865\n",
      "78  train loss:  0.1719052791595459\n",
      "79  train loss:  0.17127001285552979\n",
      "80  train loss:  0.17059820890426636\n",
      "81  train loss:  0.17017152905464172\n",
      "82  train loss:  0.16952557861804962\n",
      "83  train loss:  0.16888868808746338\n",
      "84  train loss:  0.16854774951934814\n",
      "85  train loss:  0.16793011128902435\n",
      "86  train loss:  0.1673285961151123\n",
      "87  train loss:  0.16690020263195038\n",
      "88  train loss:  0.16621913015842438\n",
      "89  train loss:  0.165986567735672\n",
      "90  train loss:  0.16567930579185486\n",
      "91  train loss:  0.16486628353595734\n",
      "92  train loss:  0.16438138484954834\n",
      "93  train loss:  0.16611354053020477\n",
      "94  train loss:  0.1692124307155609\n",
      "95  train loss:  0.1787048876285553\n",
      "96  train loss:  0.16775023937225342\n",
      "97  train loss:  0.1738240122795105\n",
      "98  train loss:  0.1685393750667572\n",
      "99  train loss:  0.1711210012435913\n",
      "test acc (%):  tensor(78.8161)\n",
      "0  train loss:  0.4825485944747925\n",
      "1  train loss:  0.45180025696754456\n",
      "2  train loss:  0.4286097288131714\n",
      "3  train loss:  0.4072902202606201\n",
      "4  train loss:  0.401635080575943\n",
      "5  train loss:  0.37622135877609253\n",
      "6  train loss:  0.3496091663837433\n",
      "7  train loss:  0.342815637588501\n",
      "8  train loss:  0.3387753665447235\n",
      "9  train loss:  0.3258149325847626\n",
      "10  train loss:  0.3265222907066345\n",
      "11  train loss:  0.3261381983757019\n",
      "12  train loss:  0.31874391436576843\n",
      "13  train loss:  0.30837589502334595\n",
      "14  train loss:  0.30611059069633484\n",
      "15  train loss:  0.29927533864974976\n",
      "16  train loss:  0.3027392029762268\n",
      "17  train loss:  0.3075784742832184\n",
      "18  train loss:  0.3057437241077423\n",
      "19  train loss:  0.29330089688301086\n",
      "20  train loss:  0.30740880966186523\n",
      "21  train loss:  0.30809590220451355\n",
      "22  train loss:  0.2925933003425598\n",
      "23  train loss:  0.3055332899093628\n",
      "24  train loss:  0.2960704267024994\n",
      "25  train loss:  0.29884132742881775\n",
      "26  train loss:  0.2926596999168396\n",
      "27  train loss:  0.28283292055130005\n",
      "28  train loss:  0.2855988144874573\n",
      "29  train loss:  0.2725285589694977\n",
      "30  train loss:  0.28195881843566895\n",
      "31  train loss:  0.27471229434013367\n",
      "32  train loss:  0.26515740156173706\n",
      "33  train loss:  0.2631073594093323\n",
      "34  train loss:  0.26024213433265686\n",
      "35  train loss:  0.25364959239959717\n",
      "36  train loss:  0.25701844692230225\n",
      "37  train loss:  0.25619491934776306\n",
      "38  train loss:  0.2507852613925934\n",
      "39  train loss:  0.24934300780296326\n",
      "40  train loss:  0.24917952716350555\n",
      "41  train loss:  0.2448822408914566\n",
      "42  train loss:  0.241416335105896\n",
      "43  train loss:  0.2412041574716568\n",
      "44  train loss:  0.23702777922153473\n",
      "45  train loss:  0.23728890717029572\n",
      "46  train loss:  0.23194950819015503\n",
      "47  train loss:  0.23210780322551727\n",
      "48  train loss:  0.23018497228622437\n",
      "49  train loss:  0.22919760644435883\n",
      "50  train loss:  0.2262970507144928\n",
      "51  train loss:  0.22585512697696686\n",
      "52  train loss:  0.22316516935825348\n",
      "53  train loss:  0.22339306771755219\n",
      "54  train loss:  0.22118385136127472\n",
      "55  train loss:  0.22190362215042114\n",
      "56  train loss:  0.23711052536964417\n",
      "57  train loss:  0.22717563807964325\n",
      "58  train loss:  0.22972629964351654\n",
      "59  train loss:  0.23098088800907135\n",
      "60  train loss:  0.22943469882011414\n",
      "61  train loss:  0.2179432064294815\n",
      "62  train loss:  0.22603556513786316\n",
      "63  train loss:  0.2253390997648239\n",
      "64  train loss:  0.2209310233592987\n",
      "65  train loss:  0.21712255477905273\n",
      "66  train loss:  0.21790175139904022\n",
      "67  train loss:  0.21971653401851654\n",
      "68  train loss:  0.21833811700344086\n",
      "69  train loss:  0.21624276041984558\n",
      "70  train loss:  0.213917076587677\n",
      "71  train loss:  0.21450872719287872\n",
      "72  train loss:  0.21649441123008728\n",
      "73  train loss:  0.21555256843566895\n",
      "74  train loss:  0.2092193067073822\n",
      "75  train loss:  0.21058329939842224\n",
      "76  train loss:  0.210403174161911\n",
      "77  train loss:  0.2095249891281128\n",
      "78  train loss:  0.2096453309059143\n",
      "79  train loss:  0.20799383521080017\n",
      "80  train loss:  0.2055869698524475\n",
      "81  train loss:  0.20562909543514252\n",
      "82  train loss:  0.20289704203605652\n",
      "83  train loss:  0.20237646996974945\n",
      "84  train loss:  0.20263098180294037\n",
      "85  train loss:  0.20263715088367462\n",
      "86  train loss:  0.19847403466701508\n",
      "87  train loss:  0.1977154016494751\n",
      "88  train loss:  0.19742675125598907\n",
      "89  train loss:  0.1970805823802948\n",
      "90  train loss:  0.19569344818592072\n",
      "91  train loss:  0.1945788860321045\n",
      "92  train loss:  0.1947474479675293\n",
      "93  train loss:  0.19523905217647552\n",
      "94  train loss:  0.1949434131383896\n",
      "95  train loss:  0.19210971891880035\n",
      "96  train loss:  0.1934700459241867\n",
      "97  train loss:  0.19337917864322662\n",
      "98  train loss:  0.19144847989082336\n",
      "99  train loss:  0.19347649812698364\n",
      "test acc (%):  tensor(78.4324)\n",
      "0  train loss:  0.4217083752155304\n",
      "1  train loss:  0.38889679312705994\n",
      "2  train loss:  0.37144458293914795\n",
      "3  train loss:  0.3612901568412781\n",
      "4  train loss:  0.3382309079170227\n",
      "5  train loss:  0.3129916489124298\n",
      "6  train loss:  0.3096369802951813\n",
      "7  train loss:  0.2971763014793396\n",
      "8  train loss:  0.2896726429462433\n",
      "9  train loss:  0.2946344316005707\n",
      "10  train loss:  0.28632569313049316\n",
      "11  train loss:  0.28940752148628235\n",
      "12  train loss:  0.29092252254486084\n",
      "13  train loss:  0.3072473108768463\n",
      "14  train loss:  0.3102822005748749\n",
      "15  train loss:  0.2883807122707367\n",
      "16  train loss:  0.2961483895778656\n",
      "17  train loss:  0.28493258357048035\n",
      "18  train loss:  0.2886064350605011\n",
      "19  train loss:  0.2702517509460449\n",
      "20  train loss:  0.26901158690452576\n",
      "21  train loss:  0.2717849910259247\n",
      "22  train loss:  0.26710817217826843\n",
      "23  train loss:  0.2597489058971405\n",
      "24  train loss:  0.2519490718841553\n",
      "25  train loss:  0.25625190138816833\n",
      "26  train loss:  0.24752309918403625\n",
      "27  train loss:  0.24708518385887146\n",
      "28  train loss:  0.2419653981924057\n",
      "29  train loss:  0.23776791989803314\n",
      "30  train loss:  0.23824064433574677\n",
      "31  train loss:  0.23680594563484192\n",
      "32  train loss:  0.2332855761051178\n",
      "33  train loss:  0.22985365986824036\n",
      "34  train loss:  0.2294655591249466\n",
      "35  train loss:  0.2239752560853958\n",
      "36  train loss:  0.21980592608451843\n",
      "37  train loss:  0.22040429711341858\n",
      "38  train loss:  0.21582366526126862\n",
      "39  train loss:  0.22067664563655853\n",
      "40  train loss:  0.21745868027210236\n",
      "41  train loss:  0.212276428937912\n",
      "42  train loss:  0.2113262414932251\n",
      "43  train loss:  0.21062132716178894\n",
      "44  train loss:  0.2113180160522461\n",
      "45  train loss:  0.20997457206249237\n",
      "46  train loss:  0.2076873481273651\n",
      "47  train loss:  0.2067854106426239\n",
      "48  train loss:  0.2050926685333252\n",
      "49  train loss:  0.20350486040115356\n",
      "50  train loss:  0.201939195394516\n",
      "51  train loss:  0.20042642951011658\n",
      "52  train loss:  0.1989395171403885\n",
      "53  train loss:  0.19923022389411926\n",
      "54  train loss:  0.20091892778873444\n",
      "55  train loss:  0.19624626636505127\n",
      "56  train loss:  0.19965891540050507\n",
      "57  train loss:  0.20972682535648346\n",
      "58  train loss:  0.19780929386615753\n",
      "59  train loss:  0.21021445095539093\n",
      "60  train loss:  0.19618499279022217\n",
      "61  train loss:  0.2028612196445465\n",
      "62  train loss:  0.19555436074733734\n",
      "63  train loss:  0.19650566577911377\n",
      "64  train loss:  0.19331929087638855\n",
      "65  train loss:  0.1925683319568634\n",
      "66  train loss:  0.19129274785518646\n",
      "67  train loss:  0.18930310010910034\n",
      "68  train loss:  0.19015496969223022\n",
      "69  train loss:  0.19007417559623718\n",
      "70  train loss:  0.18625546991825104\n",
      "71  train loss:  0.19264115393161774\n",
      "72  train loss:  0.18600748479366302\n",
      "73  train loss:  0.1883348524570465\n",
      "74  train loss:  0.19548797607421875\n",
      "75  train loss:  0.1863197535276413\n",
      "76  train loss:  0.19259309768676758\n",
      "77  train loss:  0.19264335930347443\n",
      "78  train loss:  0.19023309648036957\n",
      "79  train loss:  0.1870533674955368\n",
      "80  train loss:  0.1861817091703415\n",
      "81  train loss:  0.18612387776374817\n",
      "82  train loss:  0.1874866634607315\n",
      "83  train loss:  0.185402974486351\n",
      "84  train loss:  0.1830804944038391\n",
      "85  train loss:  0.1811697781085968\n",
      "86  train loss:  0.18141385912895203\n",
      "87  train loss:  0.18090154230594635\n",
      "88  train loss:  0.1787066012620926\n",
      "89  train loss:  0.17913690209388733\n",
      "90  train loss:  0.17869728803634644\n",
      "91  train loss:  0.17673401534557343\n",
      "92  train loss:  0.17660218477249146\n",
      "93  train loss:  0.17596650123596191\n",
      "94  train loss:  0.17385061085224152\n",
      "95  train loss:  0.17708991467952728\n",
      "96  train loss:  0.17518582940101624\n",
      "97  train loss:  0.1754995435476303\n",
      "98  train loss:  0.17420892417430878\n",
      "99  train loss:  0.17350459098815918\n",
      "test acc (%):  tensor(78.5695)\n",
      "0  train loss:  0.5753486752510071\n",
      "1  train loss:  0.4773963391780853\n",
      "2  train loss:  0.43134641647338867\n",
      "3  train loss:  0.3460255563259125\n",
      "4  train loss:  0.3709224760532379\n",
      "5  train loss:  0.3835742771625519\n",
      "6  train loss:  0.3793242871761322\n",
      "7  train loss:  0.3647423982620239\n",
      "8  train loss:  0.35543838143348694\n",
      "9  train loss:  0.35612407326698303\n",
      "10  train loss:  0.3625728487968445\n",
      "11  train loss:  0.3653823733329773\n",
      "12  train loss:  0.36916470527648926\n",
      "13  train loss:  0.38379526138305664\n",
      "14  train loss:  0.38718244433403015\n",
      "15  train loss:  0.3612136244773865\n",
      "16  train loss:  0.3511349856853485\n",
      "17  train loss:  0.3447321951389313\n",
      "18  train loss:  0.3405916392803192\n",
      "19  train loss:  0.3319665193557739\n",
      "20  train loss:  0.3306586742401123\n",
      "21  train loss:  0.33437398076057434\n",
      "22  train loss:  0.33754608035087585\n",
      "23  train loss:  0.32249489426612854\n",
      "24  train loss:  0.32179996371269226\n",
      "25  train loss:  0.34294378757476807\n",
      "26  train loss:  0.331306129693985\n",
      "27  train loss:  0.3180801570415497\n",
      "28  train loss:  0.3117748498916626\n",
      "29  train loss:  0.3086211085319519\n",
      "30  train loss:  0.30899983644485474\n",
      "31  train loss:  0.297331839799881\n",
      "32  train loss:  0.2956843972206116\n",
      "33  train loss:  0.3052046298980713\n",
      "34  train loss:  0.31062033772468567\n",
      "35  train loss:  0.3180837035179138\n",
      "36  train loss:  0.3193218410015106\n",
      "37  train loss:  0.31583675742149353\n",
      "38  train loss:  0.30944278836250305\n",
      "39  train loss:  0.3005625605583191\n",
      "40  train loss:  0.3011166751384735\n",
      "41  train loss:  0.299252986907959\n",
      "42  train loss:  0.296585351228714\n",
      "43  train loss:  0.2914867103099823\n",
      "44  train loss:  0.28220027685165405\n",
      "45  train loss:  0.2988874316215515\n",
      "46  train loss:  0.2867126166820526\n",
      "47  train loss:  0.27495113015174866\n",
      "48  train loss:  0.2804911136627197\n",
      "49  train loss:  0.2786201238632202\n",
      "50  train loss:  0.28247401118278503\n",
      "51  train loss:  0.277054101228714\n",
      "52  train loss:  0.2679278254508972\n",
      "53  train loss:  0.2696709632873535\n",
      "54  train loss:  0.2768106758594513\n",
      "55  train loss:  0.26250553131103516\n",
      "56  train loss:  0.2597911059856415\n",
      "57  train loss:  0.25980621576309204\n",
      "58  train loss:  0.2521735727787018\n",
      "59  train loss:  0.24947352707386017\n",
      "60  train loss:  0.24805226922035217\n",
      "61  train loss:  0.24750541150569916\n",
      "62  train loss:  0.24420495331287384\n",
      "63  train loss:  0.2429715245962143\n",
      "64  train loss:  0.24179452657699585\n",
      "65  train loss:  0.23898839950561523\n",
      "66  train loss:  0.2371564358472824\n",
      "67  train loss:  0.2365567833185196\n",
      "68  train loss:  0.2331579476594925\n",
      "69  train loss:  0.2300918847322464\n",
      "70  train loss:  0.22899964451789856\n",
      "71  train loss:  0.22751781344413757\n",
      "72  train loss:  0.2268134206533432\n",
      "73  train loss:  0.22448080778121948\n",
      "74  train loss:  0.22225840389728546\n",
      "75  train loss:  0.22098250687122345\n",
      "76  train loss:  0.2206396907567978\n",
      "77  train loss:  0.217901811003685\n",
      "78  train loss:  0.2175646424293518\n",
      "79  train loss:  0.21785634756088257\n",
      "80  train loss:  0.21620726585388184\n",
      "81  train loss:  0.21587613224983215\n",
      "82  train loss:  0.21639859676361084\n",
      "83  train loss:  0.21444521844387054\n",
      "84  train loss:  0.21686622500419617\n",
      "85  train loss:  0.21105296909809113\n",
      "86  train loss:  0.21195903420448303\n",
      "87  train loss:  0.20750343799591064\n",
      "88  train loss:  0.2086872011423111\n",
      "89  train loss:  0.20853492617607117\n",
      "90  train loss:  0.20734316110610962\n",
      "91  train loss:  0.2061237096786499\n",
      "92  train loss:  0.20658430457115173\n",
      "93  train loss:  0.20666159689426422\n",
      "94  train loss:  0.2031976580619812\n",
      "95  train loss:  0.20485612750053406\n",
      "96  train loss:  0.20249812304973602\n",
      "97  train loss:  0.20544640719890594\n",
      "98  train loss:  0.20204097032546997\n",
      "99  train loss:  0.20193858444690704\n",
      "test acc (%):  tensor(79.0902)\n",
      "0  train loss:  0.4451310634613037\n",
      "1  train loss:  0.4295292794704437\n",
      "2  train loss:  0.4028988182544708\n",
      "3  train loss:  0.3912302255630493\n",
      "4  train loss:  0.3752802312374115\n",
      "5  train loss:  0.3589131236076355\n",
      "6  train loss:  0.34874188899993896\n",
      "7  train loss:  0.33463677763938904\n",
      "8  train loss:  0.3477628827095032\n",
      "9  train loss:  0.35679206252098083\n",
      "10  train loss:  0.34720170497894287\n",
      "11  train loss:  0.34059131145477295\n",
      "12  train loss:  0.3336506485939026\n",
      "13  train loss:  0.31815293431282043\n",
      "14  train loss:  0.313255250453949\n",
      "15  train loss:  0.31653082370758057\n",
      "16  train loss:  0.3080006241798401\n",
      "17  train loss:  0.3078891634941101\n",
      "18  train loss:  0.30285561084747314\n",
      "19  train loss:  0.29929637908935547\n",
      "20  train loss:  0.2987936735153198\n",
      "21  train loss:  0.30348798632621765\n",
      "22  train loss:  0.29712241888046265\n",
      "23  train loss:  0.30364733934402466\n",
      "24  train loss:  0.307890921831131\n",
      "25  train loss:  0.28990936279296875\n",
      "26  train loss:  0.2898003160953522\n",
      "27  train loss:  0.2809188663959503\n",
      "28  train loss:  0.27897390723228455\n",
      "29  train loss:  0.28223520517349243\n",
      "30  train loss:  0.2794899642467499\n",
      "31  train loss:  0.2774088382720947\n",
      "32  train loss:  0.2754817008972168\n",
      "33  train loss:  0.27735039591789246\n",
      "34  train loss:  0.27312126755714417\n",
      "35  train loss:  0.2666993737220764\n",
      "36  train loss:  0.2651035785675049\n",
      "37  train loss:  0.2719047963619232\n",
      "38  train loss:  0.26428303122520447\n",
      "39  train loss:  0.26090875267982483\n",
      "40  train loss:  0.261447548866272\n",
      "41  train loss:  0.27041786909103394\n",
      "42  train loss:  0.27104780077934265\n",
      "43  train loss:  0.26710015535354614\n",
      "44  train loss:  0.27281415462493896\n",
      "45  train loss:  0.26759257912635803\n",
      "46  train loss:  0.2642282545566559\n",
      "47  train loss:  0.2656734883785248\n",
      "48  train loss:  0.2679886519908905\n",
      "49  train loss:  0.2650209665298462\n",
      "50  train loss:  0.2632666826248169\n",
      "51  train loss:  0.26808205246925354\n",
      "52  train loss:  0.26380038261413574\n",
      "53  train loss:  0.2640002369880676\n",
      "54  train loss:  0.25859785079956055\n",
      "55  train loss:  0.2555222809314728\n",
      "56  train loss:  0.2538830041885376\n",
      "57  train loss:  0.25323286652565\n",
      "58  train loss:  0.2502414882183075\n",
      "59  train loss:  0.2486543506383896\n",
      "60  train loss:  0.2463967204093933\n",
      "61  train loss:  0.24477098882198334\n",
      "62  train loss:  0.2415374219417572\n",
      "63  train loss:  0.24564607441425323\n",
      "64  train loss:  0.24632517993450165\n",
      "65  train loss:  0.24373573064804077\n",
      "66  train loss:  0.24260713160037994\n",
      "67  train loss:  0.24102413654327393\n",
      "68  train loss:  0.23622366786003113\n",
      "69  train loss:  0.23705467581748962\n",
      "70  train loss:  0.23409903049468994\n",
      "71  train loss:  0.2310420572757721\n",
      "72  train loss:  0.22805365920066833\n",
      "73  train loss:  0.22678758203983307\n",
      "74  train loss:  0.2258816808462143\n",
      "75  train loss:  0.22513186931610107\n",
      "76  train loss:  0.22260360419750214\n",
      "77  train loss:  0.22084921598434448\n",
      "78  train loss:  0.21948030591011047\n",
      "79  train loss:  0.217881977558136\n",
      "80  train loss:  0.21716943383216858\n",
      "81  train loss:  0.21564166247844696\n",
      "82  train loss:  0.21610434353351593\n",
      "83  train loss:  0.21526816487312317\n",
      "84  train loss:  0.2150173932313919\n",
      "85  train loss:  0.22015538811683655\n",
      "86  train loss:  0.21612681448459625\n",
      "87  train loss:  0.2204558402299881\n",
      "88  train loss:  0.2160191386938095\n",
      "89  train loss:  0.21588543057441711\n",
      "90  train loss:  0.21385115385055542\n",
      "91  train loss:  0.2147468626499176\n",
      "92  train loss:  0.21234974265098572\n",
      "93  train loss:  0.2103717178106308\n",
      "94  train loss:  0.214753657579422\n",
      "95  train loss:  0.21024738252162933\n",
      "96  train loss:  0.20807160437107086\n",
      "97  train loss:  0.21039870381355286\n",
      "98  train loss:  0.21985214948654175\n",
      "99  train loss:  0.21350984275341034\n",
      "test acc (%):  tensor(76.8704)\n",
      "0  train loss:  0.4677742123603821\n",
      "1  train loss:  0.4460446834564209\n",
      "2  train loss:  0.43040114641189575\n",
      "3  train loss:  0.4125473201274872\n",
      "4  train loss:  0.3970625102519989\n",
      "5  train loss:  0.3941931426525116\n",
      "6  train loss:  0.38784030079841614\n",
      "7  train loss:  0.38869574666023254\n",
      "8  train loss:  0.37420180439949036\n",
      "9  train loss:  0.3758890628814697\n",
      "10  train loss:  0.36691680550575256\n",
      "11  train loss:  0.36652958393096924\n",
      "12  train loss:  0.3590056598186493\n",
      "13  train loss:  0.3522276282310486\n",
      "14  train loss:  0.3478314280509949\n",
      "15  train loss:  0.3444328010082245\n",
      "16  train loss:  0.3372148275375366\n",
      "17  train loss:  0.33577096462249756\n",
      "18  train loss:  0.3325837552547455\n",
      "19  train loss:  0.3323459029197693\n",
      "20  train loss:  0.32292062044143677\n",
      "21  train loss:  0.3233198821544647\n",
      "22  train loss:  0.31880226731300354\n",
      "23  train loss:  0.3107069134712219\n",
      "24  train loss:  0.3101332485675812\n",
      "25  train loss:  0.30627408623695374\n",
      "26  train loss:  0.30181562900543213\n",
      "27  train loss:  0.3021739423274994\n",
      "28  train loss:  0.2996121048927307\n",
      "29  train loss:  0.29646533727645874\n",
      "30  train loss:  0.2943793535232544\n",
      "31  train loss:  0.2905271649360657\n",
      "32  train loss:  0.2889712452888489\n",
      "33  train loss:  0.29139789938926697\n",
      "34  train loss:  0.2937801778316498\n",
      "35  train loss:  0.2876910865306854\n",
      "36  train loss:  0.28454259037971497\n",
      "37  train loss:  0.2887081205844879\n",
      "38  train loss:  0.2864105701446533\n",
      "39  train loss:  0.29509177803993225\n",
      "40  train loss:  0.28301456570625305\n",
      "41  train loss:  0.29448267817497253\n",
      "42  train loss:  0.2810016870498657\n",
      "43  train loss:  0.2866554856300354\n",
      "44  train loss:  0.3074970543384552\n",
      "45  train loss:  0.2789519429206848\n",
      "46  train loss:  0.300258070230484\n",
      "47  train loss:  0.2963522672653198\n",
      "48  train loss:  0.28104737401008606\n",
      "49  train loss:  0.3050152063369751\n",
      "50  train loss:  0.30480650067329407\n",
      "51  train loss:  0.3006786108016968\n",
      "52  train loss:  0.29724857211112976\n",
      "53  train loss:  0.2896556854248047\n",
      "54  train loss:  0.2787023186683655\n",
      "55  train loss:  0.2757076919078827\n",
      "56  train loss:  0.28064030408859253\n",
      "57  train loss:  0.28230971097946167\n",
      "58  train loss:  0.27261853218078613\n",
      "59  train loss:  0.26912859082221985\n",
      "60  train loss:  0.27094465494155884\n",
      "61  train loss:  0.2795695662498474\n",
      "62  train loss:  0.27067235112190247\n",
      "63  train loss:  0.26253795623779297\n",
      "64  train loss:  0.26889482140541077\n",
      "65  train loss:  0.263278067111969\n",
      "66  train loss:  0.26336467266082764\n",
      "67  train loss:  0.26269468665122986\n",
      "68  train loss:  0.25880900025367737\n",
      "69  train loss:  0.2576262950897217\n",
      "70  train loss:  0.2594660222530365\n",
      "71  train loss:  0.2675066590309143\n",
      "72  train loss:  0.2667556703090668\n",
      "73  train loss:  0.2548709809780121\n",
      "74  train loss:  0.2617795169353485\n",
      "75  train loss:  0.27148333191871643\n",
      "76  train loss:  0.26799145340919495\n",
      "77  train loss:  0.2650761008262634\n",
      "78  train loss:  0.2631809115409851\n",
      "79  train loss:  0.26269060373306274\n",
      "80  train loss:  0.2580431401729584\n",
      "81  train loss:  0.2561482787132263\n",
      "82  train loss:  0.2506936192512512\n",
      "83  train loss:  0.2586478888988495\n",
      "84  train loss:  0.2584304213523865\n",
      "85  train loss:  0.263276606798172\n",
      "86  train loss:  0.2598586082458496\n",
      "87  train loss:  0.2525641620159149\n",
      "88  train loss:  0.25328266620635986\n",
      "89  train loss:  0.2563129663467407\n",
      "90  train loss:  0.25524473190307617\n",
      "91  train loss:  0.2518053352832794\n",
      "92  train loss:  0.25189903378486633\n",
      "93  train loss:  0.25012972950935364\n",
      "94  train loss:  0.247123584151268\n",
      "95  train loss:  0.2462533712387085\n",
      "96  train loss:  0.24650534987449646\n",
      "97  train loss:  0.2444082498550415\n",
      "98  train loss:  0.24326805770397186\n",
      "99  train loss:  0.24267780780792236\n",
      "test acc (%):  tensor(77.9118)\n",
      "0  train loss:  0.40547481179237366\n",
      "1  train loss:  0.3818855583667755\n",
      "2  train loss:  0.3803645968437195\n",
      "3  train loss:  0.36000245809555054\n",
      "4  train loss:  0.3341984748840332\n",
      "5  train loss:  0.32031551003456116\n",
      "6  train loss:  0.3167188763618469\n",
      "7  train loss:  0.3175807297229767\n",
      "8  train loss:  0.31487879157066345\n",
      "9  train loss:  0.31196680665016174\n",
      "10  train loss:  0.29473787546157837\n",
      "11  train loss:  0.28777721524238586\n",
      "12  train loss:  0.286457896232605\n",
      "13  train loss:  0.2851566672325134\n",
      "14  train loss:  0.2790411114692688\n",
      "15  train loss:  0.2650667726993561\n",
      "16  train loss:  0.26674965023994446\n",
      "17  train loss:  0.25826022028923035\n",
      "18  train loss:  0.2524581849575043\n",
      "19  train loss:  0.24773824214935303\n",
      "20  train loss:  0.24330833554267883\n",
      "21  train loss:  0.24230602383613586\n",
      "22  train loss:  0.24116256833076477\n",
      "23  train loss:  0.2383064329624176\n",
      "24  train loss:  0.23371601104736328\n",
      "25  train loss:  0.23125705122947693\n",
      "26  train loss:  0.23283283412456512\n",
      "27  train loss:  0.22808873653411865\n",
      "28  train loss:  0.22870871424674988\n",
      "29  train loss:  0.22714270651340485\n",
      "30  train loss:  0.22562438249588013\n",
      "31  train loss:  0.22708962857723236\n",
      "32  train loss:  0.2218719869852066\n",
      "33  train loss:  0.22456094622612\n",
      "34  train loss:  0.2239733338356018\n",
      "35  train loss:  0.21999192237854004\n",
      "36  train loss:  0.218239888548851\n",
      "37  train loss:  0.21670010685920715\n",
      "38  train loss:  0.21632714569568634\n",
      "39  train loss:  0.21454843878746033\n",
      "40  train loss:  0.2128119021654129\n",
      "41  train loss:  0.21124136447906494\n",
      "42  train loss:  0.20996859669685364\n",
      "43  train loss:  0.20874780416488647\n",
      "44  train loss:  0.20673879981040955\n",
      "45  train loss:  0.20575599372386932\n",
      "46  train loss:  0.20633259415626526\n",
      "47  train loss:  0.20682770013809204\n",
      "48  train loss:  0.20433783531188965\n",
      "49  train loss:  0.2036176174879074\n",
      "50  train loss:  0.203518345952034\n",
      "51  train loss:  0.20254743099212646\n",
      "52  train loss:  0.2023269385099411\n",
      "53  train loss:  0.20069032907485962\n",
      "54  train loss:  0.2013763040304184\n",
      "55  train loss:  0.19942715764045715\n",
      "56  train loss:  0.2003810554742813\n",
      "57  train loss:  0.1988854706287384\n",
      "58  train loss:  0.1991090625524521\n",
      "59  train loss:  0.1980331540107727\n",
      "60  train loss:  0.19706863164901733\n",
      "61  train loss:  0.1960252970457077\n",
      "62  train loss:  0.19571468234062195\n",
      "63  train loss:  0.19512952864170074\n",
      "64  train loss:  0.19418881833553314\n",
      "65  train loss:  0.1936882734298706\n",
      "66  train loss:  0.19319626688957214\n",
      "67  train loss:  0.19346469640731812\n",
      "68  train loss:  0.19263271987438202\n",
      "69  train loss:  0.19235606491565704\n",
      "70  train loss:  0.1919385939836502\n",
      "71  train loss:  0.191578671336174\n",
      "72  train loss:  0.1911107748746872\n",
      "73  train loss:  0.190604105591774\n",
      "74  train loss:  0.19009922444820404\n",
      "75  train loss:  0.18992310762405396\n",
      "76  train loss:  0.18926484882831573\n",
      "77  train loss:  0.18886128067970276\n",
      "78  train loss:  0.18842916190624237\n",
      "79  train loss:  0.18952807784080505\n",
      "80  train loss:  0.18854263424873352\n",
      "81  train loss:  0.18750905990600586\n",
      "82  train loss:  0.18700148165225983\n",
      "83  train loss:  0.185965433716774\n",
      "84  train loss:  0.1848178654909134\n",
      "85  train loss:  0.18420763313770294\n",
      "86  train loss:  0.18373362720012665\n",
      "87  train loss:  0.18314896523952484\n",
      "88  train loss:  0.18257686495780945\n",
      "89  train loss:  0.18211732804775238\n",
      "90  train loss:  0.18207281827926636\n",
      "91  train loss:  0.18158605694770813\n",
      "92  train loss:  0.18094657361507416\n",
      "93  train loss:  0.18144913017749786\n",
      "94  train loss:  0.18004944920539856\n",
      "95  train loss:  0.17991986870765686\n",
      "96  train loss:  0.17926529049873352\n",
      "97  train loss:  0.1790277510881424\n",
      "98  train loss:  0.17837169766426086\n",
      "99  train loss:  0.17806687951087952\n",
      "test acc (%):  tensor(78.1036)\n",
      "0  train loss:  0.4586137533187866\n",
      "1  train loss:  0.42223191261291504\n",
      "2  train loss:  0.39375951886177063\n",
      "3  train loss:  0.37449222803115845\n",
      "4  train loss:  0.34700652956962585\n",
      "5  train loss:  0.3498592674732208\n",
      "6  train loss:  0.33495503664016724\n",
      "7  train loss:  0.32383036613464355\n",
      "8  train loss:  0.33574700355529785\n",
      "9  train loss:  0.31567686796188354\n",
      "10  train loss:  0.30088868737220764\n",
      "11  train loss:  0.30321115255355835\n",
      "12  train loss:  0.30284231901168823\n",
      "13  train loss:  0.29690781235694885\n",
      "14  train loss:  0.29865211248397827\n",
      "15  train loss:  0.2930506467819214\n",
      "16  train loss:  0.283413827419281\n",
      "17  train loss:  0.2757231891155243\n",
      "18  train loss:  0.27516064047813416\n",
      "19  train loss:  0.2726483643054962\n",
      "20  train loss:  0.281974732875824\n",
      "21  train loss:  0.2734157145023346\n",
      "22  train loss:  0.26921287178993225\n",
      "23  train loss:  0.28192469477653503\n",
      "24  train loss:  0.25992318987846375\n",
      "25  train loss:  0.2629201412200928\n",
      "26  train loss:  0.25767239928245544\n",
      "27  train loss:  0.2549654543399811\n",
      "28  train loss:  0.2628282904624939\n",
      "29  train loss:  0.2513691782951355\n",
      "30  train loss:  0.24826370179653168\n",
      "31  train loss:  0.24299918115139008\n",
      "32  train loss:  0.2368461787700653\n",
      "33  train loss:  0.2373693287372589\n",
      "34  train loss:  0.23699906468391418\n",
      "35  train loss:  0.23489360511302948\n",
      "36  train loss:  0.23286184668540955\n",
      "37  train loss:  0.23038774728775024\n",
      "38  train loss:  0.22761639952659607\n",
      "39  train loss:  0.22543856501579285\n",
      "40  train loss:  0.22530443966388702\n",
      "41  train loss:  0.22419287264347076\n",
      "42  train loss:  0.22059588134288788\n",
      "43  train loss:  0.22109830379486084\n",
      "44  train loss:  0.21826429665088654\n",
      "45  train loss:  0.21867813169956207\n",
      "46  train loss:  0.21696613729000092\n",
      "47  train loss:  0.21556593477725983\n",
      "48  train loss:  0.21383629739284515\n",
      "49  train loss:  0.21319261193275452\n",
      "50  train loss:  0.21266931295394897\n",
      "51  train loss:  0.21254198253154755\n",
      "52  train loss:  0.21067173779010773\n",
      "53  train loss:  0.21025371551513672\n",
      "54  train loss:  0.20888225734233856\n",
      "55  train loss:  0.20852600038051605\n",
      "56  train loss:  0.2075686752796173\n",
      "57  train loss:  0.20774056017398834\n",
      "58  train loss:  0.2061375081539154\n",
      "59  train loss:  0.20496465265750885\n",
      "60  train loss:  0.20458665490150452\n",
      "61  train loss:  0.20406706631183624\n",
      "62  train loss:  0.20389488339424133\n",
      "63  train loss:  0.20325179398059845\n",
      "64  train loss:  0.20230995118618011\n",
      "65  train loss:  0.20136475563049316\n",
      "66  train loss:  0.201157346367836\n",
      "67  train loss:  0.20072335004806519\n",
      "68  train loss:  0.1998889297246933\n",
      "69  train loss:  0.19979441165924072\n",
      "70  train loss:  0.19911028444766998\n",
      "71  train loss:  0.19863402843475342\n",
      "72  train loss:  0.19829493761062622\n",
      "73  train loss:  0.19774195551872253\n",
      "74  train loss:  0.19732551276683807\n",
      "75  train loss:  0.1971273422241211\n",
      "76  train loss:  0.19646227359771729\n",
      "77  train loss:  0.1962224245071411\n",
      "78  train loss:  0.19572974741458893\n",
      "79  train loss:  0.19517560303211212\n",
      "80  train loss:  0.19502204656600952\n",
      "81  train loss:  0.19418953359127045\n",
      "82  train loss:  0.19378025829792023\n",
      "83  train loss:  0.193839892745018\n",
      "84  train loss:  0.1940736174583435\n",
      "85  train loss:  0.1962200254201889\n",
      "86  train loss:  0.19314518570899963\n",
      "87  train loss:  0.19472628831863403\n",
      "88  train loss:  0.19254006445407867\n",
      "89  train loss:  0.19382858276367188\n",
      "90  train loss:  0.1919516623020172\n",
      "91  train loss:  0.19683147966861725\n",
      "92  train loss:  0.19815818965435028\n",
      "93  train loss:  0.19317111372947693\n",
      "94  train loss:  0.19819970428943634\n",
      "95  train loss:  0.20827874541282654\n",
      "96  train loss:  0.19222350418567657\n",
      "97  train loss:  0.20043648779392242\n",
      "98  train loss:  0.19381611049175262\n",
      "99  train loss:  0.1971062272787094\n",
      "test acc (%):  tensor(77.1718)\n",
      "0  train loss:  0.4644729197025299\n",
      "1  train loss:  0.4357273578643799\n",
      "2  train loss:  0.4055013656616211\n",
      "3  train loss:  0.37882283329963684\n",
      "4  train loss:  0.39161235094070435\n",
      "5  train loss:  0.3806828260421753\n",
      "6  train loss:  0.34812676906585693\n",
      "7  train loss:  0.3497495651245117\n",
      "8  train loss:  0.3456684947013855\n",
      "9  train loss:  0.34206730127334595\n",
      "10  train loss:  0.3336562514305115\n",
      "11  train loss:  0.326116681098938\n",
      "12  train loss:  0.3141231834888458\n",
      "13  train loss:  0.30701059103012085\n",
      "14  train loss:  0.3139180541038513\n",
      "15  train loss:  0.31490054726600647\n",
      "16  train loss:  0.3080276548862457\n",
      "17  train loss:  0.3057102859020233\n",
      "18  train loss:  0.2967655062675476\n",
      "19  train loss:  0.2894846200942993\n",
      "20  train loss:  0.2822968661785126\n",
      "21  train loss:  0.28157562017440796\n",
      "22  train loss:  0.28319448232650757\n",
      "23  train loss:  0.284559965133667\n",
      "24  train loss:  0.278464674949646\n",
      "25  train loss:  0.274172842502594\n",
      "26  train loss:  0.27462056279182434\n",
      "27  train loss:  0.2680550515651703\n",
      "28  train loss:  0.2714344263076782\n",
      "29  train loss:  0.26153215765953064\n",
      "30  train loss:  0.2624252438545227\n",
      "31  train loss:  0.2585226893424988\n",
      "32  train loss:  0.2583727538585663\n",
      "33  train loss:  0.25487020611763\n",
      "34  train loss:  0.24884717166423798\n",
      "35  train loss:  0.24566765129566193\n",
      "36  train loss:  0.2446088194847107\n",
      "37  train loss:  0.24571113288402557\n",
      "38  train loss:  0.24516984820365906\n",
      "39  train loss:  0.23906713724136353\n",
      "40  train loss:  0.24309112131595612\n",
      "41  train loss:  0.24266012012958527\n",
      "42  train loss:  0.2402607500553131\n",
      "43  train loss:  0.2441639006137848\n",
      "44  train loss:  0.24067051708698273\n",
      "45  train loss:  0.2308790236711502\n",
      "46  train loss:  0.2319556176662445\n",
      "47  train loss:  0.22931765019893646\n",
      "48  train loss:  0.22630636394023895\n",
      "49  train loss:  0.22956915199756622\n",
      "50  train loss:  0.22642068564891815\n",
      "51  train loss:  0.2237456887960434\n",
      "52  train loss:  0.22205747663974762\n",
      "53  train loss:  0.2197679728269577\n",
      "54  train loss:  0.21485160291194916\n",
      "55  train loss:  0.21493758261203766\n",
      "56  train loss:  0.21427053213119507\n",
      "57  train loss:  0.21114444732666016\n",
      "58  train loss:  0.2111639529466629\n",
      "59  train loss:  0.2105051428079605\n",
      "60  train loss:  0.20949140191078186\n",
      "61  train loss:  0.20710048079490662\n",
      "62  train loss:  0.206773579120636\n",
      "63  train loss:  0.20467792451381683\n",
      "64  train loss:  0.20472218096256256\n",
      "65  train loss:  0.20331791043281555\n",
      "66  train loss:  0.20203830301761627\n",
      "67  train loss:  0.20185749232769012\n",
      "68  train loss:  0.20145919919013977\n",
      "69  train loss:  0.19954949617385864\n",
      "70  train loss:  0.19881874322891235\n",
      "71  train loss:  0.19853843748569489\n",
      "72  train loss:  0.19724874198436737\n",
      "73  train loss:  0.19663238525390625\n",
      "74  train loss:  0.19662344455718994\n",
      "75  train loss:  0.1971888542175293\n",
      "76  train loss:  0.19561269879341125\n",
      "77  train loss:  0.19651974737644196\n",
      "78  train loss:  0.19407211244106293\n",
      "79  train loss:  0.19353853166103363\n",
      "80  train loss:  0.19374051690101624\n",
      "81  train loss:  0.1924370527267456\n",
      "82  train loss:  0.1922382265329361\n",
      "83  train loss:  0.1916634738445282\n",
      "84  train loss:  0.19109825789928436\n",
      "85  train loss:  0.19091251492500305\n",
      "86  train loss:  0.19026167690753937\n",
      "87  train loss:  0.18938744068145752\n",
      "88  train loss:  0.188860684633255\n",
      "89  train loss:  0.18881136178970337\n",
      "90  train loss:  0.1886155754327774\n",
      "91  train loss:  0.18725194036960602\n",
      "92  train loss:  0.18685083091259003\n",
      "93  train loss:  0.18667663633823395\n",
      "94  train loss:  0.18603986501693726\n",
      "95  train loss:  0.18829704821109772\n",
      "96  train loss:  0.1860860139131546\n",
      "97  train loss:  0.18707852065563202\n",
      "98  train loss:  0.18546541035175323\n",
      "99  train loss:  0.18511199951171875\n",
      "test acc (%):  tensor(77.5281)\n",
      "0  train loss:  0.5156555771827698\n",
      "1  train loss:  0.4841606914997101\n",
      "2  train loss:  0.46726056933403015\n",
      "3  train loss:  0.44092920422554016\n",
      "4  train loss:  0.4226965010166168\n",
      "5  train loss:  0.3977244794368744\n",
      "6  train loss:  0.3805127739906311\n",
      "7  train loss:  0.365276038646698\n",
      "8  train loss:  0.36025646328926086\n",
      "9  train loss:  0.3564487397670746\n",
      "10  train loss:  0.34363725781440735\n",
      "11  train loss:  0.32728931307792664\n",
      "12  train loss:  0.3261294364929199\n",
      "13  train loss:  0.31938713788986206\n",
      "14  train loss:  0.30494314432144165\n",
      "15  train loss:  0.2961772084236145\n",
      "16  train loss:  0.2941837012767792\n",
      "17  train loss:  0.2873573303222656\n",
      "18  train loss:  0.28421810269355774\n",
      "19  train loss:  0.28358083963394165\n",
      "20  train loss:  0.28146278858184814\n",
      "21  train loss:  0.2823822498321533\n",
      "22  train loss:  0.2773292660713196\n",
      "23  train loss:  0.2733428478240967\n",
      "24  train loss:  0.2692781686782837\n",
      "25  train loss:  0.2642950713634491\n",
      "26  train loss:  0.26426786184310913\n",
      "27  train loss:  0.2616463303565979\n",
      "28  train loss:  0.2574818730354309\n",
      "29  train loss:  0.25442469120025635\n",
      "30  train loss:  0.2541208565235138\n",
      "31  train loss:  0.24982406198978424\n",
      "32  train loss:  0.2471483200788498\n",
      "33  train loss:  0.24328535795211792\n",
      "34  train loss:  0.2416038066148758\n",
      "35  train loss:  0.2389916479587555\n",
      "36  train loss:  0.23584622144699097\n",
      "37  train loss:  0.2323354035615921\n",
      "38  train loss:  0.232569620013237\n",
      "39  train loss:  0.2323610782623291\n",
      "40  train loss:  0.2289261370897293\n",
      "41  train loss:  0.2257314920425415\n",
      "42  train loss:  0.2238149344921112\n",
      "43  train loss:  0.22122739255428314\n",
      "44  train loss:  0.2201385796070099\n",
      "45  train loss:  0.2177463322877884\n",
      "46  train loss:  0.21771258115768433\n",
      "47  train loss:  0.2153191864490509\n",
      "48  train loss:  0.2138431966304779\n",
      "49  train loss:  0.21228154003620148\n",
      "50  train loss:  0.21063129603862762\n",
      "51  train loss:  0.20997126400470734\n",
      "52  train loss:  0.2100345343351364\n",
      "53  train loss:  0.2081041932106018\n",
      "54  train loss:  0.2079184502363205\n",
      "55  train loss:  0.20671279728412628\n",
      "56  train loss:  0.20520271360874176\n",
      "57  train loss:  0.2042294293642044\n",
      "58  train loss:  0.2030285894870758\n",
      "59  train loss:  0.20151983201503754\n",
      "60  train loss:  0.20098459720611572\n",
      "61  train loss:  0.19933432340621948\n",
      "62  train loss:  0.19910116493701935\n",
      "63  train loss:  0.19875644147396088\n",
      "64  train loss:  0.19701305031776428\n",
      "65  train loss:  0.19723959267139435\n",
      "66  train loss:  0.19540826976299286\n",
      "67  train loss:  0.19436217844486237\n",
      "68  train loss:  0.19417987763881683\n",
      "69  train loss:  0.19309002161026\n",
      "70  train loss:  0.1923559606075287\n",
      "71  train loss:  0.1910630166530609\n",
      "72  train loss:  0.18962670862674713\n",
      "73  train loss:  0.18919412791728973\n",
      "74  train loss:  0.18799345195293427\n",
      "75  train loss:  0.18709634244441986\n",
      "76  train loss:  0.1861247718334198\n",
      "77  train loss:  0.18731456995010376\n",
      "78  train loss:  0.19122005999088287\n",
      "79  train loss:  0.19608746469020844\n",
      "80  train loss:  0.1900644600391388\n",
      "81  train loss:  0.1873943954706192\n",
      "82  train loss:  0.18876199424266815\n",
      "83  train loss:  0.1923189014196396\n",
      "84  train loss:  0.18742316961288452\n",
      "85  train loss:  0.1868223249912262\n",
      "86  train loss:  0.1901673674583435\n",
      "87  train loss:  0.1876063346862793\n",
      "88  train loss:  0.1853957325220108\n",
      "89  train loss:  0.1881798356771469\n",
      "90  train loss:  0.1887742280960083\n",
      "91  train loss:  0.18760167062282562\n",
      "92  train loss:  0.1836036890745163\n",
      "93  train loss:  0.18661059439182281\n",
      "94  train loss:  0.18473514914512634\n",
      "95  train loss:  0.18148891627788544\n",
      "96  train loss:  0.18349269032478333\n",
      "97  train loss:  0.1915198713541031\n",
      "98  train loss:  0.18677294254302979\n",
      "99  train loss:  0.1836380660533905\n",
      "test acc (%):  tensor(76.5141)\n",
      "0  train loss:  0.43566805124282837\n",
      "1  train loss:  0.3618374168872833\n",
      "2  train loss:  0.32986196875572205\n",
      "3  train loss:  0.3151432275772095\n",
      "4  train loss:  0.3063737452030182\n",
      "5  train loss:  0.2981800436973572\n",
      "6  train loss:  0.28157761693000793\n",
      "7  train loss:  0.26863792538642883\n",
      "8  train loss:  0.28286394476890564\n",
      "9  train loss:  0.2695731818675995\n",
      "10  train loss:  0.2650517523288727\n",
      "11  train loss:  0.2541782855987549\n",
      "12  train loss:  0.2438531070947647\n",
      "13  train loss:  0.2424580156803131\n",
      "14  train loss:  0.23906610906124115\n",
      "15  train loss:  0.23870240151882172\n",
      "16  train loss:  0.23100930452346802\n",
      "17  train loss:  0.2254469394683838\n",
      "18  train loss:  0.2251540571451187\n",
      "19  train loss:  0.21916863322257996\n",
      "20  train loss:  0.21854040026664734\n",
      "21  train loss:  0.21780696511268616\n",
      "22  train loss:  0.21430712938308716\n",
      "23  train loss:  0.21018342673778534\n",
      "24  train loss:  0.2069464772939682\n",
      "25  train loss:  0.20561961829662323\n",
      "26  train loss:  0.2044229507446289\n",
      "27  train loss:  0.20169314742088318\n",
      "28  train loss:  0.19998721778392792\n",
      "29  train loss:  0.1984725445508957\n",
      "30  train loss:  0.1961989402770996\n",
      "31  train loss:  0.19464261829853058\n",
      "32  train loss:  0.1927752047777176\n",
      "33  train loss:  0.19382011890411377\n",
      "34  train loss:  0.1913018822669983\n",
      "35  train loss:  0.1910962462425232\n",
      "36  train loss:  0.19259963929653168\n",
      "37  train loss:  0.19373489916324615\n",
      "38  train loss:  0.1877661645412445\n",
      "39  train loss:  0.19620256125926971\n",
      "40  train loss:  0.19837582111358643\n",
      "41  train loss:  0.1925082951784134\n",
      "42  train loss:  0.19052675366401672\n",
      "43  train loss:  0.18845775723457336\n",
      "44  train loss:  0.19393913447856903\n",
      "45  train loss:  0.1910964995622635\n",
      "46  train loss:  0.18606165051460266\n",
      "47  train loss:  0.18925133347511292\n",
      "48  train loss:  0.1869225800037384\n",
      "49  train loss:  0.1839345246553421\n",
      "50  train loss:  0.18446679413318634\n",
      "51  train loss:  0.18449179828166962\n",
      "52  train loss:  0.18486757576465607\n",
      "53  train loss:  0.18348312377929688\n",
      "54  train loss:  0.18165913224220276\n",
      "55  train loss:  0.1821650266647339\n",
      "56  train loss:  0.17952542006969452\n",
      "57  train loss:  0.1790185570716858\n",
      "58  train loss:  0.17858944833278656\n",
      "59  train loss:  0.1765301376581192\n",
      "60  train loss:  0.17604093253612518\n",
      "61  train loss:  0.1737941950559616\n",
      "62  train loss:  0.17301902174949646\n",
      "63  train loss:  0.17266441881656647\n",
      "64  train loss:  0.1705465018749237\n",
      "65  train loss:  0.17011918127536774\n",
      "66  train loss:  0.17013435065746307\n",
      "67  train loss:  0.16852115094661713\n",
      "68  train loss:  0.167363241314888\n",
      "69  train loss:  0.16737055778503418\n",
      "70  train loss:  0.16579224169254303\n",
      "71  train loss:  0.16565249860286713\n",
      "72  train loss:  0.16441909968852997\n",
      "73  train loss:  0.16423438489437103\n",
      "74  train loss:  0.16341611742973328\n",
      "75  train loss:  0.16262176632881165\n",
      "76  train loss:  0.1619100570678711\n",
      "77  train loss:  0.1613548845052719\n",
      "78  train loss:  0.1609051525592804\n",
      "79  train loss:  0.16028057038784027\n",
      "80  train loss:  0.15982937812805176\n",
      "81  train loss:  0.15923944115638733\n",
      "82  train loss:  0.15819048881530762\n",
      "83  train loss:  0.15759089589118958\n",
      "84  train loss:  0.15667131543159485\n",
      "85  train loss:  0.15562127530574799\n",
      "86  train loss:  0.15484589338302612\n",
      "87  train loss:  0.15426968038082123\n",
      "88  train loss:  0.15360914170742035\n",
      "89  train loss:  0.15306982398033142\n",
      "90  train loss:  0.15274350345134735\n",
      "91  train loss:  0.15194746851921082\n",
      "92  train loss:  0.15149210393428802\n",
      "93  train loss:  0.1509888619184494\n",
      "94  train loss:  0.1504991054534912\n",
      "95  train loss:  0.15006649494171143\n",
      "96  train loss:  0.14959922432899475\n",
      "97  train loss:  0.14914663136005402\n",
      "98  train loss:  0.14874480664730072\n",
      "99  train loss:  0.14826872944831848\n",
      "test acc (%):  tensor(78.3228)\n",
      "0  train loss:  0.4982554018497467\n",
      "1  train loss:  0.4589882493019104\n",
      "2  train loss:  0.42878472805023193\n",
      "3  train loss:  0.3962772488594055\n",
      "4  train loss:  0.37889808416366577\n",
      "5  train loss:  0.37092968821525574\n",
      "6  train loss:  0.36563608050346375\n",
      "7  train loss:  0.3641812801361084\n",
      "8  train loss:  0.35599538683891296\n",
      "9  train loss:  0.3352689743041992\n",
      "10  train loss:  0.3324826955795288\n",
      "11  train loss:  0.3267662227153778\n",
      "12  train loss:  0.3137504458427429\n",
      "13  train loss:  0.3115660548210144\n",
      "14  train loss:  0.30428311228752136\n",
      "15  train loss:  0.3000617027282715\n",
      "16  train loss:  0.2922336459159851\n",
      "17  train loss:  0.28768450021743774\n",
      "18  train loss:  0.28034543991088867\n",
      "19  train loss:  0.2706077992916107\n",
      "20  train loss:  0.2725544273853302\n",
      "21  train loss:  0.26875758171081543\n",
      "22  train loss:  0.25841790437698364\n",
      "23  train loss:  0.25510072708129883\n",
      "24  train loss:  0.25240358710289\n",
      "25  train loss:  0.24838508665561676\n",
      "26  train loss:  0.24360598623752594\n",
      "27  train loss:  0.2417275756597519\n",
      "28  train loss:  0.239613339304924\n",
      "29  train loss:  0.23627367615699768\n",
      "30  train loss:  0.23454703390598297\n",
      "31  train loss:  0.23208272457122803\n",
      "32  train loss:  0.23109902441501617\n",
      "33  train loss:  0.2276414930820465\n",
      "34  train loss:  0.2256193310022354\n",
      "35  train loss:  0.2237078994512558\n",
      "36  train loss:  0.22141975164413452\n",
      "37  train loss:  0.22022220492362976\n",
      "38  train loss:  0.21720358729362488\n",
      "39  train loss:  0.21978552639484406\n",
      "40  train loss:  0.21623879671096802\n",
      "41  train loss:  0.215580552816391\n",
      "42  train loss:  0.21493613719940186\n",
      "43  train loss:  0.21354873478412628\n",
      "44  train loss:  0.21146254241466522\n",
      "45  train loss:  0.21008388698101044\n",
      "46  train loss:  0.21026568114757538\n",
      "47  train loss:  0.20699335634708405\n",
      "48  train loss:  0.2063630223274231\n",
      "49  train loss:  0.20513878762722015\n",
      "50  train loss:  0.20335069298744202\n",
      "51  train loss:  0.2022632658481598\n",
      "52  train loss:  0.20180737972259521\n",
      "53  train loss:  0.20333093404769897\n",
      "54  train loss:  0.19995439052581787\n",
      "55  train loss:  0.2027958631515503\n",
      "56  train loss:  0.2008606195449829\n",
      "57  train loss:  0.19852934777736664\n",
      "58  train loss:  0.19774939119815826\n",
      "59  train loss:  0.1960894614458084\n",
      "60  train loss:  0.19847187399864197\n",
      "61  train loss:  0.1960635483264923\n",
      "62  train loss:  0.1931774616241455\n",
      "63  train loss:  0.19355998933315277\n",
      "64  train loss:  0.19278942048549652\n",
      "65  train loss:  0.19204643368721008\n",
      "66  train loss:  0.1904306262731552\n",
      "67  train loss:  0.1906137764453888\n",
      "68  train loss:  0.1904522031545639\n",
      "69  train loss:  0.18897485733032227\n",
      "70  train loss:  0.188674196600914\n",
      "71  train loss:  0.18846824765205383\n",
      "72  train loss:  0.1870478391647339\n",
      "73  train loss:  0.18631699681282043\n",
      "74  train loss:  0.18545609712600708\n",
      "75  train loss:  0.18496093153953552\n",
      "76  train loss:  0.18476425111293793\n",
      "77  train loss:  0.183766707777977\n",
      "78  train loss:  0.18314820528030396\n",
      "79  train loss:  0.18304531276226044\n",
      "80  train loss:  0.18226632475852966\n",
      "81  train loss:  0.18215778470039368\n",
      "82  train loss:  0.1815657913684845\n",
      "83  train loss:  0.18097837269306183\n",
      "84  train loss:  0.18087013065814972\n",
      "85  train loss:  0.18004897236824036\n",
      "86  train loss:  0.1797376573085785\n",
      "87  train loss:  0.17900244891643524\n",
      "88  train loss:  0.17852242290973663\n",
      "89  train loss:  0.17796726524829865\n",
      "90  train loss:  0.177242711186409\n",
      "91  train loss:  0.17673446238040924\n",
      "92  train loss:  0.17614568769931793\n",
      "93  train loss:  0.1761806309223175\n",
      "94  train loss:  0.17597167193889618\n",
      "95  train loss:  0.17526063323020935\n",
      "96  train loss:  0.17449705302715302\n",
      "97  train loss:  0.17572927474975586\n",
      "98  train loss:  0.17485938966274261\n",
      "99  train loss:  0.17398859560489655\n",
      "test acc (%):  tensor(78.0762)\n",
      "0  train loss:  0.5894323587417603\n",
      "1  train loss:  0.5065756440162659\n",
      "2  train loss:  0.45793670415878296\n",
      "3  train loss:  0.4254016876220703\n",
      "4  train loss:  0.39346185326576233\n",
      "5  train loss:  0.36393892765045166\n",
      "6  train loss:  0.3318388760089874\n",
      "7  train loss:  0.3190908133983612\n",
      "8  train loss:  0.3034313917160034\n",
      "9  train loss:  0.29647043347358704\n",
      "10  train loss:  0.26853206753730774\n",
      "11  train loss:  0.2784215807914734\n",
      "12  train loss:  0.2707439363002777\n",
      "13  train loss:  0.26284554600715637\n",
      "14  train loss:  0.25803565979003906\n",
      "15  train loss:  0.25740793347358704\n",
      "16  train loss:  0.2533893287181854\n",
      "17  train loss:  0.24370332062244415\n",
      "18  train loss:  0.23500943183898926\n",
      "19  train loss:  0.23289865255355835\n",
      "20  train loss:  0.23439612984657288\n",
      "21  train loss:  0.23193426430225372\n",
      "22  train loss:  0.22624471783638\n",
      "23  train loss:  0.2241591066122055\n",
      "24  train loss:  0.22105516493320465\n",
      "25  train loss:  0.21842162311077118\n",
      "26  train loss:  0.2138720452785492\n",
      "27  train loss:  0.21147267520427704\n",
      "28  train loss:  0.21032708883285522\n",
      "29  train loss:  0.20963776111602783\n",
      "30  train loss:  0.21196067333221436\n",
      "31  train loss:  0.20341062545776367\n",
      "32  train loss:  0.20452910661697388\n",
      "33  train loss:  0.2007569819688797\n",
      "34  train loss:  0.19731183350086212\n",
      "35  train loss:  0.19539563357830048\n",
      "36  train loss:  0.19287027418613434\n",
      "37  train loss:  0.1926906853914261\n",
      "38  train loss:  0.19005675613880157\n",
      "39  train loss:  0.18712717294692993\n",
      "40  train loss:  0.18569618463516235\n",
      "41  train loss:  0.18392032384872437\n",
      "42  train loss:  0.18293091654777527\n",
      "43  train loss:  0.18283699452877045\n",
      "44  train loss:  0.18070365488529205\n",
      "45  train loss:  0.17859621345996857\n",
      "46  train loss:  0.177292138338089\n",
      "47  train loss:  0.1766205132007599\n",
      "48  train loss:  0.17574259638786316\n",
      "49  train loss:  0.17444676160812378\n",
      "50  train loss:  0.17351296544075012\n",
      "51  train loss:  0.1731358915567398\n",
      "52  train loss:  0.1714005172252655\n",
      "53  train loss:  0.17087018489837646\n",
      "54  train loss:  0.17000696063041687\n",
      "55  train loss:  0.16955743730068207\n",
      "56  train loss:  0.1683381199836731\n",
      "57  train loss:  0.1672055721282959\n",
      "58  train loss:  0.1654067039489746\n",
      "59  train loss:  0.16500715911388397\n",
      "60  train loss:  0.16404852271080017\n",
      "61  train loss:  0.1633480191230774\n",
      "62  train loss:  0.16200938820838928\n",
      "63  train loss:  0.1632266491651535\n",
      "64  train loss:  0.16105607151985168\n",
      "65  train loss:  0.16015493869781494\n",
      "66  train loss:  0.1602182686328888\n",
      "67  train loss:  0.15861408412456512\n",
      "68  train loss:  0.15879662334918976\n",
      "69  train loss:  0.15764017403125763\n",
      "70  train loss:  0.15728503465652466\n",
      "71  train loss:  0.15691737830638885\n",
      "72  train loss:  0.158018097281456\n",
      "73  train loss:  0.15611982345581055\n",
      "74  train loss:  0.1562959849834442\n",
      "75  train loss:  0.15588581562042236\n",
      "76  train loss:  0.15643183887004852\n",
      "77  train loss:  0.15555340051651\n",
      "78  train loss:  0.15521973371505737\n",
      "79  train loss:  0.15407602488994598\n",
      "80  train loss:  0.15359367430210114\n",
      "81  train loss:  0.1534804105758667\n",
      "82  train loss:  0.1531384140253067\n",
      "83  train loss:  0.1528821438550949\n",
      "84  train loss:  0.15200279653072357\n",
      "85  train loss:  0.15194916725158691\n",
      "86  train loss:  0.15112929046154022\n",
      "87  train loss:  0.15094386041164398\n",
      "88  train loss:  0.15051360428333282\n",
      "89  train loss:  0.14995801448822021\n",
      "90  train loss:  0.14959903061389923\n",
      "91  train loss:  0.14984740316867828\n",
      "92  train loss:  0.14871463179588318\n",
      "93  train loss:  0.1483692079782486\n",
      "94  train loss:  0.1481180489063263\n",
      "95  train loss:  0.1477472186088562\n",
      "96  train loss:  0.14755217730998993\n",
      "97  train loss:  0.14702165126800537\n",
      "98  train loss:  0.147208571434021\n",
      "99  train loss:  0.14647531509399414\n",
      "test acc (%):  tensor(76.8704)\n",
      "0  train loss:  0.5048546195030212\n",
      "1  train loss:  0.4386008679866791\n",
      "2  train loss:  0.3938579559326172\n",
      "3  train loss:  0.3875063359737396\n",
      "4  train loss:  0.36402007937431335\n",
      "5  train loss:  0.34145957231521606\n",
      "6  train loss:  0.3142383396625519\n",
      "7  train loss:  0.304788202047348\n",
      "8  train loss:  0.30007532238960266\n",
      "9  train loss:  0.2915218770503998\n",
      "10  train loss:  0.2844979166984558\n",
      "11  train loss:  0.2725074291229248\n",
      "12  train loss:  0.26960012316703796\n",
      "13  train loss:  0.2719489634037018\n",
      "14  train loss:  0.26772841811180115\n",
      "15  train loss:  0.26979967951774597\n",
      "16  train loss:  0.26694226264953613\n",
      "17  train loss:  0.25928637385368347\n",
      "18  train loss:  0.2493143528699875\n",
      "19  train loss:  0.239933580160141\n",
      "20  train loss:  0.23793013393878937\n",
      "21  train loss:  0.23375363647937775\n",
      "22  train loss:  0.2313380241394043\n",
      "23  train loss:  0.2298184186220169\n",
      "24  train loss:  0.22283683717250824\n",
      "25  train loss:  0.21418826282024384\n",
      "26  train loss:  0.21125313639640808\n",
      "27  train loss:  0.20807260274887085\n",
      "28  train loss:  0.2047140747308731\n",
      "29  train loss:  0.20387011766433716\n",
      "30  train loss:  0.20272938907146454\n",
      "31  train loss:  0.19860781729221344\n",
      "32  train loss:  0.19556905329227448\n",
      "33  train loss:  0.19236844778060913\n",
      "34  train loss:  0.19028586149215698\n",
      "35  train loss:  0.1883639544248581\n",
      "36  train loss:  0.18713697791099548\n",
      "37  train loss:  0.1870676726102829\n",
      "38  train loss:  0.1828828901052475\n",
      "39  train loss:  0.18228890001773834\n",
      "40  train loss:  0.1827286332845688\n",
      "41  train loss:  0.18150557577610016\n",
      "42  train loss:  0.17872482538223267\n",
      "43  train loss:  0.17703062295913696\n",
      "44  train loss:  0.17591242492198944\n",
      "45  train loss:  0.17512747645378113\n",
      "46  train loss:  0.1726367473602295\n",
      "47  train loss:  0.17134448885917664\n",
      "48  train loss:  0.17116044461727142\n",
      "49  train loss:  0.17074766755104065\n",
      "50  train loss:  0.1692730188369751\n",
      "51  train loss:  0.16875416040420532\n",
      "52  train loss:  0.16776004433631897\n",
      "53  train loss:  0.16626517474651337\n",
      "54  train loss:  0.1659936159849167\n",
      "55  train loss:  0.16576632857322693\n",
      "56  train loss:  0.1649962067604065\n",
      "57  train loss:  0.16455228626728058\n",
      "58  train loss:  0.1637260764837265\n",
      "59  train loss:  0.1628863662481308\n",
      "60  train loss:  0.162586972117424\n",
      "61  train loss:  0.1622195690870285\n",
      "62  train loss:  0.16173307597637177\n",
      "63  train loss:  0.16108733415603638\n",
      "64  train loss:  0.1605837345123291\n",
      "65  train loss:  0.16016139090061188\n",
      "66  train loss:  0.15981128811836243\n",
      "67  train loss:  0.15937210619449615\n",
      "68  train loss:  0.15889666974544525\n",
      "69  train loss:  0.1585783213376999\n",
      "70  train loss:  0.15802742540836334\n",
      "71  train loss:  0.15769140422344208\n",
      "72  train loss:  0.15746262669563293\n",
      "73  train loss:  0.1569761484861374\n",
      "74  train loss:  0.15665917098522186\n",
      "75  train loss:  0.15627531707286835\n",
      "76  train loss:  0.1558179259300232\n",
      "77  train loss:  0.1556190401315689\n",
      "78  train loss:  0.15529248118400574\n",
      "79  train loss:  0.15490907430648804\n",
      "80  train loss:  0.15455736219882965\n",
      "81  train loss:  0.154276043176651\n",
      "82  train loss:  0.1540064662694931\n",
      "83  train loss:  0.15368641912937164\n",
      "84  train loss:  0.15343010425567627\n",
      "85  train loss:  0.1531999558210373\n",
      "86  train loss:  0.15297545492649078\n",
      "87  train loss:  0.15267297625541687\n",
      "88  train loss:  0.15262946486473083\n",
      "89  train loss:  0.15222486853599548\n",
      "90  train loss:  0.1520787924528122\n",
      "91  train loss:  0.1518096923828125\n",
      "92  train loss:  0.15154767036437988\n",
      "93  train loss:  0.15158632397651672\n",
      "94  train loss:  0.1511714607477188\n",
      "95  train loss:  0.15094228088855743\n",
      "96  train loss:  0.15079186856746674\n",
      "97  train loss:  0.15048550069332123\n",
      "98  train loss:  0.15034285187721252\n",
      "99  train loss:  0.15011939406394958\n",
      "test acc (%):  tensor(78.2132)\n",
      "0  train loss:  0.43476471304893494\n",
      "1  train loss:  0.4009675979614258\n",
      "2  train loss:  0.3829037547111511\n",
      "3  train loss:  0.3578285872936249\n",
      "4  train loss:  0.3551051616668701\n",
      "5  train loss:  0.34539052844047546\n",
      "6  train loss:  0.3396400511264801\n",
      "7  train loss:  0.3323391079902649\n",
      "8  train loss:  0.3222992718219757\n",
      "9  train loss:  0.3223274350166321\n",
      "10  train loss:  0.3139968812465668\n",
      "11  train loss:  0.3027832806110382\n",
      "12  train loss:  0.30005407333374023\n",
      "13  train loss:  0.29711008071899414\n",
      "14  train loss:  0.2786523103713989\n",
      "15  train loss:  0.26559197902679443\n",
      "16  train loss:  0.2654811143875122\n",
      "17  train loss:  0.2677547335624695\n",
      "18  train loss:  0.26045119762420654\n",
      "19  train loss:  0.2522084712982178\n",
      "20  train loss:  0.2483130842447281\n",
      "21  train loss:  0.24634908139705658\n",
      "22  train loss:  0.2372702658176422\n",
      "23  train loss:  0.2414190024137497\n",
      "24  train loss:  0.24067731201648712\n",
      "25  train loss:  0.23837155103683472\n",
      "26  train loss:  0.23153454065322876\n",
      "27  train loss:  0.22999413311481476\n",
      "28  train loss:  0.22756902873516083\n",
      "29  train loss:  0.2272324562072754\n",
      "30  train loss:  0.2253936529159546\n",
      "31  train loss:  0.22182823717594147\n",
      "32  train loss:  0.21972830593585968\n",
      "33  train loss:  0.2200174778699875\n",
      "34  train loss:  0.21539048850536346\n",
      "35  train loss:  0.21560519933700562\n",
      "36  train loss:  0.2168000191450119\n",
      "37  train loss:  0.21440742909908295\n",
      "38  train loss:  0.21188373863697052\n",
      "39  train loss:  0.20854322612285614\n",
      "40  train loss:  0.2094450145959854\n",
      "41  train loss:  0.2088761329650879\n",
      "42  train loss:  0.20538337528705597\n",
      "43  train loss:  0.20540723204612732\n",
      "44  train loss:  0.20351272821426392\n",
      "45  train loss:  0.20426470041275024\n",
      "46  train loss:  0.2016029804944992\n",
      "47  train loss:  0.19872213900089264\n",
      "48  train loss:  0.19871538877487183\n",
      "49  train loss:  0.19784720242023468\n",
      "50  train loss:  0.19696512818336487\n",
      "51  train loss:  0.19667884707450867\n",
      "52  train loss:  0.19461354613304138\n",
      "53  train loss:  0.19451260566711426\n",
      "54  train loss:  0.19480255246162415\n",
      "55  train loss:  0.19299405813217163\n",
      "56  train loss:  0.19560249149799347\n",
      "57  train loss:  0.19616751372814178\n",
      "58  train loss:  0.19146400690078735\n",
      "59  train loss:  0.19448450207710266\n",
      "60  train loss:  0.19006043672561646\n",
      "61  train loss:  0.19339679181575775\n",
      "62  train loss:  0.1920330822467804\n",
      "63  train loss:  0.192127987742424\n",
      "64  train loss:  0.18957215547561646\n",
      "65  train loss:  0.19205763936042786\n",
      "66  train loss:  0.18690703809261322\n",
      "67  train loss:  0.1880839318037033\n",
      "68  train loss:  0.18881674110889435\n",
      "69  train loss:  0.18653641641139984\n",
      "70  train loss:  0.18745483458042145\n",
      "71  train loss:  0.18950577080249786\n",
      "72  train loss:  0.18526685237884521\n",
      "73  train loss:  0.1902068853378296\n",
      "74  train loss:  0.1903291493654251\n",
      "75  train loss:  0.1890207827091217\n",
      "76  train loss:  0.18594585359096527\n",
      "77  train loss:  0.18221837282180786\n",
      "78  train loss:  0.18973766267299652\n",
      "79  train loss:  0.18792352080345154\n",
      "80  train loss:  0.18559370934963226\n",
      "81  train loss:  0.1850678026676178\n",
      "82  train loss:  0.1857903003692627\n",
      "83  train loss:  0.1839444637298584\n",
      "84  train loss:  0.18015877902507782\n",
      "85  train loss:  0.1809464693069458\n",
      "86  train loss:  0.18114666640758514\n",
      "87  train loss:  0.1789056807756424\n",
      "88  train loss:  0.17706860601902008\n",
      "89  train loss:  0.17668570578098297\n",
      "90  train loss:  0.1755535900592804\n",
      "91  train loss:  0.17408309876918793\n",
      "92  train loss:  0.174163356423378\n",
      "93  train loss:  0.17345479130744934\n",
      "94  train loss:  0.17267636954784393\n",
      "95  train loss:  0.17188797891139984\n",
      "96  train loss:  0.17127105593681335\n",
      "97  train loss:  0.17026400566101074\n",
      "98  train loss:  0.16999171674251556\n",
      "99  train loss:  0.16892997920513153\n",
      "test acc (%):  tensor(78.3776)\n",
      "0  train loss:  0.5051103830337524\n",
      "1  train loss:  0.4511084258556366\n",
      "2  train loss:  0.4302586317062378\n",
      "3  train loss:  0.39790529012680054\n",
      "4  train loss:  0.3732798993587494\n",
      "5  train loss:  0.35880112648010254\n",
      "6  train loss:  0.3488161861896515\n",
      "7  train loss:  0.3442591428756714\n",
      "8  train loss:  0.32496529817581177\n",
      "9  train loss:  0.2989804446697235\n",
      "10  train loss:  0.29104551672935486\n",
      "11  train loss:  0.2847437560558319\n",
      "12  train loss:  0.2752206325531006\n",
      "13  train loss:  0.26905402541160583\n",
      "14  train loss:  0.2659823000431061\n",
      "15  train loss:  0.2583724558353424\n",
      "16  train loss:  0.2534005641937256\n",
      "17  train loss:  0.24368934333324432\n",
      "18  train loss:  0.24130527675151825\n",
      "19  train loss:  0.24329520761966705\n",
      "20  train loss:  0.227321594953537\n",
      "21  train loss:  0.2341141253709793\n",
      "22  train loss:  0.23163683712482452\n",
      "23  train loss:  0.22077949345111847\n",
      "24  train loss:  0.22815515100955963\n",
      "25  train loss:  0.21918471157550812\n",
      "26  train loss:  0.22275668382644653\n",
      "27  train loss:  0.22061312198638916\n",
      "28  train loss:  0.226734921336174\n",
      "29  train loss:  0.2141304463148117\n",
      "30  train loss:  0.20420612394809723\n",
      "31  train loss:  0.20151595771312714\n",
      "32  train loss:  0.2024141401052475\n",
      "33  train loss:  0.1959846466779709\n",
      "34  train loss:  0.19555696845054626\n",
      "35  train loss:  0.20393140614032745\n",
      "36  train loss:  0.19635353982448578\n",
      "37  train loss:  0.20480278134346008\n",
      "38  train loss:  0.1963927000761032\n",
      "39  train loss:  0.20133817195892334\n",
      "40  train loss:  0.19229446351528168\n",
      "41  train loss:  0.19627338647842407\n",
      "42  train loss:  0.19140920042991638\n",
      "43  train loss:  0.18813809752464294\n",
      "44  train loss:  0.18321996927261353\n",
      "45  train loss:  0.18798576295375824\n",
      "46  train loss:  0.18383164703845978\n",
      "47  train loss:  0.18282975256443024\n",
      "48  train loss:  0.1818523406982422\n",
      "49  train loss:  0.18450260162353516\n",
      "50  train loss:  0.18205220997333527\n",
      "51  train loss:  0.18606045842170715\n",
      "52  train loss:  0.18312124907970428\n",
      "53  train loss:  0.18329976499080658\n",
      "54  train loss:  0.18089836835861206\n",
      "55  train loss:  0.17762337625026703\n",
      "56  train loss:  0.18046541512012482\n",
      "57  train loss:  0.18065054714679718\n",
      "58  train loss:  0.1799243986606598\n",
      "59  train loss:  0.17922262847423553\n",
      "60  train loss:  0.17777691781520844\n",
      "61  train loss:  0.1802690327167511\n",
      "62  train loss:  0.1885940581560135\n",
      "63  train loss:  0.1857818365097046\n",
      "64  train loss:  0.1865185797214508\n",
      "65  train loss:  0.18528297543525696\n",
      "66  train loss:  0.18414904177188873\n",
      "67  train loss:  0.1819957196712494\n",
      "68  train loss:  0.18215759098529816\n",
      "69  train loss:  0.1817510575056076\n",
      "70  train loss:  0.18162274360656738\n",
      "71  train loss:  0.17990590631961823\n",
      "72  train loss:  0.1752290576696396\n",
      "73  train loss:  0.17561210691928864\n",
      "74  train loss:  0.1737508773803711\n",
      "75  train loss:  0.17145001888275146\n",
      "76  train loss:  0.17046856880187988\n",
      "77  train loss:  0.16991138458251953\n",
      "78  train loss:  0.16945530474185944\n",
      "79  train loss:  0.16752541065216064\n",
      "80  train loss:  0.16981375217437744\n",
      "81  train loss:  0.1695944368839264\n",
      "82  train loss:  0.16886988282203674\n",
      "83  train loss:  0.16792774200439453\n",
      "84  train loss:  0.16808542609214783\n",
      "85  train loss:  0.16831207275390625\n",
      "86  train loss:  0.1657836139202118\n",
      "87  train loss:  0.1681164801120758\n",
      "88  train loss:  0.16757477819919586\n",
      "89  train loss:  0.16313694417476654\n",
      "90  train loss:  0.16298779845237732\n",
      "91  train loss:  0.16363227367401123\n",
      "92  train loss:  0.16348615288734436\n",
      "93  train loss:  0.16137979924678802\n",
      "94  train loss:  0.16102159023284912\n",
      "95  train loss:  0.160709410905838\n",
      "96  train loss:  0.15984275937080383\n",
      "97  train loss:  0.16084809601306915\n",
      "98  train loss:  0.16100609302520752\n",
      "99  train loss:  0.16036425530910492\n",
      "test acc (%):  tensor(75.8016)\n",
      "0  train loss:  0.4607674479484558\n",
      "1  train loss:  0.41082096099853516\n",
      "2  train loss:  0.3785490095615387\n",
      "3  train loss:  0.39837685227394104\n",
      "4  train loss:  0.3578956425189972\n",
      "5  train loss:  0.3194650113582611\n",
      "6  train loss:  0.3225381672382355\n",
      "7  train loss:  0.309573233127594\n",
      "8  train loss:  0.30146801471710205\n",
      "9  train loss:  0.3015346825122833\n",
      "10  train loss:  0.28175365924835205\n",
      "11  train loss:  0.267380028963089\n",
      "12  train loss:  0.26745903491973877\n",
      "13  train loss:  0.2714378833770752\n",
      "14  train loss:  0.2643560767173767\n",
      "15  train loss:  0.2510612905025482\n",
      "16  train loss:  0.23667128384113312\n",
      "17  train loss:  0.23693738877773285\n",
      "18  train loss:  0.24128016829490662\n",
      "19  train loss:  0.23531325161457062\n",
      "20  train loss:  0.22466319799423218\n",
      "21  train loss:  0.22711414098739624\n",
      "22  train loss:  0.22934329509735107\n",
      "23  train loss:  0.225467711687088\n",
      "24  train loss:  0.21196378767490387\n",
      "25  train loss:  0.21458148956298828\n",
      "26  train loss:  0.2121867835521698\n",
      "27  train loss:  0.21004676818847656\n",
      "28  train loss:  0.20223258435726166\n",
      "29  train loss:  0.19969436526298523\n",
      "30  train loss:  0.19340915977954865\n",
      "31  train loss:  0.19136561453342438\n",
      "32  train loss:  0.19099943339824677\n",
      "33  train loss:  0.18801464140415192\n",
      "34  train loss:  0.18592673540115356\n",
      "35  train loss:  0.18533776700496674\n",
      "36  train loss:  0.18313609063625336\n",
      "37  train loss:  0.18740937113761902\n",
      "38  train loss:  0.1816350668668747\n",
      "39  train loss:  0.17401136457920074\n",
      "40  train loss:  0.1834564357995987\n",
      "41  train loss:  0.17473942041397095\n",
      "42  train loss:  0.1808452606201172\n",
      "43  train loss:  0.1711329072713852\n",
      "44  train loss:  0.1709458827972412\n",
      "45  train loss:  0.17178551852703094\n",
      "46  train loss:  0.1690983921289444\n",
      "47  train loss:  0.16809304058551788\n",
      "48  train loss:  0.16517573595046997\n",
      "49  train loss:  0.16518492996692657\n",
      "50  train loss:  0.16448107361793518\n",
      "51  train loss:  0.1631484180688858\n",
      "52  train loss:  0.1610678881406784\n",
      "53  train loss:  0.15973295271396637\n",
      "54  train loss:  0.15970031917095184\n",
      "55  train loss:  0.15973038971424103\n",
      "56  train loss:  0.15708771347999573\n",
      "57  train loss:  0.1580008715391159\n",
      "58  train loss:  0.15669475495815277\n",
      "59  train loss:  0.15852533280849457\n",
      "60  train loss:  0.15558171272277832\n",
      "61  train loss:  0.15397149324417114\n",
      "62  train loss:  0.1531500518321991\n",
      "63  train loss:  0.15172120928764343\n",
      "64  train loss:  0.15289653837680817\n",
      "65  train loss:  0.15035410225391388\n",
      "66  train loss:  0.15119005739688873\n",
      "67  train loss:  0.15163129568099976\n",
      "68  train loss:  0.15001116693019867\n",
      "69  train loss:  0.14800573885440826\n",
      "70  train loss:  0.14788304269313812\n",
      "71  train loss:  0.14811183512210846\n",
      "72  train loss:  0.14665478467941284\n",
      "73  train loss:  0.14747236669063568\n",
      "74  train loss:  0.14560218155384064\n",
      "75  train loss:  0.14543494582176208\n",
      "76  train loss:  0.1457374542951584\n",
      "77  train loss:  0.14410442113876343\n",
      "78  train loss:  0.1451835185289383\n",
      "79  train loss:  0.14404085278511047\n",
      "80  train loss:  0.14312762022018433\n",
      "81  train loss:  0.14436298608779907\n",
      "82  train loss:  0.14288237690925598\n",
      "83  train loss:  0.14327169954776764\n",
      "84  train loss:  0.14146435260772705\n",
      "85  train loss:  0.14151631295681\n",
      "86  train loss:  0.1430336982011795\n",
      "87  train loss:  0.14192701876163483\n",
      "88  train loss:  0.14049729704856873\n",
      "89  train loss:  0.14216934144496918\n",
      "90  train loss:  0.14132563769817352\n",
      "91  train loss:  0.13971804082393646\n",
      "92  train loss:  0.14017392694950104\n",
      "93  train loss:  0.13881662487983704\n",
      "94  train loss:  0.13872598111629486\n",
      "95  train loss:  0.14047306776046753\n",
      "96  train loss:  0.13821257650852203\n",
      "97  train loss:  0.13793079555034637\n",
      "98  train loss:  0.14014750719070435\n",
      "99  train loss:  0.13638710975646973\n",
      "test acc (%):  tensor(77.9118)\n",
      "0  train loss:  0.5000598430633545\n",
      "1  train loss:  0.45333024859428406\n",
      "2  train loss:  0.414391428232193\n",
      "3  train loss:  0.3634977340698242\n",
      "4  train loss:  0.3551497459411621\n",
      "5  train loss:  0.3249095380306244\n",
      "6  train loss:  0.3054863512516022\n",
      "7  train loss:  0.2940385639667511\n",
      "8  train loss:  0.2819116413593292\n",
      "9  train loss:  0.27067697048187256\n",
      "10  train loss:  0.257259339094162\n",
      "11  train loss:  0.25967755913734436\n",
      "12  train loss:  0.25575199723243713\n",
      "13  train loss:  0.2449636459350586\n",
      "14  train loss:  0.24299849569797516\n",
      "15  train loss:  0.2360503077507019\n",
      "16  train loss:  0.22992271184921265\n",
      "17  train loss:  0.22598344087600708\n",
      "18  train loss:  0.22368599474430084\n",
      "19  train loss:  0.21959713101387024\n",
      "20  train loss:  0.20935197174549103\n",
      "21  train loss:  0.2074304223060608\n",
      "22  train loss:  0.2013343870639801\n",
      "23  train loss:  0.19746188819408417\n",
      "24  train loss:  0.19644653797149658\n",
      "25  train loss:  0.19151820242404938\n",
      "26  train loss:  0.18934375047683716\n",
      "27  train loss:  0.1853240579366684\n",
      "28  train loss:  0.18206572532653809\n",
      "29  train loss:  0.17979256808757782\n",
      "30  train loss:  0.17629893124103546\n",
      "31  train loss:  0.175526425242424\n",
      "32  train loss:  0.17331776022911072\n",
      "33  train loss:  0.17224837839603424\n",
      "34  train loss:  0.1701337993144989\n",
      "35  train loss:  0.16825051605701447\n",
      "36  train loss:  0.16718317568302155\n",
      "37  train loss:  0.16529755294322968\n",
      "38  train loss:  0.1641673743724823\n",
      "39  train loss:  0.16474972665309906\n",
      "40  train loss:  0.16237236559391022\n",
      "41  train loss:  0.16074803471565247\n",
      "42  train loss:  0.15890447795391083\n",
      "43  train loss:  0.15767474472522736\n",
      "44  train loss:  0.15712182223796844\n",
      "45  train loss:  0.15533950924873352\n",
      "46  train loss:  0.15452076494693756\n",
      "47  train loss:  0.15324074029922485\n",
      "48  train loss:  0.15214844048023224\n",
      "49  train loss:  0.15169881284236908\n",
      "50  train loss:  0.15039922297000885\n",
      "51  train loss:  0.1498889923095703\n",
      "52  train loss:  0.14887621998786926\n",
      "53  train loss:  0.14818379282951355\n",
      "54  train loss:  0.14741414785385132\n",
      "55  train loss:  0.14664463698863983\n",
      "56  train loss:  0.14583474397659302\n",
      "57  train loss:  0.14490076899528503\n",
      "58  train loss:  0.14423689246177673\n",
      "59  train loss:  0.14359956979751587\n",
      "60  train loss:  0.14308121800422668\n",
      "61  train loss:  0.14244765043258667\n",
      "62  train loss:  0.14187277853488922\n",
      "63  train loss:  0.14128108322620392\n",
      "64  train loss:  0.1413619965314865\n",
      "65  train loss:  0.14172624051570892\n",
      "66  train loss:  0.14097860455513\n",
      "67  train loss:  0.14090697467327118\n",
      "68  train loss:  0.13934893906116486\n",
      "69  train loss:  0.13947667181491852\n",
      "70  train loss:  0.13894496858119965\n",
      "71  train loss:  0.13871142268180847\n",
      "72  train loss:  0.13838911056518555\n",
      "73  train loss:  0.13781453669071198\n",
      "74  train loss:  0.13720789551734924\n",
      "75  train loss:  0.13679565489292145\n",
      "76  train loss:  0.13640256226062775\n",
      "77  train loss:  0.13597865402698517\n",
      "78  train loss:  0.13566045463085175\n",
      "79  train loss:  0.13540804386138916\n",
      "80  train loss:  0.13502778112888336\n",
      "81  train loss:  0.13460388779640198\n",
      "82  train loss:  0.13436473906040192\n",
      "83  train loss:  0.1340302675962448\n",
      "84  train loss:  0.13361015915870667\n",
      "85  train loss:  0.13336682319641113\n",
      "86  train loss:  0.13292796909809113\n",
      "87  train loss:  0.1326182782649994\n",
      "88  train loss:  0.13214437663555145\n",
      "89  train loss:  0.13193848729133606\n",
      "90  train loss:  0.13148443400859833\n",
      "91  train loss:  0.1312515288591385\n",
      "92  train loss:  0.130885511636734\n",
      "93  train loss:  0.13052046298980713\n",
      "94  train loss:  0.1302049309015274\n",
      "95  train loss:  0.12986038625240326\n",
      "96  train loss:  0.129703089594841\n",
      "97  train loss:  0.12937501072883606\n",
      "98  train loss:  0.12903578579425812\n",
      "99  train loss:  0.12877103686332703\n",
      "test acc (%):  tensor(77.6377)\n",
      "0  train loss:  0.6400183439254761\n",
      "1  train loss:  0.4188437759876251\n",
      "2  train loss:  0.39506494998931885\n",
      "3  train loss:  0.37408801913261414\n",
      "4  train loss:  0.36147427558898926\n",
      "5  train loss:  0.3464154899120331\n",
      "6  train loss:  0.32206955552101135\n",
      "7  train loss:  0.3159036636352539\n",
      "8  train loss:  0.2975624203681946\n",
      "9  train loss:  0.2795830965042114\n",
      "10  train loss:  0.2799089848995209\n",
      "11  train loss:  0.2711108922958374\n",
      "12  train loss:  0.26080432534217834\n",
      "13  train loss:  0.252433717250824\n",
      "14  train loss:  0.24775195121765137\n",
      "15  train loss:  0.248226135969162\n",
      "16  train loss:  0.23333293199539185\n",
      "17  train loss:  0.23154586553573608\n",
      "18  train loss:  0.2257937639951706\n",
      "19  train loss:  0.2238793969154358\n",
      "20  train loss:  0.2182309478521347\n",
      "21  train loss:  0.21622011065483093\n",
      "22  train loss:  0.21423137187957764\n",
      "23  train loss:  0.21085084974765778\n",
      "24  train loss:  0.2063005268573761\n",
      "25  train loss:  0.20597797632217407\n",
      "26  train loss:  0.20456503331661224\n",
      "27  train loss:  0.20272964239120483\n",
      "28  train loss:  0.20264874398708344\n",
      "29  train loss:  0.20221060514450073\n",
      "30  train loss:  0.1997133195400238\n",
      "31  train loss:  0.19693994522094727\n",
      "32  train loss:  0.19809848070144653\n",
      "33  train loss:  0.19194774329662323\n",
      "34  train loss:  0.1950983852148056\n",
      "35  train loss:  0.19126717746257782\n",
      "36  train loss:  0.19631648063659668\n",
      "37  train loss:  0.1894669234752655\n",
      "38  train loss:  0.19120611250400543\n",
      "39  train loss:  0.18638646602630615\n",
      "40  train loss:  0.19172847270965576\n",
      "41  train loss:  0.1902703046798706\n",
      "42  train loss:  0.18431274592876434\n",
      "43  train loss:  0.1805756390094757\n",
      "44  train loss:  0.18243101239204407\n",
      "45  train loss:  0.18212954699993134\n",
      "46  train loss:  0.17999432981014252\n",
      "47  train loss:  0.17809270322322845\n",
      "48  train loss:  0.17648130655288696\n",
      "49  train loss:  0.1754261702299118\n",
      "50  train loss:  0.17547732591629028\n",
      "51  train loss:  0.174464151263237\n",
      "52  train loss:  0.17366288602352142\n",
      "53  train loss:  0.17310285568237305\n",
      "54  train loss:  0.1722474843263626\n",
      "55  train loss:  0.17119663953781128\n",
      "56  train loss:  0.17051267623901367\n",
      "57  train loss:  0.17020894587039948\n",
      "58  train loss:  0.16966204345226288\n",
      "59  train loss:  0.16902552545070648\n",
      "60  train loss:  0.1685611754655838\n",
      "61  train loss:  0.16794395446777344\n",
      "62  train loss:  0.16762255132198334\n",
      "63  train loss:  0.1666712760925293\n",
      "64  train loss:  0.16615734994411469\n",
      "65  train loss:  0.1654169112443924\n",
      "66  train loss:  0.1648489534854889\n",
      "67  train loss:  0.16426245868206024\n",
      "68  train loss:  0.16381120681762695\n",
      "69  train loss:  0.16335150599479675\n",
      "70  train loss:  0.16271956264972687\n",
      "71  train loss:  0.16225095093250275\n",
      "72  train loss:  0.16173741221427917\n",
      "73  train loss:  0.16122567653656006\n",
      "74  train loss:  0.16076397895812988\n",
      "75  train loss:  0.16028833389282227\n",
      "76  train loss:  0.1599787175655365\n",
      "77  train loss:  0.15923957526683807\n",
      "78  train loss:  0.15882013738155365\n",
      "79  train loss:  0.15847617387771606\n",
      "80  train loss:  0.15799061954021454\n",
      "81  train loss:  0.15766502916812897\n",
      "82  train loss:  0.1572284996509552\n",
      "83  train loss:  0.15663546323776245\n",
      "84  train loss:  0.15614446997642517\n",
      "85  train loss:  0.1557288020849228\n",
      "86  train loss:  0.1553778350353241\n",
      "87  train loss:  0.15452373027801514\n",
      "88  train loss:  0.15405267477035522\n",
      "89  train loss:  0.1533554345369339\n",
      "90  train loss:  0.15297427773475647\n",
      "91  train loss:  0.15228401124477386\n",
      "92  train loss:  0.1518065333366394\n",
      "93  train loss:  0.1513548344373703\n",
      "94  train loss:  0.1508650779724121\n",
      "95  train loss:  0.15039712190628052\n",
      "96  train loss:  0.14997801184654236\n",
      "97  train loss:  0.14974015951156616\n",
      "98  train loss:  0.1492941975593567\n",
      "99  train loss:  0.1489981859922409\n",
      "test acc (%):  tensor(77.3363)\n",
      "0  train loss:  0.5048813819885254\n",
      "1  train loss:  0.44623973965644836\n",
      "2  train loss:  0.4071293771266937\n",
      "3  train loss:  0.3966136574745178\n",
      "4  train loss:  0.37367215752601624\n",
      "5  train loss:  0.3689766228199005\n",
      "6  train loss:  0.3511938154697418\n",
      "7  train loss:  0.3158588409423828\n",
      "8  train loss:  0.31770533323287964\n",
      "9  train loss:  0.3008668124675751\n",
      "10  train loss:  0.30680885910987854\n",
      "11  train loss:  0.27995580434799194\n",
      "12  train loss:  0.28955522179603577\n",
      "13  train loss:  0.2717099189758301\n",
      "14  train loss:  0.27443769574165344\n",
      "15  train loss:  0.2783193290233612\n",
      "16  train loss:  0.2528516948223114\n",
      "17  train loss:  0.2629532516002655\n",
      "18  train loss:  0.25725361704826355\n",
      "19  train loss:  0.24438543617725372\n",
      "20  train loss:  0.2410259246826172\n",
      "21  train loss:  0.2406487613916397\n",
      "22  train loss:  0.2308357208967209\n",
      "23  train loss:  0.2337752729654312\n",
      "24  train loss:  0.22759777307510376\n",
      "25  train loss:  0.22555918991565704\n",
      "26  train loss:  0.2215704619884491\n",
      "27  train loss:  0.2177528738975525\n",
      "28  train loss:  0.2149534821510315\n",
      "29  train loss:  0.21153955161571503\n",
      "30  train loss:  0.20689067244529724\n",
      "31  train loss:  0.2086075395345688\n",
      "32  train loss:  0.20473487675189972\n",
      "33  train loss:  0.20096537470817566\n",
      "34  train loss:  0.1983058601617813\n",
      "35  train loss:  0.1946389228105545\n",
      "36  train loss:  0.19357824325561523\n",
      "37  train loss:  0.19194574654102325\n",
      "38  train loss:  0.19190901517868042\n",
      "39  train loss:  0.1877594143152237\n",
      "40  train loss:  0.18617694079875946\n",
      "41  train loss:  0.1856471300125122\n",
      "42  train loss:  0.1838916689157486\n",
      "43  train loss:  0.18217192590236664\n",
      "44  train loss:  0.18020257353782654\n",
      "45  train loss:  0.17848177254199982\n",
      "46  train loss:  0.1772349774837494\n",
      "47  train loss:  0.1758834421634674\n",
      "48  train loss:  0.17474447190761566\n",
      "49  train loss:  0.17227837443351746\n",
      "50  train loss:  0.17040079832077026\n",
      "51  train loss:  0.16942636668682098\n",
      "52  train loss:  0.1686292290687561\n",
      "53  train loss:  0.16790492832660675\n",
      "54  train loss:  0.1666119247674942\n",
      "55  train loss:  0.1661561131477356\n",
      "56  train loss:  0.16503772139549255\n",
      "57  train loss:  0.1641082465648651\n",
      "58  train loss:  0.16323763132095337\n",
      "59  train loss:  0.16214396059513092\n",
      "60  train loss:  0.16166116297245026\n",
      "61  train loss:  0.16089460253715515\n",
      "62  train loss:  0.15990658104419708\n",
      "63  train loss:  0.15914709866046906\n",
      "64  train loss:  0.15794289112091064\n",
      "65  train loss:  0.156690776348114\n",
      "66  train loss:  0.15610559284687042\n",
      "67  train loss:  0.1555493324995041\n",
      "68  train loss:  0.15532216429710388\n",
      "69  train loss:  0.15444287657737732\n",
      "70  train loss:  0.1537213921546936\n",
      "71  train loss:  0.1532527655363083\n",
      "72  train loss:  0.15309090912342072\n",
      "73  train loss:  0.15260356664657593\n",
      "74  train loss:  0.15179985761642456\n",
      "75  train loss:  0.1513456255197525\n",
      "76  train loss:  0.15081116557121277\n",
      "77  train loss:  0.15034356713294983\n",
      "78  train loss:  0.14981193840503693\n",
      "79  train loss:  0.1490766853094101\n",
      "80  train loss:  0.14855416119098663\n",
      "81  train loss:  0.14829669892787933\n",
      "82  train loss:  0.14773952960968018\n",
      "83  train loss:  0.14709097146987915\n",
      "84  train loss:  0.14683175086975098\n",
      "85  train loss:  0.14641644060611725\n",
      "86  train loss:  0.14596186578273773\n",
      "87  train loss:  0.1456110030412674\n",
      "88  train loss:  0.14525380730628967\n",
      "89  train loss:  0.14484873414039612\n",
      "90  train loss:  0.14447934925556183\n",
      "91  train loss:  0.14411015808582306\n",
      "92  train loss:  0.14380589127540588\n",
      "93  train loss:  0.143424853682518\n",
      "94  train loss:  0.14311714470386505\n",
      "95  train loss:  0.14271531999111176\n",
      "96  train loss:  0.1425265520811081\n",
      "97  train loss:  0.1423095464706421\n",
      "98  train loss:  0.14192578196525574\n",
      "99  train loss:  0.14153200387954712\n",
      "test acc (%):  tensor(77.7199)\n",
      "0  train loss:  0.4219472110271454\n",
      "1  train loss:  0.4084513783454895\n",
      "2  train loss:  0.39702096581459045\n",
      "3  train loss:  0.3794935643672943\n",
      "4  train loss:  0.3954845070838928\n",
      "5  train loss:  0.3674659729003906\n",
      "6  train loss:  0.3482457399368286\n",
      "7  train loss:  0.3402285873889923\n",
      "8  train loss:  0.32723695039749146\n",
      "9  train loss:  0.33033499121665955\n",
      "10  train loss:  0.32515203952789307\n",
      "11  train loss:  0.31599336862564087\n",
      "12  train loss:  0.31666257977485657\n",
      "13  train loss:  0.31678488850593567\n",
      "14  train loss:  0.3124614953994751\n",
      "15  train loss:  0.3060562014579773\n",
      "16  train loss:  0.29887276887893677\n",
      "17  train loss:  0.2910141348838806\n",
      "18  train loss:  0.2846132516860962\n",
      "19  train loss:  0.28035828471183777\n",
      "20  train loss:  0.2689149081707001\n",
      "21  train loss:  0.2624330222606659\n",
      "22  train loss:  0.2575998604297638\n",
      "23  train loss:  0.252197802066803\n",
      "24  train loss:  0.2484717071056366\n",
      "25  train loss:  0.24792997539043427\n",
      "26  train loss:  0.24528393149375916\n",
      "27  train loss:  0.24135445058345795\n",
      "28  train loss:  0.23874914646148682\n",
      "29  train loss:  0.2352847307920456\n",
      "30  train loss:  0.23266910016536713\n",
      "31  train loss:  0.23007526993751526\n",
      "32  train loss:  0.2277001440525055\n",
      "33  train loss:  0.22655537724494934\n",
      "34  train loss:  0.22553925216197968\n",
      "35  train loss:  0.22394956648349762\n",
      "36  train loss:  0.22141703963279724\n",
      "37  train loss:  0.21951237320899963\n",
      "38  train loss:  0.218922421336174\n",
      "39  train loss:  0.21643240749835968\n",
      "40  train loss:  0.21459554135799408\n",
      "41  train loss:  0.21335147321224213\n",
      "42  train loss:  0.2119537591934204\n",
      "43  train loss:  0.2098601907491684\n",
      "44  train loss:  0.2079285979270935\n",
      "45  train loss:  0.2065471112728119\n",
      "46  train loss:  0.20476503670215607\n",
      "47  train loss:  0.20367398858070374\n",
      "48  train loss:  0.20308208465576172\n",
      "49  train loss:  0.20162855088710785\n",
      "50  train loss:  0.2004927545785904\n",
      "51  train loss:  0.19986557960510254\n",
      "52  train loss:  0.1991669237613678\n",
      "53  train loss:  0.19790524244308472\n",
      "54  train loss:  0.19797073304653168\n",
      "55  train loss:  0.20028938353061676\n",
      "56  train loss:  0.21927420794963837\n",
      "57  train loss:  0.2183404415845871\n",
      "58  train loss:  0.20316065847873688\n",
      "59  train loss:  0.2173498570919037\n",
      "60  train loss:  0.21517956256866455\n",
      "61  train loss:  0.20352067053318024\n",
      "62  train loss:  0.20757849514484406\n",
      "63  train loss:  0.21034902334213257\n",
      "64  train loss:  0.20671507716178894\n",
      "65  train loss:  0.20553678274154663\n",
      "66  train loss:  0.2041390836238861\n",
      "67  train loss:  0.20120680332183838\n",
      "68  train loss:  0.1983424723148346\n",
      "69  train loss:  0.19766752421855927\n",
      "70  train loss:  0.19752933084964752\n",
      "71  train loss:  0.19393682479858398\n",
      "72  train loss:  0.19478201866149902\n",
      "73  train loss:  0.1915222704410553\n",
      "74  train loss:  0.19061696529388428\n",
      "75  train loss:  0.18905436992645264\n",
      "76  train loss:  0.18655818700790405\n",
      "77  train loss:  0.18765251338481903\n",
      "78  train loss:  0.18669767677783966\n",
      "79  train loss:  0.1840633898973465\n",
      "80  train loss:  0.1837395280599594\n",
      "81  train loss:  0.18383587896823883\n",
      "82  train loss:  0.18318355083465576\n",
      "83  train loss:  0.180633082985878\n",
      "84  train loss:  0.18115748465061188\n",
      "85  train loss:  0.18128934502601624\n",
      "86  train loss:  0.17991797626018524\n",
      "87  train loss:  0.17910943925380707\n",
      "88  train loss:  0.1793626844882965\n",
      "89  train loss:  0.1788274496793747\n",
      "90  train loss:  0.17763929069042206\n",
      "91  train loss:  0.176796555519104\n",
      "92  train loss:  0.17650732398033142\n",
      "93  train loss:  0.17587700486183167\n",
      "94  train loss:  0.17533910274505615\n",
      "95  train loss:  0.17485886812210083\n",
      "96  train loss:  0.17461955547332764\n",
      "97  train loss:  0.1740770936012268\n",
      "98  train loss:  0.17341755330562592\n",
      "99  train loss:  0.17275527119636536\n",
      "test acc (%):  tensor(77.4459)\n"
     ]
    }
   ],
   "source": [
    "sn_train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 0\n",
      "loss:  0.5792011618614197\n",
      "acc (%):  tensor(82.5706)\n"
     ]
    }
   ],
   "source": [
    "sn_test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 0\n",
      "loss:  0.7074867486953735\n",
      "acc (%):  tensor(80.)\n"
     ]
    }
   ],
   "source": [
    "sn_real_test(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
