{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import gensim\n",
    "import simple_net\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_df.sentence.values\n",
    "train_labels = train_df.label.values\n",
    "\n",
    "test_sentences = test_df.sentence.values\n",
    "test_labels = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('../model/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bring_nn_input(sentences):\n",
    "    vec_list = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = sentence.strip().split()\n",
    "\n",
    "        count = 0\n",
    "        sum_vec = np.zeros(300)\n",
    "\n",
    "        for word in words:\n",
    "            if word in word2vec_model:\n",
    "                sum_vec += word2vec_model[word]\n",
    "                count += 1\n",
    "        \n",
    "        if count != 0:\n",
    "            vec = (sum_vec / count)\n",
    "    \n",
    "        vec_list.append(vec)\n",
    "\n",
    "    return np.array(vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = bring_nn_input(train_sentences)\n",
    "test_vec = bring_nn_input(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 300\n",
    "hidden=100\n",
    "output = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_model = simple_net.Simple_Net(input, hidden, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(train_vec, train_labels, shuffle=True, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "optimizer = torch.optim.Adam(sn_model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/usairline{}'.format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sn_train(epochs):\n",
    "    x_train = Variable(torch.from_numpy(features_train)).float()\n",
    "    y_train = Variable(torch.from_numpy(labels_train)).long()\n",
    "\n",
    "    x_test = Variable(torch.from_numpy(features_test)).float()\n",
    "    y_test = Variable(torch.from_numpy(labels_test)).long()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sn_model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred_train = sn_model(x_train)\n",
    "        loss_train = criterion(y_pred_train, y_train)\n",
    "        \n",
    "        # print (\"epoch #\",epoch)\n",
    "        print (\"train loss: \", loss_train.item())\n",
    "        pred_train = torch.max(y_pred_train, 1)[1].eq(y_train).sum()\n",
    "        print (\"train acc:(%) \", 100*pred_train/len(x_train))\n",
    "\n",
    "        tb_x = epoch\n",
    "        # writer.add_scalar('Loss/train', loss_train.item(), tb_x)\n",
    "\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_test = sn_model(x_test)\n",
    "            loss_test = criterion(y_pred_test, y_test)\n",
    "            \n",
    "            # print (\"epoch #\",epoch)\n",
    "            print (\"test loss: \", loss_test.item())\n",
    "            pred_test = torch.max(y_pred_test, 1)[1].eq(y_test).sum()\n",
    "            print (\"test acc (%): \", 100*pred_test/len(x_test))\n",
    "        \n",
    "        writer.add_scalars('SimpleNet Training vs. Testing Loss',\n",
    "                    { 'Train' : loss_train.item(), 'Test' : loss_test.item() },\n",
    "                    tb_x + 1)\n",
    "        \n",
    "        writer.add_scalars('SimpleNet Training vs. Testing Accuracy',\n",
    "                    { 'Train' : 100*pred_train/len(x_train), 'Test' : 100*pred_test/len(x_test) },\n",
    "                    tb_x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sn_test(epochs):\n",
    "    sn_model.eval()\n",
    "    x_test = Variable(torch.from_numpy(features_test)).float()\n",
    "    y_test = Variable(torch.from_numpy(labels_test)).long()\n",
    "    for epoch in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            y_pred = sn_model(x_test)\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            print (\"epoch #\",epoch)\n",
    "            print (\"loss: \", loss.item())\n",
    "            pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "            print (\"acc (%): \", 100*pred/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sn_real_test(epochs):\n",
    "    sn_model.eval()\n",
    "    x_test = Variable(torch.from_numpy(test_vec)).float()\n",
    "    y_test = Variable(torch.from_numpy(test_labels)).long()\n",
    "    for epoch in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            y_pred = sn_model(x_test)\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            print (\"epoch #\",epoch)\n",
    "            print (\"loss: \", loss.item())\n",
    "            pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "            print (\"acc (%): \", 100*pred/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_real_test(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
